(function(e,t){'object'==typeof exports&&'undefined'!=typeof module?t():'function'==typeof define&&define.amd?define(t):t()})(this,function(){'use strict';function e(){throw new Error('Dynamic requires are not currently supported by rollup-plugin-commonjs')}function t(e,t){return t={exports:{}},e(t,t.exports),t.exports}// ES3 safe
//closed el<el />
function n(){}function r(e,t,n,r,c){function f(e){// String.prototype.fromCharCode does not supports
// > 2 bytes unicode chars directly
if(65535<e){e-=65536;var t=55296+(e>>10),n=56320+(1023&e);return Fe(t,n)}return Fe(e)}function g(e){var t=e.slice(1,-1);return t in n?n[t]:'#'===t.charAt(0)?f(parseInt(t.substr(1).replace('x','0x'))):(c.error('entity not found:'+e),e)}function _(t){//has some bugs
if(t>C){var n=e.substring(C,t).replace(/&#?\w+;/g,g);v&&b(C),r.characters(n,0,t-C),C=t}}function b(t,n){for(;t>=x&&(n=k.exec(e));)y=n.index,x=y+n[0].length,v.lineNumber++;v.columnNumber=t-y+1}for(var y=0,x=0,k=/.*(?:\r\n?|\n)|.*$/g,v=r.locator,w=[{currentNSMap:t}],N={},C=0;;){try{var E=e.indexOf('<',C);if(0>E){if(!e.substr(C).match(/^\s*$/)){var S=r.doc,I=S.createTextNode(e.substr(C));S.appendChild(I),r.currentElement=I}return}switch(E>C&&_(E),e.charAt(E+1)){case'/':var A=e.indexOf('>',E+3),T=e.substring(E+2,A),O=w.pop();0>A?(T=e.substring(E+2).replace(/[\s<].*/,''),c.error('end tag name: '+T+' is not complete:'+O.tagName),A=E+1+T.length):T.match(/\s</)&&(T=T.replace(/[\s<].*/,''),c.error('end tag name: '+T+' maybe not complete'),A=E+1+T.length);//console.error(parseStack.length,parseStack)
//console.error(config);
var z=O.localNSMap,D=O.tagName==T,R=D||O.tagName&&O.tagName.toLowerCase()==T.toLowerCase();if(R){if(r.endElement(O.uri,O.localName,T),z)for(var B in z)r.endPrefixMapping(B);D||c.fatalError('end tag name: '+T+' is not match the current start tagName:'+O.tagName)}else w.push(O);A++;break;// end elment
case'?':v&&b(E),A=h(e,E,r);break;case'!':v&&b(E),A=u(e,E,r,c);break;default:v&&b(E);var P=new m,L=w[w.length-1].currentNSMap,A=o(e,E,P,L,g,c),F=P.length;//elStartEnd
if(!P.closed&&p(e,A,P.tagName,N)&&(P.closed=!0,!n.nbsp&&c.warning('unclosed xml attribute')),v&&F){//try{//attribute position fixed
for(var j=s(v,{}),U=0,i;U<F;U++)i=P[U],b(i.offset),i.locator=s(v,{});//}catch(e){console.error('@@@@@'+e)}
r.locator=j,d(P,r,L)&&w.push(P),r.locator=v}else d(P,r,L)&&w.push(P);'http://www.w3.org/1999/xhtml'!==P.uri||P.closed?A++:A=l(e,A,P.tagName,g,r);}}catch(t){c.error('element parse error: '+t),A=-1}A>C?C=A:_(Ue(E,C)+1)}}function s(e,n){return n.lineNumber=e.lineNumber,n.columnNumber=e.columnNumber,n}/**
	 * @see #appendElement(source,elStartEnd,el,selfClosed,entityReplacer,domBuilder,parseStack);
	 * @return end of the elementStartPart(end of elementEndPart for selfClosed el)
	 */function o(e,t,n,r,a,i){//status
for(var o=++t,d=gt,s,l;;){var p=e.charAt(o);switch(p){case'=':if(d===_t)s=e.slice(t,o),d=yt;else if(d===bt)d=yt;else//fatalError: equal must after attrName or space after attrName
throw new Error('attribute equal must after attrName');break;case'\'':case'"':if(d===yt||d===_t//|| s == S_ATTR_SPACE
){if(d===_t&&(i.warning('attribute value must after "="'),s=e.slice(t,o)),t=o+1,o=e.indexOf(p,t),0<o)l=e.slice(t,o).replace(/&#?\w+;/g,a),n.add(s,l,t-1),d=kt;else//fatalError: no end quot match
throw new Error('attribute value no end \''+p+'\' match');}else if(d==xt)l=e.slice(t,o).replace(/&#?\w+;/g,a),n.add(s,l,t),i.warning('attribute "'+s+'" missed start quot('+p+')!!'),t=o+1,d=kt;else//fatalError: no equal before
throw new Error('attribute value must after "="');break;case'/':switch(d){case gt:n.setTagName(e.slice(t,o));case kt:case vt:case wt:d=wt,n.closed=!0;case xt:case _t:case bt:break;//case S_EQ:
default:throw new Error('attribute invalid close char(\'/\')');}break;case'':return i.error('unexpected end of input'),d==gt&&n.setTagName(e.slice(t,o)),o;case'>':switch(d){case gt:n.setTagName(e.slice(t,o));case kt:case vt:case wt:break;//normal
case xt://Compatible state
case _t:l=e.slice(t,o),'/'===l.slice(-1)&&(n.closed=!0,l=l.slice(0,-1));case bt:d===bt&&(l=s),d==xt?(i.warning('attribute "'+l+'" missed quot(")!!'),n.add(s,l.replace(/&#?\w+;/g,a),t)):(('http://www.w3.org/1999/xhtml'!==r['']||!l.match(/^(?:disabled|checked|selected)$/i))&&i.warning('attribute "'+l+'" missed value!! "'+l+'" instead!!'),n.add(l,l,t));break;case yt:throw new Error('attribute value missed!!');}//			console.log(tagName,tagNamePattern,tagNamePattern.test(tagName))
return o;/*xml space '\x20' | #x9 | #xD | #xA; */case'\x80':p=' ';default:if(' '>=p)//space
switch(d){case gt:n.setTagName(e.slice(t,o)),d=vt;break;case _t:s=e.slice(t,o),d=bt;break;case xt:var l=e.slice(t,o).replace(/&#?\w+;/g,a);i.warning('attribute "'+l+'" missed quot(")!!'),n.add(s,l,t);case kt:d=vt;//case S_TAG_SPACE:
//case S_EQ:
//case S_ATTR_SPACE:
//	void();break;
//case S_TAG_CLOSE:
//ignore warning
}else//not space
//S_TAG,	S_ATTR,	S_EQ,	S_ATTR_NOQUOT_VALUE
//S_ATTR_SPACE,	S_ATTR_END,	S_TAG_SPACE, S_TAG_CLOSE
switch(d){//case S_TAG:void();break;
//case S_ATTR:void();break;
//case S_ATTR_NOQUOT_VALUE:void();break;
case bt:n.tagName;'http://www.w3.org/1999/xhtml'===r['']&&s.match(/^(?:disabled|checked|selected)$/i)||i.warning('attribute "'+s+'" missed value!! "'+s+'" instead2!!'),n.add(s,s,t),t=o,d=_t;break;case kt:i.warning('attribute space is required"'+s+'"!!');case vt:d=_t,t=o;break;case yt:d=xt,t=o;break;case wt:throw new Error('elements closed character \'/\' and \'>\' must be connected to');}}//end outer switch
//console.log('p++',p)
o++}}/**
	 * @return true if has new namespace define
	 */function d(e,t,n){//var currentNSMap = parseStack[parseStack.length-1].currentNSMap;
for(var r=e.tagName,s=null,o=e.length;o--;){var i=e[o],a=i.qName,d=i.value,l=a.indexOf(':');if(0<l)var p=i.prefix=a.slice(0,l),u=a.slice(l+1),h='xmlns'===p&&u;else u=a,p=null,h='xmlns'===a&&'';//can not set prefix,because prefix !== ''
i.localName=u,!1!==h&&(null==s&&(s={},c(n,n={})),n[h]=s[h]=d,i.uri='http://www.w3.org/2000/xmlns/',t.startPrefixMapping(h,d))}for(var o=e.length;o--;){i=e[o];var p=i.prefix;p&&('xml'===p&&(i.uri='http://www.w3.org/XML/1998/namespace'),'xmlns'!==p&&(i.uri=n[p||'']))}var l=r.indexOf(':');0<l?(p=e.prefix=r.slice(0,l),u=e.localName=r.slice(l+1)):(p=null,u=e.localName=r);//no prefix element has default namespace
var m=e.uri=n[p||''];//endPrefixMapping and startPrefixMapping have not any help for dom builder
//localNSMap = null
if(t.startElement(m,u,r,e),!e.closed)//parseStack.push(el);
return e.currentNSMap=n,e.localNSMap=s,!0;if(t.endElement(m,u,r),s)for(p in s)t.endPrefixMapping(p)}function l(e,t,n,r,a){if(/^(?:script|textarea)$/i.test(n)){var i=e.indexOf('</'+n+'>',t),s=e.substring(t+1,i);if(/[&<]/.test(s))//}
return /^script$/i.test(n)?(a.characters(s,0,s.length),i):(s=s.replace(/&#?\w+;/g,r),a.characters(s,0,s.length),i);//}else{//text area
}return t+1}function p(e,t,n,r){//if(tagName in closeMap){
var a=r[n];return null==a&&(a=e.lastIndexOf('</'+n+'>'),a<t&&(a=e.lastIndexOf('</'+n)),r[n]=a),a<t;//} 
}function c(e,t){for(var r in e)t[r]=e[r]}function u(e,t,n,r){//sure start with '<!'
var a=e.charAt(t+2);switch(a){case'-':if('-'===e.charAt(t+3)){var s=e.indexOf('-->',t+4);//append comment source.substring(4,end)//<!--
return s>t?(n.comment(e,t+4,s-t-4),s+3):(r.error('Unclosed comment'),-1)}//error
return-1;default:if('CDATA['==e.substr(t+3,6)){var s=e.indexOf(']]>',t+9);return n.startCDATA(),n.characters(e,t+9,s-t-9),n.endCDATA(),s+3}//<!DOCTYPE
//startDTD(java.lang.String name, java.lang.String publicId, java.lang.String systemId) 
var o=i(e,t),d=o.length;if(1<d&&/!doctype/i.test(o[0][0])){var l=o[1][0],p=3<d&&/^public$/i.test(o[2][0])&&o[3][0],c=4<d&&o[4][0],u=o[d-1];return n.startDTD(l,p&&p.replace(/^(['"])(.*?)\1$/,'$2'),c&&c.replace(/^(['"])(.*?)\1$/,'$2')),n.endDTD(),u.index+u[0].length}}return-1}function h(e,t,n){var r=e.indexOf('?>',t);if(r){var a=e.substring(t,r).match(/^<\?(\S*)\s*([\s\S]*?)\s*$/);if(a){a[0].length;return n.processingInstruction(a[1],a[2]),r+2}//error
return-1}return-1}/**
	 * @param source
	 */function m(){}function a(e,t){return e.__proto__=t,e}function i(e,t){var n=[],r=/'[^']+'|"[^"]+"|[^\s<>\/=]+=?|(\/?\s*>|<)/g,a;//skip <
for(r.lastIndex=t,r.exec(e);a=r.exec(e);)if(n.push(a),a[1])return n}/*
	 * DOM Level 2
	 * Object DOMException
	 * @see http://www.w3.org/TR/REC-DOM-Level-1/ecma-script-language-binding.html
	 * @see http://www.w3.org/TR/2000/REC-DOM-Level-2-Core-20001113/ecma-script-binding.html
	 */function f(e,t){for(var n in e)t[n]=e[n]}/**
	^\w+\.prototype\.([_\w]+)\s*=\s*((?:.*\{\s*?[\r\n][\s\S]*?^})|\S.*?(?=[;\r\n]));?
	^\w+\.prototype\.([_\w]+)\s*=\s*(\S.*?(?=[;\r\n]));?
	 */function g(e,n){var r=e.prototype;if(Object.create){var t=Object.create(n.prototype);r.__proto__=t}if(!(r instanceof n)){function a(){}a.prototype=n.prototype,a=new a,f(r,a),e.prototype=r=a}r.constructor!=e&&('function'!=typeof e&&console.error('unknow Class:'+e),r.constructor=e)}function _(e,t){if(t instanceof Error)var n=t;else n=this,Error.call(this,Ut[e]),this.message=Ut[e],Error.captureStackTrace&&Error.captureStackTrace(this,_);return n.code=e,t&&(this.message=this.message+': '+t),n}/**
	 * @see http://www.w3.org/TR/2000/REC-DOM-Level-2-Core-20001113/core.html#ID-536297177
	 * The NodeList interface provides the abstraction of an ordered collection of nodes, without defining or constraining how this collection is implemented. NodeList objects in the DOM are live.
	 * The items in the NodeList are accessible via an integral index, starting from 0.
	 */function b(){}function y(e,t){this._node=e,this._refresh=t,x(this)}function x(e){var t=e._node._inc||e._node.ownerDocument._inc;if(e._inc!=t){var n=e._refresh(e._node);//console.log(ls.length)
ee(e,'length',n.length),f(n,e),e._inc=t}}/**
	 * 
	 * Objects implementing the NamedNodeMap interface are used to represent collections of nodes that can be accessed by name. Note that NamedNodeMap does not inherit from NodeList; NamedNodeMaps are not maintained in any particular order. Objects contained in an object implementing NamedNodeMap may also be accessed by an ordinal index, but this is simply to allow convenient enumeration of the contents of a NamedNodeMap, and does not imply that the DOM specifies an order to these Nodes.
	 * NamedNodeMap objects in the DOM are live.
	 * used for attributes or DocumentType entities 
	 */function k(){}function v(e,t){for(var n=e.length;n--;)if(e[n]===t)return n}function w(e,t,n,r){if(r?t[v(t,r)]=n:t[t.length++]=n,e){n.ownerElement=e;var a=e.ownerDocument;a&&(r&&O(a,e,r),T(a,e,n))}}function N(e,t,n){//console.log('remove attr:'+attr)
var r=v(t,n);if(0<=r){for(var a=t.length-1;r<a;)t[r]=t[++r];if(t.length=a,e){var i=e.ownerDocument;i&&(O(i,e,n),n.ownerElement=null)}}else throw _(Xt,new Error(e.tagName+'@'+n))}/**
	 * @see http://www.w3.org/TR/REC-DOM-Level-1/level-one-core.html#ID-102161490
	 */function C(/* Object */e){if(this._features={},e)for(var t in e)this._features=e[t]}/**
	 * @see http://www.w3.org/TR/2000/REC-DOM-Level-2-Core-20001113/core.html#ID-1950641247
	 */function E(){}function S(e){return'<'==e&&'&lt;'||'>'==e&&'&gt;'||'&'==e&&'&amp;'||'"'==e&&'&quot;'||'&#'+e.charCodeAt()+';'}/**
	 * @param callback return true for continue,false for break
	 * @return boolean true: break visit;
	 */function I(e,t){if(t(e))return!0;if(e=e.firstChild)do if(I(e,t))return!0;while(e=e.nextSibling)}function A(){}function T(e,t,n){e&&e._inc++;var r=n.namespaceURI;'http://www.w3.org/2000/xmlns/'==r&&(t._nsMap[n.prefix?n.localName:'']=n.value)}function O(e,t,n){e&&e._inc++;var r=n.namespaceURI;'http://www.w3.org/2000/xmlns/'==r&&delete t._nsMap[n.prefix?n.localName:'']}function z(e,t,n){if(e&&e._inc){e._inc++;//update childNodes
var r=t.childNodes;if(n)r[r.length++]=n;else{for(//console.log(1)
var a=t.firstChild,s=0;a;)r[s++]=a,a=a.nextSibling;r.length=s}}}/**
	 * attributes;
	 * children;
	 * 
	 * writeable properties:
	 * nodeValue,Attr:value,CharacterData:data
	 * prefix
	 */function D(e,t){var n=t.previousSibling,r=t.nextSibling;return n?n.nextSibling=r:e.firstChild=r,r?r.previousSibling=n:e.lastChild=n,z(e.ownerDocument,e),t}/**
	 * preformance key(refChild == null)
	 */function R(e,t,n){var r=t.parentNode;if(r&&r.removeChild(t),t.nodeType===Lt){var a=t.firstChild;if(null==a)return t;var i=t.lastChild}else a=i=t;var s=n?n.previousSibling:e.lastChild;a.previousSibling=s,i.nextSibling=n,s?s.nextSibling=a:e.firstChild=a,null==n?e.lastChild=i:n.previousSibling=i;do a.parentNode=e;while(a!==i&&(a=a.nextSibling));return z(e.ownerDocument||e,e),t.nodeType==Lt&&(t.firstChild=t.lastChild=null),t}function B(e,t){var n=t.parentNode;if(n){var r=e.lastChild;n.removeChild(t);//remove and update
var r=e.lastChild}var r=e.lastChild;return t.parentNode=e,t.previousSibling=r,t.nextSibling=null,r?r.nextSibling=t:e.firstChild=t,e.lastChild=t,z(e.ownerDocument,e,t),t;//console.log("__aa",parentNode.lastChild.nextSibling == null)
}function P(){this._nsMap={}}function L(){}function F(){}function j(){}function U(){}function M(){}function W(){}function H(){}function Z(){}function q(){}function Y(){}function G(){}function X(){}function V(e,t){var n=[],r=9==this.nodeType?this.documentElement:this,a=r.prefix,i=r.namespaceURI;if(i&&null==a){//console.log(prefix)
var a=r.lookupPrefix(i);if(null==a)//isHTML = true;
var s=[{namespace:i,prefix:null//{namespace:uri,prefix:''}
}]}//console.log('###',this.nodeType,uri,prefix,buf.join(''))
return $(this,n,e,t,s),n.join('')}function K(e,t,n){var r=e.prefix||'',a=e.namespaceURI;if(!r&&!a)return!1;if('xml'===r&&'http://www.w3.org/XML/1998/namespace'===a||'http://www.w3.org/2000/xmlns/'==a)return!1;//console.log('@@@@',node.tagName,prefix,uri,visibleNamespaces)
for(var s=n.length;s--;){var i=n[s];// get namespace prefix
//console.log(node.nodeType,node.tagName,ns.prefix,prefix)
if(i.prefix==r)return i.namespace!=a}//console.log(isHTML,uri,prefix=='')
//if(isHTML && prefix ==null && uri == 'http://www.w3.org/1999/xhtml'){
//	return false;
//}
//node.flag = '11111'
//console.error(3,true,node.flag,node.prefix,node.namespaceURI)
return!0}function $(e,t,n,r,a){if(r){if(e=r(e),!e)return;//buf.sort.apply(attrs, attributeSorter);
if('string'==typeof e)return void t.push(e)}switch(e.nodeType){case St:a||(a=[]);var s=a.length,o=e.attributes,d=o.length,l=e.firstChild,p=e.tagName;n=Ct===e.namespaceURI||n,t.push('<',p);for(var c=0,i;c<d;c++)i=o.item(c),'xmlns'==i.prefix?a.push({prefix:i.localName,namespace:i.value}):'xmlns'==i.nodeName&&a.push({prefix:'',namespace:i.value});for(var c=0,i;c<d;c++){if(i=o.item(c),K(i,n,a)){var u=i.prefix||'',h=i.namespaceURI,m=u?' xmlns:'+u:' xmlns';t.push(m,'="',h,'"'),a.push({prefix:u,namespace:h})}$(i,t,n,r,a)}// add namespace for current node		
if(K(e,n,a)){var u=e.prefix||'',h=e.namespaceURI,m=u?' xmlns:'+u:' xmlns';t.push(m,'="',h,'"'),a.push({prefix:u,namespace:h})}if(l||n&&!/^(?:meta|link|img|br|hr|input)$/i.test(p)){//if is cdata child node
if(t.push('>'),n&&/^script$/i.test(p))for(;l;)l.data?t.push(l.data):$(l,t,n,r,a),l=l.nextSibling;else for(;l;)$(l,t,n,r,a),l=l.nextSibling;t.push('</',p,'>')}else t.push('/>');// remove added visible namespaces
//visibleNamespaces.length = startVisibleNamespaces;
return;case Bt:case Lt:for(var l=e.firstChild;l;)$(l,t,n,r,a),l=l.nextSibling;return;case It:return t.push(' ',e.name,'="',e.value.replace(/[<&"]/g,S),'"');case At:return t.push(e.data.replace(/[<&]/g,S));case Tt:return t.push('<![CDATA[',e.data,']]>');case Rt:return t.push('<!--',e.data,'-->');case Pt:var f=e.publicId,g=e.systemId;if(t.push('<!DOCTYPE ',e.name),f)t.push(' PUBLIC "',f),g&&'.'!=g&&t.push('" "',g),t.push('">');else if(g&&'.'!=g)t.push(' SYSTEM "',g,'">');else{var _=e.internalSubset;_&&t.push(' [',_,']'),t.push('>')}return;case Dt:return t.push('<?',e.target,' ',e.data,'?>');case Ot:return t.push('&',e.nodeName,';');//case ENTITY_NODE:
//case NOTATION_NODE:
default:t.push('??',e.nodeName);}}function J(e,t,n){var r;switch(t.nodeType){case St:r=t.cloneNode(!1),r.ownerDocument=e;//var attrs = node2.attributes;
//var len = attrs.length;
//for(var i=0;i<len;i++){
//node2.setAttributeNodeNS(importNode(doc,attrs.item(i),deep));
//}
case Lt:break;case It:n=!0;//case ENTITY_REFERENCE_NODE:
//case PROCESSING_INSTRUCTION_NODE:
////case TEXT_NODE:
//case CDATA_SECTION_NODE:
//case COMMENT_NODE:
//	deep = false;
//	break;
//case DOCUMENT_NODE:
//case DOCUMENT_TYPE_NODE:
//cannot be imported.
//case ENTITY_NODE:
//case NOTATION_NODE：
//can not hit in level3
//default:throw e;
}if(r||(r=t.cloneNode(!1)),r.ownerDocument=e,r.parentNode=null,n)for(var a=t.firstChild;a;)r.appendChild(J(e,a,n)),a=a.nextSibling;return r}//
//var _relationMap = {firstChild:1,lastChild:1,previousSibling:1,nextSibling:1,
//					attributes:1,childNodes:1,parentNode:1,documentElement:1,doctype,};
function Q(e,t,r){var a=new t.constructor;for(var s in t){var n=t[s];'object'!=typeof n&&n!=a[s]&&(a[s]=n)}switch(t.childNodes&&(a.childNodes=new b),a.ownerDocument=e,a.nodeType){case St:var o=t.attributes,d=a.attributes=new k,l=o.length;d._ownerElement=a;for(var p=0;p<l;p++)a.setAttributeNode(Q(e,o.item(p),!0));break;case It:r=!0;}if(r)for(var i=t.firstChild;i;)a.appendChild(Q(e,i,r)),i=i.nextSibling;return a}function ee(e,t,n){e[t]=n}//do dynamic
/**
	 * Generates a UUID
	 * based on: http://stackoverflow.com/questions/105034/how-to-create-a-guid-uuid-in-javascript
	 * @returns {string} uuid
	 * @memberof Core
	 */function te(){var e=new Date().getTime();return'undefined'!=typeof performance&&'function'==typeof performance.now&&(e+=performance.now()),'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g,function(t){var n=0|(e+16*Math.random())%16;return e=Le(e/16),('x'===t?n:8|3&n).toString(16)})}/**
	 * @returns {boolean}
	 * @memberof Core
	 */function ne(e){return!isNaN(parseFloat(e))&&isFinite(e)}/**
	 * Extend properties of an object
	 * @param {object} target
	 * @returns {object}
	 * @memberof Core
	 */function re(e){var t=[].slice.call(arguments,1);return t.forEach(function(t){t&&Object.getOwnPropertyNames(t).forEach(function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))})}),e}/**
	 * Finds where something would fit into a sorted array
	 * @param {any} item
	 * @param {array} array
	 * @param {function} [compareFunction]
	 * @param {function} [_start]
	 * @param {function} [_end]
	 * @returns {number} location (in array)
	 * @memberof Core
	 */function ae(e,t,n,r,a){var i=r||0,s=a||t.length,o=parseInt(i+(s-i)/2),d;return(n||(n=function(e,t){return e>t?1:e<t?-1:e==t?0:void 0}),0>=s-i)?o:(d=n(t[o],e),1==s-i?0<=d?o:o+1:0===d?o:-1===d?ae(e,t,n,o,s):ae(e,t,n,i,o))}/**
	 * Finds index of something in a sorted array
	 * Returns -1 if not found
	 * @param {any} item
	 * @param {array} array
	 * @param {function} [compareFunction]
	 * @param {function} [_start]
	 * @param {function} [_end]
	 * @returns {number} index (in array) or -1
	 * @memberof Core
	 */function ie(e,t,n,r,a){var i=r||0,s=a||t.length,o=parseInt(i+(s-i)/2),d;return(n||(n=function(e,t){return e>t?1:e<t?-1:e==t?0:void 0}),0>=s-i)?-1:(d=n(t[o],e),1==s-i?0===d?o:-1:0===d?o:-1===d?ie(e,t,n,o,s):ie(e,t,n,i,o))}/**
	 * Gets the index of a node in its parent
	 * @private
	 * @memberof Core
	 */function se(e,t){for(var n=e.parentNode,r=n.childNodes,a=-1,s=0,i;s<r.length&&(i=r[s],i.nodeType===t&&a++,i!=e);s++);return a}/**
	 * Gets the index of an element node in its parent
	 * @param {element} elementNode
	 * @returns {number} index
	 * @memberof Core
	 */function oe(e){return se(e,ln)}/**
	 * Check if extension is xml
	 * @param {string} ext
	 * @returns {boolean}
	 * @memberof Core
	 */function de(e){return-1<['xml','opf','ncx'].indexOf(e)}/**
	 * Create a new blob
	 * @param {any} content
	 * @param {string} mime
	 * @returns {Blob}
	 * @memberof Core
	 */function le(e,t){return new Blob([e],{type:t})}/**
	 * Create a new blob url
	 * @param {any} content
	 * @param {string} mime
	 * @returns {string} url
	 * @memberof Core
	 */function pe(e,t){var n=le(e,t),r;return r=pn.createObjectURL(n),r}/**
	 * Remove a blob url
	 * @param {string} url
	 * @memberof Core
	 */function ce(e){return pn.revokeObjectURL(e)}/**
	 * Create a new base64 encoded url
	 * @param {any} content
	 * @param {string} mime
	 * @returns {string} url
	 * @memberof Core
	 */function ue(e,t){var n,r;if('string'==typeof e)// Only handles strings
return n=btoa(encodeURIComponent(e)),r='data:'+t+';base64,'+n,r}/**
	 * Get type of an object
	 * @param {object} obj
	 * @returns {string} type
	 * @memberof Core
	 */function he(e){return Object.prototype.toString.call(e).slice(8,-1)}/**
	 * Parse xml (or html) markup
	 * @param {string} markup
	 * @param {string} mime
	 * @param {boolean} forceXMLDom force using xmlDom to parse instead of native parser
	 * @returns {document} document
	 * @memberof Core
	 */function me(e,t,n){var r,a;return a='undefined'==typeof DOMParser||n?rn.DOMParser:DOMParser,65279===e.charCodeAt(0)&&(e=e.slice(1)),r=new a().parseFromString(e,t),r}/**
	 * querySelector polyfill
	 * @param {element} el
	 * @param {string} sel selector string
	 * @returns {element} element
	 * @memberof Core
	 */function fe(e,t){var n;if(!e)throw new Error('No Element Provided');return'undefined'==typeof e.querySelector?(n=e.getElementsByTagName(t),n.length)?n[0]:void 0:e.querySelector(t)}/**
	 * querySelectorAll polyfill
	 * @param {element} el
	 * @param {string} sel selector string
	 * @returns {element[]} elements
	 * @memberof Core
	 */function ge(e,t){return'undefined'==typeof e.querySelector?e.getElementsByTagName(t):e.querySelectorAll(t)}/**
	 * querySelector by property
	 * @param {element} el
	 * @param {string} sel selector string
	 * @param {props[]} props
	 * @returns {element[]} elements
	 * @memberof Core
	 */function _e(e,t,n){var r,a;if('undefined'!=typeof e.querySelector){for(var i in t+='[',n)t+=i+'~=\''+n[i]+'\'';return t+=']',e.querySelector(t)}return(r=e.getElementsByTagName(t),a=Array.prototype.slice.call(r,0).filter(function(e){for(var t in n)if(e.getAttribute(t)===n[t])return!0;return!1}),a)?a[0]:void 0}/**
	 * Sprint through all text nodes in a document
	 * @memberof Core
	 * @param  {element} root element to start with
	 * @param  {function} func function to run on each element
	 */function be(e,t){var n=e.ownerDocument||e;'undefined'==typeof n.createTreeWalker?xe(e,function(e){e&&3===e.nodeType&&t(e)},!0):ye(e,t,NodeFilter.SHOW_TEXT)}function ye(e,t,n){var r=document.createTreeWalker(e,n,null,!1);for(let a;a=r.nextNode();)t(a)}/**
	 * @memberof Core
	 * @param {node} node
	 * @param {callback} return false for continue,true for break inside callback
	 */function xe(e,t){if(t(e))return!0;if(e=e.firstChild,e)do{let n=xe(e,t);if(n)return!0;e=e.nextSibling}while(e)}/**
	 * Convert a blob to a base64 encoded string
	 * @param {Blog} blob
	 * @returns {string}
	 * @memberof Core
	 */function ke(e){return new Promise(function(t){var n=new FileReader;n.readAsDataURL(e),n.onloadend=function(){t(n.result)}})}/**
	 * Creates a new pending promise and provides methods to resolve or reject it.
	 * From: https://developer.mozilla.org/en-US/docs/Mozilla/JavaScript_code_modules/Promise.jsm/Deferred#backwards_forwards_compatible
	 * @memberof Core
	 */function ve(){this.resolve=null,this.reject=null,this.id=te(),this.promise=new Promise((e,t)=>{this.resolve=e,this.reject=t}),Object.freeze(this)}/**
	 * querySelector with filter by epub type
	 * @param {element} html
	 * @param {string} element element type to find
	 * @param {string} type epub type to find
	 * @returns {element[]} elements
	 * @memberof Core
	 */function we(e,t,n){var r;// Handle IE not supporting namespaced epub:type in querySelector
if('undefined'!=typeof e.querySelector&&(r=e.querySelector(`${t}[*|type="${n}"]`)),!r||0===r.length){r=ge(e,t);for(var a=0;a<r.length;a++)if(r[a].getAttributeNS('http://www.idpf.org/2007/ops','type')===n||r[a].getAttribute('epub:type')===n)return r[a]}else return r}/**
	 * Find direct decendents of an element
	 * @param {element} el
	 * @returns {element[]} children
	 * @memberof Core
	 */function Ne(e){for(var t=[],n=e.childNodes,r=0;r<n.length;r++){let e=n[r];1===e.nodeType&&t.push(e)}return t}/**
	 * Find all parents (ancestors) of an element
	 * @param {element} node
	 * @returns {element[]} parents
	 * @memberof Core
	 */function Ce(e){for(var t=[e];e;e=e.parentNode)t.unshift(e);return t}/**
	 * Find all direct decendents of a specific type
	 * @param {element} el
	 * @param {string} nodeName
	 * @param {boolean} [single]
	 * @returns {element[]} children
	 * @memberof Core
	 */function Ee(e,t,n){for(var r=[],a=e.childNodes,s=0;s<a.length;s++){let e=a[s];if(1===e.nodeType&&e.nodeName.toLowerCase()===t){if(n)return e;r.push(e)}}if(!n)return r}/**
	 * Filter all parents (ancestors) with tag name
	 * @param {element} node
	 * @param {string} tagname
	 * @returns {element[]} parents
	 * @memberof Core
	 */function Se(e,t){let n;if(null!==e&&''!==t)for(n=e.parentNode;1===n.nodeType;){if(n.tagName.toLowerCase()===t)return n;n=n.parentNode}}/**
	 * Lightweight Polyfill for DOM Range
	 * @class
	 * @memberof Core
	 */function Ie(e){if('string'!=typeof e)throw new TypeError('Path must be a string. Received '+e)}// Resolves . and .. elements in a path with directory names
function Ae(e,t){for(var n='',r=-1,a=0,s=0,i;s<=e.length;++s){if(s<e.length)i=e.charCodeAt(s);else if(47===i/*/*/)break;else i=47/*/*/;if(47===i/*/*/){if(r===s-1||1==a);else if(r!==s-1&&2==a){if(2>n.length||46!==n.charCodeAt(n.length-1)/*.*/||46!==n.charCodeAt(n.length-2)/*.*/)if(2<n.length){for(var o=n.length-1,d=o;0<=d&&47!==n.charCodeAt(d)/*/*/;--d);if(d!==o){n=-1===d?'':n.slice(0,d),r=s,a=0;continue}}else if(2===n.length||1===n.length){n='',r=s,a=0;continue}t&&(0<n.length?n+='/..':n='..')}else 0<n.length?n+='/'+e.slice(r+1,s):n=e.slice(r+1,s);r=s,a=0}else 46===i/*.*/&&-1!=a?++a:a=-1}return n}function Te(e,t){var n=t.dir||t.root,r=t.base||(t.name||'')+(t.ext||'');return n?n===t.root?n+r:n+e+r:r}function Oe(e,t){var n=t.href,r=-1<n.indexOf('://'),a,i;if(e){// Fix for Safari crashing if the url doesn't have an origin
if(i=fe(e,'head'),a=fe(i,'base'),a||(a=e.createElement('base'),i.insertBefore(a,i.firstChild)),!r&&'undefined'!=typeof window&&window.location){let e=window.location.href.split('/'),t='';e.pop(),t=e.join('/'),n=t+n}a.setAttribute('href',n)}}function ze(e,t){var n=t.canonical||t.href,r,a;e&&(r=fe(e,'head'),a=fe(r,'link[rel=\'canonical\']'),a?a.setAttribute('href',n):(a=e.createElement('link'),a.setAttribute('rel','canonical'),a.setAttribute('href',n),r.appendChild(a)))}function De(e,t){var n=t.idref||t.href,r,a;e&&(r=fe(e,'head'),a=fe(r,'link[property=\'dc.identifier\']'),a?a.setAttribute('content',n):(a=e.createElement('meta'),a.setAttribute('name','dc.identifier'),a.setAttribute('content',n),r.appendChild(a)))}function Re(e,t,n,r){function a(t){d.reject(t)}function i(){if(this.readyState===XMLHttpRequest.DONE){var e=!1;if((''===this.responseType||'document'===this.responseType)&&(e=this.responseXML),200===this.status||e){//-- Firefox is reporting 0 for blob urls
var n;if(!this.response&&!e)return d.reject({status:this.status,message:'Empty Response',stack:new Error().stack}),d.promise;if(403===this.status)return d.reject({status:this.status,response:this.response,message:'Forbidden',stack:new Error().stack}),d.promise;n=e?this.responseXML:de(t)?me(this.response,'text/xml'):'xhtml'==t?me(this.response,'application/xhtml+xml'):'html'==t||'htm'==t?me(this.response,'text/html'):'json'==t?JSON.parse(this.response):'blob'==t?s?this.response:new Blob([this.response]):this.response,d.resolve(n)}else d.reject({status:this.status,message:this.response,stack:new Error().stack})}}var s='undefined'!=typeof window&&window.URL,o=s?'blob':'arraybuffer',d=new ve,l=new XMLHttpRequest,p=XMLHttpRequest.prototype,c;// TODO: fallback for url if window isn't defined
//-- Check from PDF.js:
//   https://github.com/mozilla/pdf.js/blob/master/web/compatibility.js
for(c in'overrideMimeType'in p||Object.defineProperty(p,'overrideMimeType',{value:function(){}}),n&&(l.withCredentials=!0),l.onreadystatechange=i,l.onerror=a,l.open('GET',e,!0),r)l.setRequestHeader(c,r[c]);return'json'==t&&l.setRequestHeader('Accept','application/json'),t||(t=new fn(e).extension),'blob'==t&&(l.responseType=o),de(t)&&l.overrideMimeType('text/xml'),'binary'==t&&(l.responseType='arraybuffer'),l.send(),d.promise}/**
	 * Represents a Section of the Book
	 *
	 * In most books this is equivelent to a Chapter
	 * @param {object} item  The spine item representing the section
	 * @param {object} hooks hooks for serialize and content
	 * @param {object} settings
	 * @param {object} settings.replacements
	 *///"application/octet-stream";
var Be=Math.round,Pe=Math.ceil,Le=Math.floor,Fe=String.fromCharCode,je=String.prototype,Ue=Math.max,Me='undefined'==typeof globalThis?'undefined'==typeof window?'undefined'==typeof global?'undefined'==typeof self?{}:self:global:window:globalThis,We=function(e){return void 0!==e&&null!==e},He={object:!0,function:!0,undefined:!0/* document.all */},Ze=function(e){return!!We(e)&&hasOwnProperty.call(He,typeof e)},qe=function(e){if(!Ze(e))return!1;try{return!!e.constructor&&e.constructor.prototype===e}catch(e){return!1}},Ye=function(e){if('function'!=typeof e)return!1;if(!hasOwnProperty.call(e,'length'))return!1;try{if('number'!=typeof e.length)return!1;if('function'!=typeof e.call)return!1;if('function'!=typeof e.apply)return!1}catch(e){return!1}return!qe(e)},Ge=/^\s*class[\s{/}]/,Xe=Function.prototype.toString,Ve=function(e){return!!Ye(e)&&!Ge.test(Xe.call(e))},Ke=function(){}(),$e=function(e){return e!==Ke&&null!==e},Je=Object.keys,Qe=function(){try{return!0}catch(t){return!1}}()?Object.keys:function(e){return Je($e(e)?Object(e):e)},et=function(e){if(!$e(e))throw new TypeError('Cannot use null or undefined');return e},tt=function(){var e=Object.assign,t;return'function'==typeof e&&(t={foo:'raz'},e(t,{bar:'dwa'},{trzy:'trzy'}),'razdwatrzy'===t.foo+t.bar+t.trzy)}()?Object.assign:function(e,t/*, …srcn*/){var n=Ue(arguments.length,2),r,a,i;for(e=Object(et(e)),i=function(n){try{e[n]=t[n]}catch(t){r||(r=t)}},a=1;a<n;++a)t=arguments[a],Qe(t).forEach(i);if(void 0!==r)throw r;return e},nt=Array.prototype.forEach,rt=Object.create,at=function(e,t){for(var n in e)t[n]=e[n]},it=function()/*, …options*/{var e=rt(null);return nt.call(arguments,function(t){$e(t)&&at(Object(t),e)}),e},st='razdwatrzy',ot=je.indexOf,dt=function(){return'function'==typeof st.contains&&!0===st.contains('dwa')&&!1===st.contains('foo')}()?je.contains:function(e/*, position*/){return-1<ot.call(this,e,arguments[1])},lt=t(function(e){var t=e.exports=function(t,n/*, options*/){var r,a,i,s,o;return 2>arguments.length||'string'!=typeof t?(s=n,n=t,t=null):s=arguments[2],We(t)?(r=dt.call(t,'c'),a=dt.call(t,'e'),i=dt.call(t,'w')):(r=i=!0,a=!1),o={value:n,configurable:r,enumerable:a,writable:i},s?tt(it(s),o):o};t.gs=function(t,n,r/*, options*/){var a,i,s,o;return'string'==typeof t?s=arguments[3]:(s=r,r=n,n=t,t=null),We(n)?Ve(n)?We(r)?!Ve(r)&&(s=r,r=void 0):r=void 0:(s=n,n=r=void 0):n=void 0,We(t)?(a=dt.call(t,'c'),i=dt.call(t,'e')):(a=!0,i=!1),o={get:n,set:r,configurable:a,enumerable:i},s?tt(it(s),o):o}}),pt=function(e){if('function'!=typeof e)throw new TypeError(e+' is not a function');return e},ct=t(function(e,t){var n=Function.prototype.apply,r=Function.prototype.call,a=Object.create,i=Object.defineProperty,s=Object.defineProperties,o=Object.prototype.hasOwnProperty,d={configurable:!0,enumerable:!1,writable:!0},l,p,c,u,h,m,f;l=function(e,t){var n;return pt(t),o.call(this,'__ee__')?n=this.__ee__:(n=d.value=a(null),i(this,'__ee__',d),d.value=null),n[e]?'object'==typeof n[e]?n[e].push(t):n[e]=[n[e],t]:n[e]=t,this},p=function(e,t){var r,a;return pt(t),a=this,l.call(this,e,r=function(){c.call(a,e,r),n.call(t,this,arguments)}),r.__eeOnceListener__=t,this},c=function(e,t){var n,r,a,s;if(pt(t),!o.call(this,'__ee__'))return this;if(n=this.__ee__,!n[e])return this;if(r=n[e],'object'==typeof r)for(s=0;a=r[s];++s)(a===t||a.__eeOnceListener__===t)&&(2===r.length?n[e]=r[s?0:1]:r.splice(s,1));else(r===t||r.__eeOnceListener__===t)&&delete n[e];return this},u=function(e){var t,a,i,s,d;if(o.call(this,'__ee__')&&(s=this.__ee__[e],!!s))if('object'==typeof s){for(a=arguments.length,d=Array(a-1),t=1;t<a;++t)d[t-1]=arguments[t];for(s=s.slice(),t=0;i=s[t];++t)n.call(i,this,d)}else switch(arguments.length){case 1:r.call(s,this);break;case 2:r.call(s,this,arguments[1]);break;case 3:r.call(s,this,arguments[1],arguments[2]);break;default:for(a=arguments.length,d=Array(a-1),t=1;t<a;++t)d[t-1]=arguments[t];n.call(s,this,d);}},h={on:l,once:p,off:c,emit:u},m={on:lt(l),once:lt(p),off:lt(c),emit:lt(u)},f=s({},m),e.exports=t=function(e){return null==e?a(f):s(Object(e),m)},t.methods=h}),ut=ct.methods,ht=/[A-Z_a-z\xC0-\xD6\xD8-\xF6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD]/,mt=new RegExp('[\\-\\.0-9'+ht.source.slice(1,-1)+'\\u00B7\\u0300-\\u036F\\u203F-\\u2040]'),ft=new RegExp('^'+ht.source+mt.source+'*(?::'+ht.source+mt.source+'*)?$'),gt=0,_t=1,bt=2,yt=3,xt=4,kt=5,vt=6,wt=7;// prettier-ignore
// eslint-disable-next-line no-empty-function
// Support ES3 engines
// eslint-disable-next-line no-unused-vars
//[4]   	NameStartChar	   ::=   	":" | [A-Z] | "_" | [a-z] | [#xC0-#xD6] | [#xD8-#xF6] | [#xF8-#x2FF] | [#x370-#x37D] | [#x37F-#x1FFF] | [#x200C-#x200D] | [#x2070-#x218F] | [#x2C00-#x2FEF] | [#x3001-#xD7FF] | [#xF900-#xFDCF] | [#xFDF0-#xFFFD] | [#x10000-#xEFFFF]
//[4a]   	NameChar	   ::=   	NameStartChar | "-" | "." | [0-9] | #xB7 | [#x0300-#x036F] | [#x203F-#x2040]
//[5]   	Name	   ::=   	NameStartChar (NameChar)*
//\u10000-\uEFFFF
//var tagNamePattern = /^[a-zA-Z_][\w\-\.]*(?:\:[a-zA-Z_][\w\-\.]*)?$/
//var handlers = 'resolveEntity,getExternalSubset,characters,endDocument,endElement,endPrefixMapping,ignorableWhitespace,processingInstruction,setDocumentLocator,skippedEntity,startDocument,startElement,startPrefixMapping,notationDecl,unparsedEntityDecl,error,fatalError,warning,attributeDecl,elementDecl,externalEntityDecl,internalEntityDecl,comment,endCDATA,endDTD,endEntity,startCDATA,startDTD,startEntity'.split(',')
//S_TAG,	S_ATTR,	S_EQ,	S_ATTR_NOQUOT_VALUE
//S_ATTR_SPACE,	S_ATTR_END,	S_TAG_SPACE, S_TAG_CLOSE
//tag name offerring
//attr name offerring 
//attr name end and space offer
//=space?
//attr value(no quot value only)
//attr value end and no space(quot end)
//(attr value end || tag end ) && (space offer)
n.prototype={parse:function(e,t,n){var a=this.domBuilder;a.startDocument(),c(t,t={}),r(e,t,n,a,this.errorHandler),a.endDocument()}},m.prototype={setTagName:function(e){if(!ft.test(e))throw new Error('invalid tagName:'+e);this.tagName=e},add:function(e,t,n){if(!ft.test(e))throw new Error('invalid attribute:'+e);this[this.length++]={qName:e,value:t,offset:n}},length:0,getLocalName:function(e){return this[e].localName},getLocator:function(e){return this[e].locator},getQName:function(e){return this[e].qName},getURI:function(e){return this[e].uri},getValue:function(e){return this[e].value}//	,getIndex:function(uri, localName)){
//		if(localName){
//			
//		}else{
//			var qName = uri
//		}
//	},
//	getValue:function(){return this.getValue(this.getIndex.apply(this,arguments))},
//	getType:function(uri,localName){}
//	getType:function(i){},
},a({},a.prototype)instanceof a||(a=function(e,t){function n(){}for(t in n.prototype=t,n=new n,e)n[t]=e[t];return n});var Nt={XMLReader:n},Ct='http://www.w3.org/1999/xhtml',Et={},St=Et.ELEMENT_NODE=1,It=Et.ATTRIBUTE_NODE=2,At=Et.TEXT_NODE=3,Tt=Et.CDATA_SECTION_NODE=4,Ot=Et.ENTITY_REFERENCE_NODE=5,zt=Et.ENTITY_NODE=6,Dt=Et.PROCESSING_INSTRUCTION_NODE=7,Rt=Et.COMMENT_NODE=8,Bt=Et.DOCUMENT_NODE=9,Pt=Et.DOCUMENT_TYPE_NODE=10,Lt=Et.DOCUMENT_FRAGMENT_NODE=11,Ft=Et.NOTATION_NODE=12,jt={},Ut={},Mt=jt.INDEX_SIZE_ERR=(Ut[1]='Index size error',1),Wt=jt.DOMSTRING_SIZE_ERR=(Ut[2]='DOMString size error',2),Ht=jt.HIERARCHY_REQUEST_ERR=(Ut[3]='Hierarchy request error',3),Zt=jt.WRONG_DOCUMENT_ERR=(Ut[4]='Wrong document',4),qt=jt.INVALID_CHARACTER_ERR=(Ut[5]='Invalid character',5),Yt=jt.NO_DATA_ALLOWED_ERR=(Ut[6]='No data allowed',6),Gt=jt.NO_MODIFICATION_ALLOWED_ERR=(Ut[7]='No modification allowed',7),Xt=jt.NOT_FOUND_ERR=(Ut[8]='Not found',8),Vt=jt.NOT_SUPPORTED_ERR=(Ut[9]='Not supported',9),Kt=jt.INUSE_ATTRIBUTE_ERR=(Ut[10]='Attribute in use',10),$t=jt.INVALID_STATE_ERR=(Ut[11]='Invalid state',11),Jt=jt.SYNTAX_ERR=(Ut[12]='Syntax error',12),Qt=jt.INVALID_MODIFICATION_ERR=(Ut[13]='Invalid modification',13),en=jt.NAMESPACE_ERR=(Ut[14]='Invalid namespace',14),tn=jt.INVALID_ACCESS_ERR=(Ut[15]='Invalid access',15);// Node Types
// ExceptionCode
//level2
_.prototype=Error.prototype,f(jt,_),b.prototype={/**
		 * The number of nodes in the list. The range of valid child node indices is 0 to length-1 inclusive.
		 * @standard level1
		 */length:0,/**
		 * Returns the indexth item in the collection. If index is greater than or equal to the number of nodes in the list, this returns null.
		 * @standard level1
		 * @param index  unsigned long 
		 *   Index into the collection.
		 * @return Node
		 * 	The node at the indexth position in the NodeList, or null if that is not a valid index. 
		 */item:function(e){return this[e]||null},toString:function(e,t){for(var n=[],r=0;r<this.length;r++)$(this[r],n,e,t);return n.join('')}},y.prototype.item=function(e){return x(this),this[e]},g(y,b),k.prototype={length:0,item:b.prototype.item,getNamedItem:function(e){for(//		if(key.indexOf(':')>0 || key == 'xmlns'){
//			return null;
//		}
//console.log()
var t=this.length;t--;){var n=this[t];//console.log(attr.nodeName,key)
if(n.nodeName==e)return n}},setNamedItem:function(e){var t=e.ownerElement;if(t&&t!=this._ownerElement)throw new _(Kt);var n=this.getNamedItem(e.nodeName);return w(this._ownerElement,this,e,n),n},/* returns Node */setNamedItemNS:function(e){// raises: WRONG_DOCUMENT_ERR,NO_MODIFICATION_ALLOWED_ERR,INUSE_ATTRIBUTE_ERR
var t=e.ownerElement,n;if(t&&t!=this._ownerElement)throw new _(Kt);return n=this.getNamedItemNS(e.namespaceURI,e.localName),w(this._ownerElement,this,e,n),n},/* returns Node */removeNamedItem:function(e){var t=this.getNamedItem(e);return N(this._ownerElement,this,t),t},// raises: NOT_FOUND_ERR,NO_MODIFICATION_ALLOWED_ERR
//for level2
removeNamedItemNS:function(e,t){var n=this.getNamedItemNS(e,t);return N(this._ownerElement,this,n),n},getNamedItemNS:function(e,t){for(var n=this.length;n--;){var r=this[n];if(r.localName==t&&r.namespaceURI==e)return r}return null}},C.prototype={hasFeature:function(/* string */e,/* string */t){var n=this._features[e.toLowerCase()];return!!(n&&(!t||t in n))},// Introduced in DOM Level 2:
createDocument:function(e,t,n){// raises:INVALID_CHARACTER_ERR,NAMESPACE_ERR,WRONG_DOCUMENT_ERR
var r=new A;if(r.implementation=this,r.childNodes=new b,r.doctype=n,n&&r.appendChild(n),t){var a=r.createElementNS(e,t);r.appendChild(a)}return r},// Introduced in DOM Level 2:
createDocumentType:function(e,t,n){// raises:INVALID_CHARACTER_ERR,NAMESPACE_ERR
var r=new W;// Introduced in DOM Level 2:
//readonly attribute DOMString        internalSubset;
//TODO:..
//  readonly attribute NamedNodeMap     entities;
//  readonly attribute NamedNodeMap     notations;
return r.name=e,r.nodeName=e,r.publicId=t,r.systemId=n,r}},E.prototype={firstChild:null,lastChild:null,previousSibling:null,nextSibling:null,attributes:null,parentNode:null,childNodes:null,ownerDocument:null,nodeValue:null,namespaceURI:null,prefix:null,localName:null,// Modified in DOM Level 2:
insertBefore:function(e,t){//raises 
return R(this,e,t)},replaceChild:function(e,t){this.insertBefore(e,t),t&&this.removeChild(t)},removeChild:function(e){return D(this,e)},appendChild:function(e){return this.insertBefore(e,null)},hasChildNodes:function(){return null!=this.firstChild},cloneNode:function(e){return Q(this.ownerDocument||this,this,e)},// Modified in DOM Level 2:
normalize:function(){for(var e=this.firstChild;e;){var t=e.nextSibling;t&&t.nodeType==At&&e.nodeType==At?(this.removeChild(t),e.appendData(t.data)):(e.normalize(),e=t)}},// Introduced in DOM Level 2:
isSupported:function(e,t){return this.ownerDocument.implementation.hasFeature(e,t)},// Introduced in DOM Level 2:
hasAttributes:function(){return 0<this.attributes.length},lookupPrefix:function(e){for(var t=this;t;){var r=t._nsMap;//console.dir(map)
if(r)for(var a in r)if(r[a]==e)return a;t=t.nodeType==It?t.ownerDocument:t.parentNode}return null},// Introduced in DOM Level 3:
lookupNamespaceURI:function(e){for(var t=this;t;){var n=t._nsMap;//console.dir(map)
if(n&&e in n)return n[e];t=t.nodeType==It?t.ownerDocument:t.parentNode}return null},// Introduced in DOM Level 3:
isDefaultNamespace:function(e){var t=this.lookupPrefix(e);return null==t}},f(Et,E),f(Et,E.prototype),A.prototype={//implementation : null,
nodeName:'#document',nodeType:Bt,doctype:null,documentElement:null,_inc:1,insertBefore:function(e,t){//raises 
if(e.nodeType==Lt){for(var n=e.firstChild,r;n;)r=n.nextSibling,this.insertBefore(n,t),n=r;return e}return null==this.documentElement&&e.nodeType==St&&(this.documentElement=e),R(this,e,t),e.ownerDocument=this,e},removeChild:function(e){return this.documentElement==e&&(this.documentElement=null),D(this,e)},// Introduced in DOM Level 2:
importNode:function(e,t){return J(this,e,t)},// Introduced in DOM Level 2:
getElementById:function(e){var t=null;return I(this.documentElement,function(n){if(n.nodeType==St&&n.getAttribute('id')==e)return t=n,!0}),t},//document factory method:
createElement:function(e){var t=new P;t.ownerDocument=this,t.nodeName=e,t.tagName=e,t.childNodes=new b;var n=t.attributes=new k;return n._ownerElement=t,t},createDocumentFragment:function(){var e=new Y;return e.ownerDocument=this,e.childNodes=new b,e},createTextNode:function(e){var t=new j;return t.ownerDocument=this,t.appendData(e),t},createComment:function(e){var t=new U;return t.ownerDocument=this,t.appendData(e),t},createCDATASection:function(e){var t=new M;return t.ownerDocument=this,t.appendData(e),t},createProcessingInstruction:function(e,t){var n=new G;return n.ownerDocument=this,n.tagName=n.target=e,n.nodeValue=n.data=t,n},createAttribute:function(e){var t=new L;return t.ownerDocument=this,t.name=e,t.nodeName=e,t.localName=e,t.specified=!0,t},createEntityReference:function(e){var t=new q;return t.ownerDocument=this,t.nodeName=e,t},// Introduced in DOM Level 2:
createElementNS:function(e,t){var n=new P,r=t.split(':'),a=n.attributes=new k;return n.childNodes=new b,n.ownerDocument=this,n.nodeName=t,n.tagName=t,n.namespaceURI=e,2==r.length?(n.prefix=r[0],n.localName=r[1]):n.localName=t,a._ownerElement=n,n},// Introduced in DOM Level 2:
createAttributeNS:function(e,t){var n=new L,r=t.split(':');return n.ownerDocument=this,n.nodeName=t,n.name=t,n.namespaceURI=e,n.specified=!0,2==r.length?(n.prefix=r[0],n.localName=r[1]):n.localName=t,n}},g(A,E),P.prototype={nodeType:St,hasAttribute:function(e){return null!=this.getAttributeNode(e)},getAttribute:function(e){var t=this.getAttributeNode(e);return t&&t.value||''},getAttributeNode:function(e){return this.attributes.getNamedItem(e)},setAttribute:function(e,t){var n=this.ownerDocument.createAttribute(e);n.value=n.nodeValue=''+t,this.setAttributeNode(n)},removeAttribute:function(e){var t=this.getAttributeNode(e);t&&this.removeAttributeNode(t)},//four real opeartion method
appendChild:function(e){return e.nodeType===Lt?this.insertBefore(e,null):B(this,e)},setAttributeNode:function(e){return this.attributes.setNamedItem(e)},setAttributeNodeNS:function(e){return this.attributes.setNamedItemNS(e)},removeAttributeNode:function(e){//console.log(this == oldAttr.ownerElement)
return this.attributes.removeNamedItem(e.nodeName)},//get real attribute name,and remove it by removeAttributeNode
removeAttributeNS:function(e,t){var n=this.getAttributeNodeNS(e,t);n&&this.removeAttributeNode(n)},hasAttributeNS:function(e,t){return null!=this.getAttributeNodeNS(e,t)},getAttributeNS:function(e,t){var n=this.getAttributeNodeNS(e,t);return n&&n.value||''},setAttributeNS:function(e,t,n){var r=this.ownerDocument.createAttributeNS(e,t);r.value=r.nodeValue=''+n,this.setAttributeNode(r)},getAttributeNodeNS:function(e,t){return this.attributes.getNamedItemNS(e,t)},getElementsByTagName:function(e){return new y(this,function(t){var n=[];return I(t,function(r){r!==t&&r.nodeType==St&&('*'===e||r.tagName==e)&&n.push(r)}),n})},getElementsByTagNameNS:function(e,t){return new y(this,function(n){var r=[];return I(n,function(a){a!==n&&a.nodeType===St&&('*'===e||a.namespaceURI===e)&&('*'===t||a.localName==t)&&r.push(a)}),r})}},A.prototype.getElementsByTagName=P.prototype.getElementsByTagName,A.prototype.getElementsByTagNameNS=P.prototype.getElementsByTagNameNS,g(P,E),L.prototype.nodeType=It,g(L,E),F.prototype={data:'',substringData:function(e,t){return this.data.substring(e,e+t)},appendData:function(e){e=this.data+e,this.nodeValue=this.data=e,this.length=e.length},insertData:function(e,t){this.replaceData(e,0,t)},appendChild:function(){throw new Error(Ut[Ht])},deleteData:function(e,t){this.replaceData(e,t,'')},replaceData:function(e,t,n){var r=this.data.substring(0,e),a=this.data.substring(e+t);n=r+n+a,this.nodeValue=this.data=n,this.length=n.length}},g(F,E),j.prototype={nodeName:'#text',nodeType:At,splitText:function(e){var t=this.data,n=t.substring(e);t=t.substring(0,e),this.data=this.nodeValue=t,this.length=t.length;var r=this.ownerDocument.createTextNode(n);return this.parentNode&&this.parentNode.insertBefore(r,this.nextSibling),r}},g(j,F),U.prototype={nodeName:'#comment',nodeType:Rt},g(U,F),M.prototype={nodeName:'#cdata-section',nodeType:Tt},g(M,F),W.prototype.nodeType=Pt,g(W,E),H.prototype.nodeType=Ft,g(H,E),Z.prototype.nodeType=zt,g(Z,E),q.prototype.nodeType=Ot,g(q,E),Y.prototype.nodeName='#document-fragment',Y.prototype.nodeType=Lt,g(Y,E),G.prototype.nodeType=Dt,g(G,E),X.prototype.serializeToString=function(e,t,n){return V.call(e,t,n)},E.prototype.toString=V;try{if(Object.defineProperty){function e(t){switch(t.nodeType){case St:case Lt:var n=[];for(t=t.firstChild;t;)7!==t.nodeType&&8!==t.nodeType&&n.push(e(t)),t=t.nextSibling;return n.join('');default:return t.nodeValue;}}Object.defineProperty(y.prototype,'length',{get:function(){return x(this),this.$$length}}),Object.defineProperty(E.prototype,'textContent',{get:function(){return e(this)},set:function(e){switch(this.nodeType){case St:case Lt:for(;this.firstChild;)this.removeChild(this.firstChild);(e||e+'')&&this.appendChild(this.ownerDocument.createTextNode(e));break;default:this.data=e,this.value=e,this.nodeValue=e;}}}),ee=function(e,t,n){e['$$'+t]=n}}}catch(t){}//ie8
//if(typeof require == 'function'){
var nn={DOMImplementation:C,XMLSerializer:X},rn=t(function(e,t){function n(e){this.options=e||{locator:{}}}function r(e,t,n){function r(t){var r=e[t];!r&&o&&(r=2==e.length?function(n){e(t,n)}:e),s[t]=r&&function(e){r('[xmldom '+t+']\t'+e+i(n))}||function(){}}if(!e){if(t instanceof a)return t;e=t}var s={},o=e instanceof Function;return n=n||{},r('warning'),r('error'),r('fatalError'),s}//console.log('#\n\n\n\n\n\n\n####')
/**
	 * +ContentHandler+ErrorHandler
	 * +LexicalHandler+EntityResolver2
	 * -DeclHandler-DTDHandler 
	 * 
	 * DefaultHandler:EntityResolver, DTDHandler, ContentHandler, ErrorHandler
	 * DefaultHandler2:DefaultHandler,LexicalHandler, DeclHandler, EntityResolver2
	 * @link http://www.saxproject.org/apidoc/org/xml/sax/helpers/DefaultHandler.html
	 */function a(){this.cdata=!1}function s(e,t){t.lineNumber=e.lineNumber,t.columnNumber=e.columnNumber}/**
	 * @see org.xml.sax.ContentHandler#startDocument
	 * @link http://www.saxproject.org/apidoc/org/xml/sax/ContentHandler.html
	 */function i(e){if(e)return'\n@'+(e.systemId||'')+'#[line:'+e.lineNumber+',col:'+e.columnNumber+']'}function o(e,t,n){return'string'==typeof e?e.substr(t,n):e.length>=t+n||t?new java.lang.String(e,t,n)+'':e}/*
	 * @link http://www.saxproject.org/apidoc/org/xml/sax/ext/LexicalHandler.html
	 * used method of org.xml.sax.ext.LexicalHandler:
	 *  #comment(chars, start, length)
	 *  #startCDATA()
	 *  #endCDATA()
	 *  #startDTD(name, publicId, systemId)
	 *
	 *
	 * IGNORED method of org.xml.sax.ext.LexicalHandler:
	 *  #endDTD()
	 *  #startEntity(name)
	 *  #endEntity(name)
	 *
	 *
	 * @link http://www.saxproject.org/apidoc/org/xml/sax/ext/DeclHandler.html
	 * IGNORED method of org.xml.sax.ext.DeclHandler
	 * 	#attributeDecl(eName, aName, type, mode, value)
	 *  #elementDecl(name, model)
	 *  #externalEntityDecl(name, publicId, systemId)
	 *  #internalEntityDecl(name, value)
	 * @link http://www.saxproject.org/apidoc/org/xml/sax/ext/EntityResolver2.html
	 * IGNORED method of org.xml.sax.EntityResolver2
	 *  #resolveEntity(String name,String publicId,String baseURI,String systemId)
	 *  #resolveEntity(publicId, systemId)
	 *  #getExternalSubset(name, baseURI)
	 * @link http://www.saxproject.org/apidoc/org/xml/sax/DTDHandler.html
	 * IGNORED method of org.xml.sax.DTDHandler
	 *  #notationDecl(name, publicId, systemId) {};
	 *  #unparsedEntityDecl(name, publicId, systemId, notationName) {};
	 *//* Private static helpers treated below as private instance methods, so don't need to add these to the public API; we might use a Relator to also get rid of non-standard public properties */function d(e,t){e.currentElement?e.currentElement.appendChild(t):e.doc.appendChild(t)}//appendChild and setAttributeNS are preformance key
//if(typeof require == 'function'){
n.prototype.parseFromString=function(e,t){var n=this.options,i=new l,s=n.domBuilder||new a,o=n.errorHandler,d=n.locator,p=n.xmlns||{},c={lt:'<',gt:'>',amp:'&',quot:'"',apos:'\''};//contentHandler and LexicalHandler
return d&&s.setDocumentLocator(d),i.errorHandler=r(o,s,d),i.domBuilder=n.domBuilder||s,/\/x?html?$/.test(t)&&(c.nbsp='\xA0',c.copy='\xA9',p['']='http://www.w3.org/1999/xhtml'),p.xml=p.xml||'http://www.w3.org/XML/1998/namespace',e?i.parse(e,p,c):i.errorHandler.error('invalid doc source'),s.doc},a.prototype={startDocument:function(){this.doc=new p().createDocument(null,null,null),this.locator&&(this.doc.documentURI=this.locator.systemId)},startElement:function(e,t,n,r){var a=this.doc,o=a.createElementNS(e,n||t),l=r.length;d(this,o),this.currentElement=o,this.locator&&s(this.locator,o);for(var p=0;p<l;p++){var e=r.getURI(p),i=r.getValue(p),n=r.getQName(p),c=a.createAttributeNS(e,n);this.locator&&s(r.getLocator(p),c),c.value=c.nodeValue=i,o.setAttributeNode(c)}},endElement:function(){var e=this.currentElement,t=e.tagName;this.currentElement=e.parentNode},startPrefixMapping:function(){},endPrefixMapping:function(){},processingInstruction:function(e,t){var n=this.doc.createProcessingInstruction(e,t);this.locator&&s(this.locator,n),d(this,n)},ignorableWhitespace:function(){},characters:function(e){//console.log(chars)
if(e=o.apply(this,arguments),e){if(this.cdata)var t=this.doc.createCDATASection(e);else var t=this.doc.createTextNode(e);this.currentElement?this.currentElement.appendChild(t):/^\s*$/.test(e)&&this.doc.appendChild(t),this.locator&&s(this.locator,t)}},skippedEntity:function(){},endDocument:function(){this.doc.normalize()},setDocumentLocator:function(e){(this.locator=e)&&(e.lineNumber=0)},//LexicalHandler
comment:function(e){e=o.apply(this,arguments);var t=this.doc.createComment(e);this.locator&&s(this.locator,t),d(this,t)},startCDATA:function(){this.cdata=!0},endCDATA:function(){this.cdata=!1},startDTD:function(e,t,n){var r=this.doc.implementation;if(r&&r.createDocumentType){var a=r.createDocumentType(e,t,n);this.locator&&s(this.locator,a),d(this,a)}},/**
		 * @see org.xml.sax.ErrorHandler
		 * @link http://www.saxproject.org/apidoc/org/xml/sax/ErrorHandler.html
		 */warning:function(e){console.warn('[xmldom warning]\t'+e,i(this.locator))},error:function(e){console.error('[xmldom error]\t'+e,i(this.locator))},fatalError:function(e){throw console.error('[xmldom fatalError]\t'+e,i(this.locator)),e}},'endDTD,startEntity,endEntity,attributeDecl,elementDecl,externalEntityDecl,internalEntityDecl,resolveEntity,getExternalSubset,notationDecl,unparsedEntityDecl'.replace(/\w+/g,function(e){a.prototype[e]=function(){return null}});var l=Nt.XMLReader,p=t.DOMImplementation=nn.DOMImplementation;t.XMLSerializer=nn.XMLSerializer,t.DOMParser=n}//}
),an=rn.DOMImplementation,sn=rn.XMLSerializer,on=rn.DOMParser;//}
/**
	 * Core Utilities and Helpers
	 * @module Core
	*//**
	 * Vendor prefixed requestAnimationFrame
	 * @returns {function} requestAnimationFrame
	 * @memberof Core
	 */const dn='undefined'!=typeof window&&(window.requestAnimationFrame||window.mozRequestAnimationFrame||window.webkitRequestAnimationFrame||window.msRequestAnimationFrame),ln=1,pn='undefined'==typeof URL?'undefined'==typeof window?void 0:window.URL||window.webkitURL||window.mozURL:URL;class cn{constructor(){this.collapsed=!1,this.commonAncestorContainer=void 0,this.endContainer=void 0,this.endOffset=void 0,this.startContainer=void 0,this.startOffset=void 0}setStart(e,t){this.startContainer=e,this.startOffset=t,this.endContainer?this.commonAncestorContainer=this._commonAncestorContainer():this.collapse(!0),this._checkCollapsed()}setEnd(e,t){this.endContainer=e,this.endOffset=t,this.startContainer?(this.collapsed=!1,this.commonAncestorContainer=this._commonAncestorContainer()):this.collapse(!1),this._checkCollapsed()}collapse(e){this.collapsed=!0,e?(this.endContainer=this.startContainer,this.endOffset=this.startOffset,this.commonAncestorContainer=this.startContainer.parentNode):(this.startContainer=this.endContainer,this.startOffset=this.endOffset,this.commonAncestorContainer=this.endOffset.parentNode)}selectNode(e){let t=e.parentNode,n=Array.prototype.indexOf.call(t.childNodes,e);this.setStart(t,n),this.setEnd(t,n+1)}selectNodeContents(e){// let end = referenceNode.childNodes[referenceNode.childNodes - 1];
let t=3===e.nodeType?e.textContent.length:parent.childNodes.length;this.setStart(e,0),this.setEnd(e,t)}_commonAncestorContainer(e,t){var n=Ce(e||this.startContainer),r=Ce(t||this.endContainer);if(n[0]==r[0])for(var a=0;a<n.length;a++)if(n[a]!=r[a])return n[a-1]}_checkCollapsed(){this.collapsed=!(this.startContainer!==this.endContainer||this.startOffset!==this.endOffset)}toString(){// TODO: implement walking between start and end to find text
}}if(!un)var un={cwd:function(){return'/'}};var hn={// path.resolve([from ...], to)
resolve:function(){for(var e='',t=!1,n=arguments.length-1,r;-1<=n&&!t;n--){var a;(0<=n?a=arguments[n]:(void 0===r&&(r=un.cwd()),a=r),Ie(a),0!==a.length)&&(e=a+'/'+e,t=47===a.charCodeAt(0)/*/*/)}// At this point the path should be resolved to a full absolute path, but
// handle relative paths to be safe (might happen when process.cwd() fails)
// Normalize the path
return e=Ae(e,!t),t?0<e.length?'/'+e:'/':0<e.length?e:'.'},normalize:function(e){if(Ie(e),0===e.length)return'.';var t=47===e.charCodeAt(0)/*/*/,n=47===e.charCodeAt(e.length-1)/*/*/;// Normalize the path
return e=Ae(e,!t),0!==e.length||t||(e='.'),0<e.length&&n&&(e+='/'),t?'/'+e:e},isAbsolute:function(e){return Ie(e),0<e.length&&47===e.charCodeAt(0)/*/*/},join:function(){if(0===arguments.length)return'.';for(var e=0,t,n;e<arguments.length;++e)n=arguments[e],Ie(n),0<n.length&&(void 0===t?t=n:t+='/'+n);return void 0===t?'.':hn.normalize(t)},relative:function(e,t){if(Ie(e),Ie(t),e===t)return'';if(e=hn.resolve(e),t=hn.resolve(t),e===t)return'';// Trim any leading backslashes
for(var n=1;n<e.length&&47===e.charCodeAt(n)/*/*/;++n);// Trim any leading backslashes
for(var r=e.length,a=r-n,s=1;s<t.length&&47===t.charCodeAt(s)/*/*/;++s);// Compare paths to find the longest common path from root
for(var o=t.length,d=o-s,l=a<d?a:d,p=-1,c=0;c<=l;++c){if(c===l){if(d>l){if(47===t.charCodeAt(s+c)/*/*/)// We get here if `from` is the exact base path for `to`.
// For example: from='/foo/bar'; to='/foo/bar/baz'
return t.slice(s+c+1);if(0==c)// We get here if `from` is the root
// For example: from='/'; to='/foo'
return t.slice(s+c)}else a>l&&(47===e.charCodeAt(n+c)/*/*/?p=c:0===c&&(p=0));break}var i=e.charCodeAt(n+c),u=t.charCodeAt(s+c);if(i!==u)break;else 47===i/*/*/&&(p=c)}var h='';// Generate the relative path based on the path difference between `to`
// and `from`
for(c=n+p+1;c<=r;++c)(c===r||47===e.charCodeAt(c)/*/*/)&&(h+=0===h.length?'..':'/..');// Lastly, append the rest of the destination (`to`) path that comes after
// the common path parts
return 0<h.length?h+t.slice(s+p):(s+=p,47===t.charCodeAt(s)/*/*/&&++s,t.slice(s))},_makeLong:function(e){return e},dirname:function(e){if(Ie(e),0===e.length)return'.';for(var t=e.charCodeAt(0),n=47===t/*/*/,r=-1,a=!0,s=e.length-1;1<=s;--s)if(t=e.charCodeAt(s),47!==t/*/*/)a=!1;else if(!a){r=s;break}return-1===r?n?'/':'.':n&&1===r?'//':e.slice(0,r)},basename:function(e,t){if(t!==void 0&&'string'!=typeof t)throw new TypeError('"ext" argument must be a string');Ie(e);var n=0,r=-1,a=!0,s;if(void 0!==t&&0<t.length&&t.length<=e.length){if(t.length===e.length&&t===e)return'';var i=t.length-1,o=-1;for(s=e.length-1;0<=s;--s){var d=e.charCodeAt(s);if(47!==d/*/*/)-1==o&&(a=!1,o=s+1),0<=i&&(d===t.charCodeAt(i)?-1==--i&&(r=s):(i=-1,r=o));else// If we reached a path separator that was not part of a set of path
// separators at the end of the string, stop now
if(!a){n=s+1;break}}return n===r?r=o:-1===r&&(r=e.length),e.slice(n,r)}for(s=e.length-1;0<=s;--s)if(47!==e.charCodeAt(s)/*/*/)-1===r&&(a=!1,r=s+1);else// If we reached a path separator that was not part of a set of path
// separators at the end of the string, stop now
if(!a){n=s+1;break}return-1===r?'':e.slice(n,r)},extname:function(e){Ie(e);// Track the state of characters (if any) we see before our first dot and
// after any path separator we find
for(var t=-1,n=0,r=-1,a=!0,s=0,o=e.length-1,i;0<=o;--o){if(i=e.charCodeAt(o),47===i/*/*/){// If we reached a path separator that was not part of a set of path
// separators at the end of the string, stop now
if(!a){n=o+1;break}continue}-1==r&&(a=!1,r=o+1),46===i/*.*/?-1===t?t=o:1!=s&&(s=1):-1!==t&&(s=-1)}return-1===t||-1===r||// We saw a non-dot character immediately before the dot
0==s||// The (right-most) trimmed path component is exactly '..'
1==s&&t===r-1&&t===n+1?'':e.slice(t,r)},format:function(e){if(null===e||'object'!=typeof e)throw new TypeError('Parameter "pathObject" must be an object, not '+typeof e);return Te('/',e)},parse:function(e){Ie(e);var t={root:'',dir:'',base:'',ext:'',name:''};if(0===e.length)return t;var n=e.charCodeAt(0),r=47===n/*/*/,a;r?(t.root='/',a=1):a=0;// Get non-dir info
// Track the state of characters (if any) we see before our first dot and
// after any path separator we find
for(var s=-1,o=0,d=-1,l=!0,p=e.length-1,i=0;p>=a;--p){if(n=e.charCodeAt(p),47===n/*/*/){// If we reached a path separator that was not part of a set of path
// separators at the end of the string, stop now
if(!l){o=p+1;break}continue}-1==d&&(l=!1,d=p+1),46===n/*.*/?-1==s?s=p:1!=i&&(i=1):-1!=s&&(i=-1)}return-1==s||-1==d||// We saw a non-dot character immediately before the dot
0==i||// The (right-most) trimmed path component is exactly '..'
1==i&&s==d-1&&s==o+1?-1!=d&&(0==o&&r?t.base=t.name=e.slice(1,d):t.base=t.name=e.slice(o,d)):(0==o&&r?(t.name=e.slice(1,s),t.base=e.slice(1,d)):(t.name=e.slice(o,s),t.base=e.slice(o,d)),t.ext=e.slice(s,d)),0<o?t.dir=e.slice(0,o-1):r&&(t.dir='/'),t},sep:'/',delimiter:':',posix:null},mn=hn;/**
	 * Creates a Path object for parsing and manipulation of a path strings
	 *
	 * Uses a polyfill for Nodejs path: https://nodejs.org/api/path.html
	 * @param	{string} pathString	a url string (relative or absolute)
	 * @class
	 */class fn{constructor(e){var t,n;t=e.indexOf('://'),-1<t&&(e=new URL(e).pathname),n=this.parse(e),this.path=e,this.directory=this.isDirectory(e)?e:n.dir+'/',this.filename=n.base,this.extension=n.ext.slice(1)}/**
	  * Parse the path: https://nodejs.org/api/path.html#path_path_parse_path
	  * @param	{string} what
	  * @returns {object}
	  */parse(e){return mn.parse(e)}/**
	  * @param	{string} what
	  * @returns {boolean}
	  */isAbsolute(e){return mn.isAbsolute(e||this.path)}/**
	  * Check if path ends with a directory
	  * @param	{string} what
	  * @returns {boolean}
	  */isDirectory(e){return'/'===e.charAt(e.length-1)}/**
	  * Resolve a path against the directory of the Path
	  *
	  * https://nodejs.org/api/path.html#path_path_resolve_paths
	  * @param	{string} what
	  * @returns {string} resolved
	  */resolve(e){return mn.resolve(this.directory,e)}/**
	  * Resolve a path relative to the directory of the Path
	  *
	  * https://nodejs.org/api/path.html#path_path_relative_from_to
	  * @param	{string} what
	  * @returns {string} relative
	  */relative(e){return mn.relative(this.directory,e)}splitPath(e){return this.splitPathRe.exec(e).slice(1)}/**
	  * Return the path string
	  * @returns {string} path
	  */toString(){return this.path}}/**
	 * creates a Url object for parsing and manipulation of a url string
	 * @param	{string} urlString	a url string (relative or absolute)
	 * @param	{string} [baseString] optional base for the url,
	 * default to window.location.href
	 */class gn{constructor(e,t){var n=-1<e.indexOf('://'),r=e,a;// URL Polyfill doesn't throw an error if base is empty
if(this.Url=void 0,this.href=e,this.protocol='',this.origin='',this.hash='',this.hash='',this.search='',this.base=t,n||!1===t||'string'==typeof t||'undefined'==typeof window||'undefined'==typeof window.location||(this.base=window.location.href),n||this.base)try{this.Url=this.base?new URL(e,this.base):new URL(e),this.href=this.Url.href,this.protocol=this.Url.protocol,this.origin=this.Url.origin,this.hash=this.Url.hash,this.search=this.Url.search,r=this.Url.pathname}catch(t){this.Url=void 0,this.base&&(a=new fn(this.base),r=a.resolve(r))}this.Path=new fn(r),this.directory=this.Path.directory,this.filename=this.Path.filename,this.extension=this.Path.extension}/**
	  * @returns {Path}
	  */path(){return this.Path}/**
	  * Resolves a relative path to a absolute url
	  * @returns {string} url
	  */resolve(e){var t=-1<e.indexOf('://'),n;return t?e:(n=mn.resolve(this.directory,e),this.origin+n)}/**
	  * Resolve a path relative to the url
	  * @returns {string} path
	  */relative(e){return mn.relative(e,this.directory)}/**
	  * @returns {string}
	  */toString(){return this.href}}const _n=1,bn=3;// const COMMENT_NODE = 8;
/**
		* Parsing and creation of EpubCFIs: http://www.idpf.org/epub/linking/cfi/epub-cfi.html

		* Implements:
		* - Character Offset: epubcfi(/6/4[chap01ref]!/4[body01]/10[para05]/2/1:3)
		* - Simple Ranges : epubcfi(/6/4[chap01ref]!/4[body01]/10[para05],/2/1:1,/3:4)

		* Does Not Implement:
		* - Temporal Offset (~)
		* - Spatial Offset (@)
		* - Temporal-Spatial Offset (~ + @)
		* - Text Location Assertion ([)
		* @class
		@param {string | Range | Node } [cfiFrom]
		@param {string | object} [base]
		@param {string} [ignoreClass] class to ignore when parsing DOM
	*/class yn{constructor(e,t,n){var r;// Allow instantiation without the "new" keyword
if(this.str='',this.base={},this.spinePos=0,this.range=!1,this.path={},this.start=null,this.end=null,!(this instanceof yn))return new yn(e,t,n);if('string'==typeof t?this.base=this.parseComponent(t):'object'==typeof t&&t.steps&&(this.base=t),r=this.checkType(e),'string'===r)return this.str=e,re(this,this.parse(e));if('range'===r)return re(this,this.fromRange(e,this.base,n));if('node'===r)return re(this,this.fromNode(e,this.base,n));if('EpubCFI'===r&&e.path)return e;if(!e)return this;throw new TypeError('not a valid argument for EpubCFI')}/**
	  * Check the type of constructor input
	  * @private
	  */checkType(e){return this.isCfiString(e)?'string':'object'==typeof e&&('Range'===he(e)||'undefined'!=typeof e.startContainer)?'range':'object'==typeof e&&'undefined'!=typeof e.nodeType?'node':!!('object'==typeof e&&e instanceof yn)&&'EpubCFI'}/**
	  * Parse a cfi string to a CFI object representation
	  * @param {string} cfiStr
	  * @returns {object} cfi
	  */parse(e){var t={spinePos:-1,range:!1,base:{},path:{},start:null,end:null},n,r,a;// Get spine node position
// cfi.spineSegment = cfi.base.steps[1];
// Chapter segment is always the second step
return'string'==typeof e?(0===e.indexOf('epubcfi(')&&')'===e[e.length-1]&&(e=e.slice(8,e.length-1)),n=this.getChapterComponent(e),!n)?{spinePos:-1}:(t.base=this.parseComponent(n),r=this.getPathComponent(e),t.path=this.parseComponent(r),a=this.getRange(e),a&&(t.range=!0,t.start=this.parseComponent(a[0]),t.end=this.parseComponent(a[1])),!t.base.steps||2>t.base.steps.length)?{spinePos:-1}:(t.spinePos=t.base.steps[1].index,t):{spinePos:-1};// Make sure this is a valid cfi or return
}parseComponent(e){var t={steps:[],terminal:{offset:null,assertion:null}},n=e.split(':'),r=n[0].split('/'),a;return 1<n.length&&(a=n[1],t.terminal=this.parseTerminal(a)),''===r[0]&&r.shift(),t.steps=r.map(function(e){return this.parseStep(e)}.bind(this)),t}parseStep(e){var t,n,r,a,i;if(a=e.match(/\[(.*)\]/),a&&a[1]&&(i=a[1]),n=parseInt(e),!isNaN(n))return 0==n%2?(t='element',r=n/2-1):(t='text',r=(n-1)/2),{type:t,index:r,id:i||null}}parseTerminal(e){var t=e.match(/\[(.*)\]/),n,r;return t&&t[1]?(n=parseInt(e.split('[')[0]),r=t[1]):n=parseInt(e),ne(n)||(n=null),{offset:n,assertion:r}}getChapterComponent(e){var t=e.split('!');return t[0]}getPathComponent(e){var t=e.split('!');if(t[1]){let e=t[1].split(',');return e[0]}}getRange(e){var t=e.split(',');return!(3!==t.length)&&[t[1],t[2]]}getCharecterOffsetComponent(e){var t=e.split(':');return t[1]||''}joinSteps(e){return e?e.map(function(e){var t='';return'element'===e.type&&(t+=2*(e.index+1)),'text'===e.type&&(t+=1+2*e.index),e.id&&(t+='['+e.id+']'),t}).join('/'):''}segmentString(e){var t='/';return t+=this.joinSteps(e.steps),e.terminal&&null!=e.terminal.offset&&(t+=':'+e.terminal.offset),e.terminal&&null!=e.terminal.assertion&&(t+='['+e.terminal.assertion+']'),t}/**
	  * Convert CFI to a epubcfi(...) string
	  * @returns {string} epubcfi
	  */toString(){var e='epubcfi(';return e+=this.segmentString(this.base),e+='!',e+=this.segmentString(this.path),this.range&&this.start&&(e+=',',e+=this.segmentString(this.start)),this.range&&this.end&&(e+=',',e+=this.segmentString(this.end)),e+=')',e}/**
	  * Compare which of two CFIs is earlier in the text
	  * @returns {number} First is earlier = 1, Second is earlier = -1, They are equal = 0
	  */compare(e,t){var n,r,a,s;// Compare Spine Positions
if('string'==typeof e&&(e=new yn(e)),'string'==typeof t&&(t=new yn(t)),e.spinePos>t.spinePos)return 1;if(e.spinePos<t.spinePos)return-1;e.range?(n=e.path.steps.concat(e.start.steps),a=e.start.terminal):(n=e.path.steps,a=e.path.terminal),t.range?(r=t.path.steps.concat(t.start.steps),s=t.start.terminal):(r=t.path.steps,s=t.path.terminal);// Compare Each Step in the First item
for(var o=0;o<n.length;o++){if(!n[o])return-1;if(!r[o])return 1;if(n[o].index>r[o].index)return 1;if(n[o].index<r[o].index)return-1;// Otherwise continue checking
}// All steps in First equal to Second and First is Less Specific
return n.length<r.length?1:a.offset>s.offset?1:a.offset<s.offset?-1:0;// Compare the charecter offset of the text node
// CFI's are equal
}step(e){var t=e.nodeType===bn?'text':'element';return{id:e.id,tagName:e.tagName,type:t,index:this.position(e)}}filteredStep(e,t){var n=this.filter(e,t),r;// Node filtered, so ignore
if(n)return r=n.nodeType===bn?'text':'element',{id:n.id,tagName:n.tagName,type:r,index:this.filteredPosition(n,t)};// Otherwise add the filter node in
}pathTo(e,t,n){for(var r={steps:[],terminal:{offset:null,assertion:null}},a=e,i;a&&a.parentNode&&a.parentNode.nodeType!=9;)i=n?this.filteredStep(a,n):this.step(a),i&&r.steps.unshift(i),a=a.parentNode;return null!=t&&0<=t&&(r.terminal.offset=t,'text'!=r.steps[r.steps.length-1].type&&r.steps.push({type:'text',index:0})),r}equalStep(e,t){return!!(e&&t)&&!(e.index!==t.index||e.id!==t.id||e.type!==t.type)}/**
	  * Create a CFI object from a Range
	  * @param {Range} range
	  * @param {string | object} base
	  * @param {string} [ignoreClass]
	  * @returns {object} cfi
	  */fromRange(e,t,n){var r={range:!1,base:{},path:{},start:null,end:null},a=e.startContainer,s=e.endContainer,o=e.startOffset,d=e.endOffset,l=!1;if(n&&(l=null!=a.ownerDocument.querySelector('.'+n)),'string'==typeof t?(r.base=this.parseComponent(t),r.spinePos=r.base.steps[1].index):'object'==typeof t&&(r.base=t),e.collapsed)l&&(o=this.patchOffset(a,o,n)),r.path=this.pathTo(a,o,n);else{r.range=!0,l&&(o=this.patchOffset(a,o,n)),r.start=this.pathTo(a,o,n),l&&(d=this.patchOffset(s,d,n)),r.end=this.pathTo(s,d,n),r.path={steps:[],terminal:null};// Push steps that are shared between start and end to the common path
var p=r.start.steps.length,c;for(c=0;c<p&&this.equalStep(r.start.steps[c],r.end.steps[c]);c++)c===p-1?r.start.terminal===r.end.terminal&&(r.path.steps.push(r.start.steps[c]),r.range=!1):r.path.steps.push(r.start.steps[c]);r.start.steps=r.start.steps.slice(r.path.steps.length),r.end.steps=r.end.steps.slice(r.path.steps.length)}return r}/**
	  * Create a CFI object from a Node
	  * @param {Node} anchor
	  * @param {string | object} base
	  * @param {string} [ignoreClass]
	  * @returns {object} cfi
	  */fromNode(e,t,n){var r={range:!1,base:{},path:{},start:null,end:null};return'string'==typeof t?(r.base=this.parseComponent(t),r.spinePos=r.base.steps[1].index):'object'==typeof t&&(r.base=t),r.path=this.pathTo(e,null,n),r}filter(e,t){var n=!1,r,a,i,s,o;// to join with
return e.nodeType===bn?(n=!0,i=e.parentNode,r=e.parentNode.classList.contains(t)):(n=!1,r=e.classList.contains(t)),r&&n?(s=i.previousSibling,o=i.nextSibling,s&&s.nodeType===bn?a=s:o&&o.nodeType===bn&&(a=o),a?a:e):(!r||n)&&e}patchOffset(e,t,n){if(e.nodeType!=bn)throw new Error('Anchor must be a text node');var r=e,a=t;// If the parent is a ignored node, get offset from it's start
for(e.parentNode.classList.contains(n)&&(r=e.parentNode);r.previousSibling;){if(!(r.previousSibling.nodeType===_n))a+=r.previousSibling.textContent.length;else// Originally a text node, so join
if(r.previousSibling.classList.contains(n))a+=r.previousSibling.textContent.length;else break;// Normal node, dont join
r=r.previousSibling}return a}normalizedMap(e,t,n){var r={},a=-1,s=e.length,o,i,d;for(o=0;o<s;o++)i=e[o].nodeType,i===_n&&e[o].classList.contains(n)&&(i=bn),0<o&&i===bn&&d===bn?r[o]=a:t===i&&(++a,r[o]=a),d=i;return r}position(e){var t,n;return e.nodeType===_n?(t=e.parentNode.children,!t&&(t=Ne(e.parentNode)),n=Array.prototype.indexOf.call(t,e)):(t=this.textNodes(e.parentNode),n=t.indexOf(e)),n}filteredPosition(e,t){var n,r,a;return e.nodeType===_n?(n=e.parentNode.children,a=this.normalizedMap(n,_n,t)):(n=e.parentNode.childNodes,e.parentNode.classList.contains(t)&&(e=e.parentNode,n=e.parentNode.childNodes),a=this.normalizedMap(n,bn,t)),r=Array.prototype.indexOf.call(n,e),a[r]}stepsToXpath(e){var t=['.','*'];return e.forEach(function(e){var n=e.index+1;e.id?t.push('*[position()='+n+' and @id=\''+e.id+'\']'):'text'===e.type?t.push('text()['+n+']'):t.push('*['+n+']')}),t.join('/')}/*
	 	To get the last step if needed:
	 	// Get the terminal step
	 lastStep = steps[steps.length-1];
	 // Get the query string
	 query = this.stepsToQuery(steps);
	 // Find the containing element
	 startContainerParent = doc.querySelector(query);
	 // Find the text node within that element
	 if(startContainerParent && lastStep.type == "text") {
	 	container = startContainerParent.childNodes[lastStep.index];
	 }
	 */stepsToQuerySelector(e){var t=['html'];return e.forEach(function(e){var n=e.index+1;e.id?t.push('#'+e.id):'text'===e.type||t.push('*:nth-child('+n+')')}),t.join('>')}textNodes(e,t){return Array.prototype.slice.call(e.childNodes).filter(function(e){if(e.nodeType===bn)return!0;return!!(t&&e.classList.contains(t))})}walkToNode(e,t,n){var r=t||document,a=r.documentElement,s=e.length,o,d,l;for(l=0;l<s&&(d=e[l],'element'===d.type?d.id?a=r.getElementById(d.id):(o=a.children||Ne(a),a=o[d.index]):'text'===d.type&&(a=this.textNodes(a,n)[d.index]),!!a);l++);return a}findNode(e,t,n){var r=t||document,a,i;return n||'undefined'==typeof r.evaluate?n?a=this.walkToNode(e,r,n):a=this.walkToNode(e,r):(i=this.stepsToXpath(e),a=r.evaluate(i,r,null,XPathResult.FIRST_ORDERED_NODE_TYPE,null).singleNodeValue),a}fixMiss(e,t,n,r){var a=this.findNode(e.slice(0,-1),n,r),i=a.childNodes,s=this.normalizedMap(i,bn,r),o=e[e.length-1].index,d,l;for(let p in s){if(!s.hasOwnProperty(p))return;if(s[p]===o)if(d=i[p],l=d.textContent.length,t>l)t-=l;else{a=d.nodeType===_n?d.childNodes[0]:d;break}}return{container:a,offset:t}}/**
	  * Creates a DOM range representing a CFI
	  * @param {document} _doc document referenced in the base
	  * @param {string} [ignoreClass]
	  * @return {Range}
	  */toRange(e,t){var n=e||document,r=this,a=!!t&&null!=n.querySelector('.'+t),i,s,o,d,l,p,c,u;if(i='undefined'==typeof n.createRange?new cn:n.createRange(),r.range?(s=r.start,p=r.path.steps.concat(s.steps),d=this.findNode(p,n,a?t:null),o=r.end,c=r.path.steps.concat(o.steps),l=this.findNode(c,n,a?t:null)):(s=r.path,p=r.path.steps,d=this.findNode(r.path.steps,n,a?t:null)),d)try{null==s.terminal.offset?i.setStart(d,0):i.setStart(d,s.terminal.offset)}catch(r){u=this.fixMiss(p,s.terminal.offset,n,a?t:null),i.setStart(u.container,u.offset)}else// No start found
return console.log('No startContainer found for',this.toString()),null;if(l)try{null==o.terminal.offset?i.setEnd(l,0):i.setEnd(l,o.terminal.offset)}catch(s){u=this.fixMiss(c,r.end.terminal.offset,n,a?t:null),i.setEnd(u.container,u.offset)}// doc.defaultView.getSelection().addRange(range);
return i}/**
	  * Check if a string is wrapped with "epubcfi()"
	  * @param {string} str
	  * @returns {boolean}
	  */isCfiString(e){return!('string'!=typeof e||0!==e.indexOf('epubcfi(')||')'!==e[e.length-1])}generateChapterComponent(e,t,n){var r=parseInt(t),a='/'+2*(e+1)+'/';return a+=2*(r+1),n&&(a+='['+n+']'),a}/**
	  * Collapse a CFI Range to a single CFI Position
	  * @param {boolean} [toStart=false]
	  */collapse(e){this.range&&(this.range=!1,e?(this.path.steps=this.path.steps.concat(this.start.steps),this.path.terminal=this.start.terminal):(this.path.steps=this.path.steps.concat(this.end.steps),this.path.terminal=this.end.terminal))}}/**
	 * Hooks allow for injecting functions that must all complete in order before finishing
	 * They will execute in parallel but all must finish before continuing
	 * Functions may return a promise if they are asycn.
	 * @param {any} context scope of this
	 * @example this.content = new EPUBJS.Hook(this);
	 */class xn{constructor(e){this.context=e||this,this.hooks=[]}/**
	  * Adds a function to be run before a hook completes
	  * @example this.content.register(function(){...});
	  */register(){for(var e=0;e<arguments.length;++e)if('function'==typeof arguments[e])this.hooks.push(arguments[e]);else// unpack array
for(var t=0;t<arguments[e].length;++t)this.hooks.push(arguments[e][t])}/**
	  * Triggers a hook to run all functions
	  * @example this.content.trigger(args).then(function(){...});
	  */trigger(){var e=arguments,t=this.context,n=[];return this.hooks.forEach(function(r){var a=r.apply(t,e);a&&'function'==typeof a.then&&n.push(a)}// Otherwise Task resolves immediately, continue
),Promise.all(n)}// Adds a function to be run before a hook completes
list(){return this.hooks}clear(){return this.hooks=[]}}class kn{constructor(e,t,n){this.item=e,this.idref=e.idref,this.linear='yes'===e.linear,this.properties=e.properties,this.index=e.index,this.href=e.href,this.source=e.source,this.canonical=e.canonical,this.type=e.type,this.next=e.next,this.prev=e.prev,this.cfiBase=e.cfiBase,t?this.hooks=t:(this.hooks={},this.hooks.serialize=new xn(this),this.hooks.content=new xn(this)),this.document=void 0,this.contents=void 0,this.output=void 0,this.originalHref=void 0,this.settings=n||{}}/**
	  * Load the section from its url
	  * @param  {method} _request a request method to use for loading
	  * @return {document} a promise with the xml document
	  */load(e){var t=e||this.request||Re,n=new ve,r=n.promise;if(this.contents)n.resolve(this.contents);else{let e='application/xhtml+xml'===this.type?'xhtml':'html';t(this.href,e).then(function(e){return this.document=e,this.contents=e.documentElement,this.hooks.content.trigger(this.document,this)}.bind(this)).then(function(){n.resolve(this.contents)}.bind(this)).catch(function(e){n.reject(e)})}return r}/**
	  * Adds a base tag for resolving urls in the section
	  * @private
	  */base(){return Oe(this.document,this)}/**
	  * Render the contents of a section
	  * @param  {method} _request a request method to use for loading
	  * @return {string} output a serialized XML Document
	  */render(e){var t=new ve,n=t.promise;return this.output,this.load(e).then(function(e){var t='undefined'!=typeof navigator&&navigator.userAgent||'',n=0<=t.indexOf('Trident'),r;r='undefined'==typeof XMLSerializer||n?rn.XMLSerializer:XMLSerializer;var a=new r;return this.output=a.serializeToString(e),this.output}.bind(this)).then(function(){return this.hooks.serialize.trigger(this.output,this)}.bind(this)).then(function(){t.resolve(this.output)}.bind(this)).catch(function(e){t.reject(e)}),n}/**
	  * Find a string in a section
	  * @param  {string} _query The query string to find
	  * @return {object[]} A list of matches, with form {cfi, excerpt}
	  */find(e){var t=this,n=[],r=e.toLowerCase(),a=function(e){for(var a=e.textContent.toLowerCase(),i=t.document.createRange(),s=-1,o=150,d,l,p;-1!=l;)l=a.indexOf(r,s+1),-1!=l&&(i=t.document.createRange(),i.setStart(e,l),i.setEnd(e,l+r.length),d=t.cfiFromRange(i),e.textContent.length<o?p=e.textContent:(p=e.textContent.substring(l-o/2,l+o/2),p='...'+p+'...'),n.push({cfi:d,excerpt:p})),s=l};return be(t.document,function(e){a(e)}),n}/**
	 * Reconciles the current chapters layout properties with
	 * the global layout properties.
	 * @param {object} global  The globa layout settings object, chapter properties string
	 * @return {object} layoutProperties Object with layout properties
	 */reconcileLayoutSettings(e){//-- Get the global defaults
var t={layout:e.layout,spread:e.spread,orientation:e.orientation};//-- Get the chapter's display type
return this.properties.forEach(function(e){var n=e.replace('rendition:',''),r=n.indexOf('-'),a,i;-1!=r&&(a=n.slice(0,r),i=n.slice(r+1),t[a]=i)}),t}/**
	  * Get a CFI from a Range in the Section
	  * @param  {range} _range
	  * @return {string} cfi an EpubCFI string
	  */cfiFromRange(e){return new yn(e,this.cfiBase).toString()}/**
	  * Get a CFI from an Element in the Section
	  * @param  {element} el
	  * @return {string} cfi an EpubCFI string
	  */cfiFromElement(e){return new yn(e,this.cfiBase).toString()}/**
	  * Unload the section document
	  */unload(){this.document=void 0,this.contents=void 0,this.output=void 0}/**
	  * Return an object representation of the item
	  * @return {object}
	  */toObject(){return{idref:this.idref,linear:this.linear?'yes':'no',href:this.href,source:this.source,type:this.type,canonical:this.canonical,cfiBase:this.cfiBase}}/**
	  * Create a url from the content
	  */createUrl(e){//var parsedUrl = new Url(url);
//var mimeType = mime.lookup(parsedUrl.filename);
let t=this.type;return this.render(e).then((e)=>new Blob([e],{type:t})).then((e)=>this.settings.replacements&&'base64'===this.settings.replacements?ke(e).then((e)=>ue(e,t)):pe(e,t)).then((e)=>(this.originalHref=this.href,this.href=e,this.unload(),e))}destroy(){this.unload(),this.hooks.serialize.clear(),this.hooks.content.clear(),this.originalHref&&ce(this.href),this.hooks=void 0,this.idref=void 0,this.linear=void 0,this.properties=void 0,this.index=void 0,this.href=void 0,this.source=void 0,this.next=void 0,this.prev=void 0,this.cfiBase=void 0}}/**
	 * A collection of Spine Items
	 */class vn{constructor(e){this.spineItems=[],this.spineByHref={},this.spineById={},this.hooks={},this.hooks.serialize=new xn,this.hooks.content=new xn,this.hooks.content.register(Oe),this.hooks.content.register(ze),this.hooks.content.register(De),this.epubcfi=new yn,this.loaded=!1,this.items=void 0,this.manifest=void 0,this.spineNodeIndex=void 0,this.baseUrl=void 0,this.length=void 0,e&&this.unpack(e)}/**
	  * Unpack items from a opf into spine items
	  * @param  {items} items
	  */unpack(e){this.items=e,this.length=this.items.length,this.items.forEach((e)=>{'yes'===e.linear?(e.prev=function(){for(let t=e.index;0<t;){let e=this.get(t-1);if(e&&e.linear)return e;t-=1}}.bind(this),e.next=function(){for(let t=e.index;t<this.spineItems.length-1;){let e=this.get(t+1);if(e&&e.linear)return e;t+=1}}.bind(this)):(e.prev=function(){},e.next=function(){});let t=new kn(e,this.hooks);this.append(t)}),this.loaded=!0}/**
	  * Get an item from the spine
	  * @param  {string|int} [target]
	  * @return {Section} section
	  * @example spine.get();
	  * @example spine.get(1);
	  * @example spine.get("chap1.html");
	  * @example spine.get("id1234");
	  */get(e){let t;if('undefined'==typeof e)for(;t<this.spineItems.length;){let e=this.spineItems[t];if(e&&e.linear)break;t+=1}else if(this.epubcfi.isCfiString(e)){let n=new yn(e);t=n.spinePos}else'number'==typeof e||!1===isNaN(e)?t=e:'string'==typeof e&&0===e.indexOf('#')?t=this.spineById[e.substring(1)]:'string'==typeof e&&(e=e.split('#')[0],t=void 0===this.spineById[e]?void 0===this.spineById[e]?this.spineByHref[encodeURI(e)]:this.spineByHref[e]:this.spineById[e]);return void 0==t?void 0:this.spineItems[t]}/**
	  * Append a Section to the Spine
	  * @private
	  * @param  {Section} section
	  */append(e){var t=this.spineItems.length;return e.index=t,this.spineItems.push(e),this.spineByHref[decodeURI(e.href)]=t,this.spineByHref[encodeURI(e.href)]=t,this.spineByHref[e.href]=t,e.source&&(this.spineByHref[e.source]=t),this.spineById[e.idref]=t,t}/**
	  * Prepend a Section to the Spine
	  * @private
	  * @param  {Section} section
	  */prepend(e){return this.spineByHref[e.href]=0,this.spineById[e.idref]=0,this.spineItems.forEach(function(e,t){e.index=t}),0}// insert(section, index) {
//
// };
/**
	  * Remove a Section from the Spine
	  * @private
	  * @param  {Section} section
	  */remove(e){var t=this.spineItems.indexOf(e);if(-1<t)return delete this.spineByHref[e.href],delete this.spineById[e.idref],this.spineItems.splice(t,1)}/**
	  * Loop over the Sections in the Spine
	  * @return {method} forEach
	  */each(){return this.spineItems.forEach.apply(this.spineItems,arguments)}/**
	  * Map the Sections in the Spine
	  * @return {method} map
	  */map(){return this.spineItems.map.apply(this.spineItems,arguments)}first(){let e=0;do{let t=this.get(e);if(t&&t.linear)return t;e+=1}while(e<this.spineItems.length)}last(){let e=this.spineItems.length-1;do{let t=this.get(e);if(t&&t.linear)return t;e-=1}while(0<=e)}/**
	  * Export an Array of all Spine Items
	  * @return {array}
	  */toArray(){return this.spineItems.map(function(e){return e.toObject()})}toJSON(){return JSON.stringify(this.toArray())}destroy(){this.each((e)=>e.destroy()),this.spineItems=void 0,this.spineByHref=void 0,this.spineById=void 0,this.hooks.serialize.clear(),this.hooks.content.clear(),this.hooks=void 0,this.epubcfi=void 0,this.loaded=!1,this.items=void 0,this.manifest=void 0,this.spineNodeIndex=void 0,this.baseUrl=void 0,this.length=void 0}}/**
	 * Queue for handling tasks one at a time
	 * @class
	 * @param {scope} context what this will resolve to in the tasks
	 */class wn{constructor(e){this._q=[],this.context=e,this.tick=dn,this.running=!1,this.paused=!1}/**
	  * Add an item to the queue
	  * @return {Promise}
	  */enqueue(){var e=[].shift.call(arguments),t=arguments,n,r,a;// Handle single args without context
// if(args && !Array.isArray(args)) {
//   args = [args];
// }
if(!e)throw new Error('No Task Provided');return'function'==typeof e?(n=new ve,r=n.promise,a={task:e,args:t,//"context"  : context,
deferred:n,promise:r}):a={promise:e},this._q.push(a),!1!=this.paused||this.running||this.run(),a.promise}/**
	  * Run one item
	  * @return {Promise}
	  */dequeue(){var e,t,n;if(this._q.length&&!this.paused){if(e=this._q.shift(),t=e.task,t)return n=t.apply(this.context,e.args),n&&'function'==typeof n.then?n.then(function(){e.deferred.resolve.apply(this.context,arguments)}.bind(this),function(){e.deferred.reject.apply(this.context,arguments)}.bind(this)):(e.deferred.resolve.apply(this.context,n),e.promise);if(e.promise)// Task is a promise
return e.promise}else return e=new ve,e.deferred.resolve(),e.promise}// Run All Immediately
dump(){for(;this._q.length;)this.dequeue()}/**
	  * Run all tasks sequentially, at convince
	  * @return {Promise}
	  */run(){return this.running||(this.running=!0,this.defered=new ve),this.tick.call(window,()=>{this._q.length?this.dequeue().then(function(){this.run()}.bind(this)):(this.defered.resolve(),this.running=void 0)}),!0==this.paused&&(this.paused=!1),this.defered.promise}/**
	  * Flush all, as quickly as possible
	  * @return {Promise}
	  */flush(){return this.running?this.running:this._q.length?(this.running=this.dequeue().then(function(){return this.running=void 0,this.flush()}.bind(this)),this.running):void 0}/**
	  * Clear all items in wait
	  */clear(){this._q=[]}/**
	  * Get the number of tasks in the queue
	  * @return {int} tasks
	  */length(){return this._q.length}/**
	  * Pause a running queue
	  */pause(){this.paused=!0}/**
	  * End the queue
	  */stop(){this._q=[],this.running=!1,this.paused=!0}}const Nn='0.4',Cn={BOOK:{OPEN_FAILED:'openFailed',READY:'ready'},CONTENTS:{EXPAND:'expand',RESIZE:'resize',SELECTED:'selected',SELECTED_RANGE:'selectedRange',LINK_CLICKED:'linkClicked'},LOCATIONS:{CHANGED:'changed'},MANAGERS:{RESIZE:'resize',RESIZED:'resized',ORIENTATION_CHANGE:'orientationchange',ADDED:'added',SCROLL:'scroll',SCROLLED:'scrolled'},VIEWS:{AXIS:'axis',LOAD_ERROR:'loaderror',RENDERED:'rendered',RESIZED:'resized',DISPLAYED:'displayed',SHOWN:'shown',HIDDEN:'hidden',MARK_CLICKED:'markClicked'},RENDITION:{STARTED:'started',ATTACHED:'attached',DISPLAYED:'displayed',DISPLAY_ERROR:'displayerror',RENDERED:'rendered',REMOVED:'removed',RESIZED:'resized',ORIENTATION_CHANGE:'orientationchange',LOCATION_CHANGED:'locationChanged',RELOCATED:'relocated',MARK_CLICKED:'markClicked',SELECTED:'selected',LAYOUT:'layout',WORKER_FAILED:'workerFailed',WORKER_INACTIVE:'workerInactive'},LAYOUT:{UPDATED:'updated'}};/**
	 * Locators
	 * @param {object} [manifest]
	 */class En{constructor(e){e&&this.unpack(e)}unpack(e){e.locations&&this.unpackLocations(e.locations),e.pages&&this.unpackPages(e.page)}unpackLocations(e){this.locations=e,this.totalLocations=this.locations.length-1}unpackPages(e){this.pages=e,this.firstPage=parseInt(this.pages[0]),this.lastPage=parseInt(this.pages[this.pages.length-1]),this.totalPages=this.lastPage-this.firstPage,e.forEach((e)=>{e.cfi&&this.pageLocations.push(e.cfi)})}/**
	  * Get a location from an EpubCFI
	  * @param {EpubCFI} cfi
	  * @return {number}
	  */locationFromCfi(e){let t;// Check if the location has not been set yet
return(yn.prototype.isCfiString(e)&&(e=new yn(e)),0===this.locations.length)?-1:(t=ae(e,this.locations,yn.prototype.compare),t>this.totalLocations?this.totalLocations:t)}/**
	  * Get a percentage position in locations from an EpubCFI
	  * @param {EpubCFI} cfi
	  * @return {number}
	  */percentageFromCfi(e){if(0===this.locations.length)return null;// Find closest cfi
var t=this.locationFromCfi(e);// Get percentage in total
return this.percentageFromLocation(t)}/**
	  * Get a percentage position from a location index
	  * @param {number} location
	  * @return {number}
	  */percentageFromLocation(e){return e&&this.totalLocations?e/this.totalLocations:0}/**
	  * Get an EpubCFI from location index
	  * @param {number} loc
	  * @return {EpubCFI} cfi
	  */cfiFromLocation(e){var t=-1;// check that pg is an int
return'number'!=typeof e&&(e=parseInt(e)),0<=e&&e<this.locations.length&&(t=this.locations[e]),t}/**
	  * Get an EpubCFI from location percentage
	  * @param {number} percentage
	  * @return {EpubCFI} cfi
	  */cfiFromPercentage(e){let t;// Make sure 1 goes to very end
if(1<e&&console.warn('Normalize cfiFromPercentage value to between 0 - 1'),1<=e){let e=new yn(this.locations[this.totalLocations]);return e.collapse(),e.toString()}return t=Pe(this.totalLocations*e),this.cfiFromLocation(t)}/**
	  * Get a PageList result from a EpubCFI
	  * @param  {string} cfi EpubCFI String
	  * @return {string} page
	  */pageFromCfi(e){var t=-1;// Check if the pageList has not been set yet
if(!this.pageLocations||0===this.pageLocations.length)return-1;// check if the cfi is in the location list
var n=indexOfSorted(e,this.pageLocations,yn.prototype.compare);return-1==n?(n=ae(e,this.pageLocations,yn.prototype.compare),t=0<=n-1?this.pages[n-1]:this.pages[0],void 0!==t||(t=-1)):t=this.pages[n],t}/**
	  * Get an EpubCFI from a Page List Item
	  * @param  {string} pg
	  * @return {string} cfi
	  */cfiFromPage(e){var t=-1;// check that pg is an int
'number'!=typeof e&&(e=parseInt(e));// check if the cfi is in the page list
// Pages could be unsorted.
var n=this.pages.indexOf(e);// TODO: handle pages not in the list
return-1!=n&&(t=this.pageLocations[n]),t}/**
	  * Get a Page from Book percentage
	  * @param  {number} percent
	  * @return {string} page
	  */pageFromPercentage(e){var t=Be(this.totalPages*e);return t}/**
	  * Returns a value between 0 - 1 corresponding to the location of a page
	  * @param  {int} pg the page
	  * @return {number} percentage
	  */percentageFromPage(e){var t=(e-this.firstPage)/this.totalPages;return Be(1e3*t)/1e3}/**
	  * Returns a value between 0 - 1 corresponding to the location of a cfi
	  * @param  {string} cfi EpubCFI String
	  * @return {number} percentage
	  */percentagePageFromCfi(e){var t=this.pageFromCfi(e),n=this.percentageFromPage(t);return n}destroy(){}}ct(En.prototype);/**
	 * Navigation wrapper
	 * @param {[object]} manifest
	 */class Sn{constructor(e){this.toc=[],this.tocByHref={},this.tocById={},this.landmarks=[],this.landmarksByType={},e&&this.unpack(e)}/**
	  * Get an item from the navigation
	  * @param  {string} target
	  * @return {object} navItems
	  */get(e){var t;return e?(0===e.indexOf('#')?t=this.tocById[e.substring(1)]:e in this.tocByHref&&(t=this.tocByHref[e]),this.toc[t]):this.toc}/**
	  * Get a landmark by type
	  * List of types: https://idpf.github.io/epub-vocabs/structure/
	  * @param  {string} type
	  * @return {object} landmarkItems
	  */landmark(e){let t;return t=this.landmarksByType[e],this.landmarks[t]}/**
	  * Unpack manifest object
	  */unpack(e){e.toc&&this.unpackToc(e.toc),e.landmarks&&this.unpackLandmarks(e.landmarks)}unpackToc(e){this.toc=e,e.forEach((e,t)=>{this.tocByHref[e.href]=t,e.source&&(this.tocByHref[e.href]=t),e.id&&(this.tocId[e.id]=t)})}unpackLandmarks(e){this.landmarks=e,e.forEach((e,t)=>{this.landmarksByType[e.type]=t})}destroy(){this.toc=void 0,this.tocByHref=void 0,this.tocById=void 0,this.landmarks=void 0,this.landmarksByType=void 0}}/**
	 * An Epub Book representation with methods for the loading and manipulation
	 * of its contents.
	 * @class
	 * @param {json | object} [manifest]
	 * @returns {Book}
	 * @example new Book(manifest)
	 */class In{constructor(e){this.sections=new vn,this.navigation=new Sn,this.locators=new En,this.manifest={"@context":'http://readium.org/webpub/default.jsonld',metadata:{"@type":'http://schema.org/Book'},resources:[],toc:[],landmarks:[],locations:[],pages:[],spine:[],links:[]},e&&this.parse(e)}parse(e){if(e){'string'==typeof e&&(e=JSON.parse(e));let{metadata:t,resources:n,toc:r,landmarks:a,locations:i,pages:s,spine:o,links:d}=e;this.metadata=t,this.resources=n,this.spine=o,this.toc=r,this.landmarks=a,this.locations=i,this.pages=s,this.links=d}}/**
	  * Get or set the Url
	  * @param {string} [url]
	  * @return {string} href
	  */get url(){let e=this.manifest.links.find((e)=>'self'===e.rel);return e&&e.href}set url(e){let t=this.manifest.links.find((e)=>'self'===e.rel);return t?t.href=e:(t={rel:'self',href:e,type:'application/webpub+json'},this.manifest.links.push(t)),this.path=t.href,t&&t.href}/**
	  * Get or set the Path to resolve content
	  * @param {string} [url]
	  * @return {string} Path
	  */get path(){return this._path}set path(e){let t=new gn(e);return this._path=t.Path,this._path}/**
	  * Get or set the Spine
	  * @param {array} [spineItems]
	  * @return {array} spineItems
	  */get spine(){return this.manifest.spine}set spine(e){if(e)return this.sections.unpack(e),this.manifest.spine=e,this.manifest.spine}/**
	  * Gets a Section of the Book from the Spine
	  * Alias for `book.spine.get`
	  * @param {string} target
	  * @return {Section}
	  */section(e){return this.sections.get(e)}/**
	  * Get or set the cover url
	  * @param {string} [coverUrl]
	  * @return {string} coverUrl
	  */get cover(){let e=this.manifest.links.find((e)=>'cover'===e.rel);return e&&e.href}set cover(e){let t=this.manifest.links.find((e)=>'cover'===e.rel);return t?t.href=e:(t={rel:'cover',href:e},this.manifest.links.push(t)),t&&t.href}/**
	  * Get or set the metadata
	  * @param {object} [metadata]
	  * @return {object} metadata
	  */get metadata(){return this.manifest.metadata}set metadata(e){if(e)return this.manifest.metadata=e,e['@type']||(this.manifest.metadata['@type']='http://schema.org/Book'),this.manifest.metadata}/**
	  * Get or set the resources
	  * @param {object} [resources]
	  * @return {object} resources
	  */get resources(){return this.manifest.resources}set resources(e){if(e)return this.manifest.resources=e.map((e)=>(e.properties&&e.properties.length&&(-1<e.properties.indexOf('cover-image')&&(e.rel='cover'),-1<e.properties.indexOf('nav')&&(e.rel='contents'),e.rel&&'cover'===e.rel&&(this.cover=e.href)),e)),this.manifest.resources}/**
	  * Get or set the toc
	  * @param {array} [toc]
	  * @return {array} toc
	  */get toc(){return this.manifest.toc}set toc(e){if(e)return this.navigation.unpackToc(e),this.manifest.toc=e}/**
	  * Get or set the landmarks
	  * @param {array} [landmarks]
	  * @return {array} landmarks
	  */get landmarks(){return this.manifest.landmarks}set landmarks(e){if(e)return this.navigation.unpackLandmarks(e),this.manifest.landmarks=e}/**
	  * Get or set the locations
	  * @param {array} [locations]
	  * @return {array} locations
	  */get locations(){return this.manifest.locations}set locations(e){if(e)return this.locators.unpackLocations(e),this.manifest.locations=e}/**
	  * Get or set the pages
	  * @param {array} [pageList]
	  * @return {array} pageList
	  */get pages(){return this.manifest.pages}set pages(e){if(e)return this.locators.unpackPages(e),this.manifest.pages=e}/**
	  * Get or set links
	  * @param {array} [links]
	  * @return {array} links
	  */get links(){return this.manifest.links}set links(e){if(e)return e.forEach((e)=>{'cover'===e.rel&&(this.cover=e.href),'self'===e.rel&&(this.path=e.href)}),this.manifest.links=e}/**
	  * Get or set the source of the book.
	  * If returns with an object, the links in the books have been replaced
	  * with service workers urls, or blob urls
	  * @param {array} [links]
	  * @return {array} links
	  */get source(){let e=this.manifest.links.find((e)=>'source'===e.rel);return e}set source(e){let t=this.manifest.links.find((e)=>'source'===e.rel);return t?t.href=e:(t={rel:'source',href:e,type:'application/epub+zip'},this.manifest.links.push(t)),t}/**
	  * Find a DOM Range for a given CFI Range
	  * @param  {EpubCFI} cfiRange a epub cfi range
	  * @return {Range}
	  */getRange(e){var t=new yn(e),n=this.sections.get(t.spinePos);return n?n.load().then(function(){var e=t.toRange(n.document);return e}):new Promise((e,t)=>{t('CFI could not be found')})}/**
	  * Generates the Book Key using the identifer in the manifest or other string provided
	  * @param  {string} [identifier] to use instead of metadata identifier
	  * @return {string} key
	  */key(e){var t=e||this.metadata.identifier;return`epubjs-${Nn}-${t}`}/**
	  * Generates a object representation of the book structure
	  * @return {object}
	  */toObject(){return this.manifest}/**
	  * Generates a JSON output of the book structure
	  */toJSON(){return JSON.stringify(this.manifest)}/**
	  * Destroy the Book and all associated objects
	  */destroy(){this.sections&&this.sections.destroy(),this.locators&&this.locators.destroy(),this.navigation&&this.navigation.destroy(),this.sections=void 0,this.locators=void 0,this.navigation=void 0,this.manifest=void 0}}//-- Enable binding events to book
ct(In.prototype);/**
	 * Find Locations for a Book
	 * @param {Spine} spine
	 * @param {request} request
	 */class An{constructor(e,t){this.request=e,this.pause=t||100,this.q=new wn(this),this.epubcfi=new yn,this._locations=[],this.total=0,this.break=150,this._current=0,this.currentLocation='',this._currentCfi='',this.processingTimeout=void 0}/**
	  * Load all of sections in the book to generate locations
	  * @param  {int} chars how many chars to split on
	  * @return {object} locations
	  */generate(e,t){return this.spine=e,t&&(this.break=t),this.q.pause(),this.spine.each(function(e){e.linear&&this.q.enqueue(this.process.bind(this),e)}.bind(this)),this.q.run().then(function(){return this.total=this._locations.length-1,this._currentCfi&&(this.currentLocation=this._currentCfi),this._locations;// console.log(this.percentage(this.book.rendition.location.start), this.percentage(this.book.rendition.location.end));
}.bind(this))}createRange(){return{startContainer:void 0,startOffset:void 0,endContainer:void 0,endOffset:void 0}}process(e){return e.load(this.request).then(function(t){var n=new ve,r=this.parse(t,e.cfiBase);return this._locations=this._locations.concat(r),e.unload(),this.processingTimeout=setTimeout(()=>n.resolve(r),this.pause),n.promise}.bind(this))}parse(e,t,n){var r=[],a=e.ownerDocument,i=fe(a,'body'),s=0,o=n||this.break,d=function(e){var n=e.length,a=0,i;if(0===e.textContent.trim().length)return!1;// continue
// Start range
for(0==s&&(l=this.createRange(),l.startContainer=e,l.startOffset=0),i=o-s,i>n&&(s+=n,a=n);a<n;)// pos += dist;
// Gone over
if(i=o-s,0===s&&(a+=1,l=this.createRange(),l.startContainer=e,l.startOffset=a),a+i>=n)s+=n-a,a=n;else{a+=i,l.endContainer=e,l.endOffset=a;// cfi = section.cfiFromRange(range);
let n=new yn(l,t).toString();r.push(n),s=0}p=e},l,p;// Close remaining
if(be(i,d.bind(this)),l&&l.startContainer&&p){l.endContainer=p,l.endOffset=p.length;let e=new yn(l,t).toString();r.push(e),s=0}return r}/**
	  * Get a location from an EpubCFI
	  * @param {EpubCFI} cfi
	  * @return {number}
	  */locationFromCfi(e){let t;// Check if the location has not been set yet
return(yn.prototype.isCfiString(e)&&(e=new yn(e)),0===this._locations.length)?-1:(t=ae(e,this._locations,this.epubcfi.compare),t>this.total?this.total:t)}/**
	  * Get a percentage position in locations from an EpubCFI
	  * @param {EpubCFI} cfi
	  * @return {number}
	  */percentageFromCfi(e){if(0===this._locations.length)return null;// Find closest cfi
var t=this.locationFromCfi(e);// Get percentage in total
return this.percentageFromLocation(t)}/**
	  * Get a percentage position from a location index
	  * @param {number} location
	  * @return {number}
	  */percentageFromLocation(e){return e&&this.total?e/this.total:0}/**
	  * Get an EpubCFI from location index
	  * @param {number} loc
	  * @return {EpubCFI} cfi
	  */cfiFromLocation(e){var t=-1;// check that pg is an int
return'number'!=typeof e&&(e=parseInt(e)),0<=e&&e<this._locations.length&&(t=this._locations[e]),t}/**
	  * Get an EpubCFI from location percentage
	  * @param {number} percentage
	  * @return {EpubCFI} cfi
	  */cfiFromPercentage(e){let t;// Make sure 1 goes to very end
if(1<e&&console.warn('Normalize cfiFromPercentage value to between 0 - 1'),1<=e){let e=new yn(this._locations[this.total]);return e.collapse(),e.toString()}return t=Pe(this.total*e),this.cfiFromLocation(t)}/**
	  * Load locations from JSON
	  * @param {json} locations
	  */load(e){return this._locations='string'==typeof e?JSON.parse(e):e,this.total=this._locations.length-1,this._locations}/**
	  * Save locations to JSON
	  * @alias toJSON
	  * @return {json}
	  */save(){return this.toJSON()}getCurrent(){return this._current}setCurrent(e){var t;if('string'==typeof e)this._currentCfi=e;else if('number'==typeof e)this._current=e;else return;0===this._locations.length||('string'==typeof e?(t=this.locationFromCfi(e),this._current=t):t=e,this.emit(Cn.LOCATIONS.CHANGED,{percentage:this.percentageFromLocation(t)}))}/**
	  * Get the current location
	  */get currentLocation(){return this._current}/**
	  * Set the current location
	  */set currentLocation(e){this.setCurrent(e)}/**
	  * Locations length
	  */length(){return this._locations.length}/**
	  * Export locations as an Array
	  * @return {array}
	  */toArray(){return this._locations}/**
	  * Export locations as JSON
	  * @return {json}
	  */toJSON(){return JSON.stringify(this._locations)}destroy(){this.spine=void 0,this.request=void 0,this.pause=void 0,this.q.stop(),this.q=void 0,this.epubcfi=void 0,this._locations=void 0,this.total=void 0,this.break=void 0,this._current=void 0,this.currentLocation=void 0,this._currentCfi=void 0,clearTimeout(this.processingTimeout)}}ct(An.prototype);/**
	 * Handles Parsing and Accessing an Epub Container
	 * @class
	 * @param {document} [containerDocument] xml document
	 */class Tn{constructor(e){this.packagePath='',this.directory='',this.encoding='',e&&this.parse(e)}/**
	  * Parse the Container XML
	  * @param  {document} containerDocument
	  */parse(e){//-- <rootfile full-path="OPS/package.opf" media-type="application/oebps-package+xml"/>
var t;if(!e)throw new Error('Container File Not Found');if(t=fe(e,'rootfile'),!t)throw new Error('No RootFile Found');this.packagePath=t.getAttribute('full-path'),this.directory=mn.dirname(this.packagePath),this.encoding=e.xmlEncoding}destroy(){this.packagePath=void 0,this.directory=void 0,this.encoding=void 0}}/**
	 * Open Packaging Format Parser
	 * @class
	 * @param {document} packageDocument OPF XML
	 */class On{constructor(e){this.manifest={},this.navPath='',this.ncxPath='',this.coverPath='',this.spineNodeIndex=0,this.spine=[],this.metadata={},e&&this.parse(e)}/**
	  * Parse OPF XML
	  * @param  {document} packageDocument OPF XML
	  * @return {object} parsed package parts
	  */parse(e){var t,n,r;if(!e)throw new Error('Package File Not Found');if(t=fe(e,'metadata'),!t)throw new Error('No Metadata Found');if(n=fe(e,'manifest'),!n)throw new Error('No Manifest Found');if(r=fe(e,'spine'),!r)throw new Error('No Spine Found');return this.manifest=this.parseManifest(n),this.navPath=this.findNavPath(n),this.ncxPath=this.findNcxPath(n,r),this.coverPath=this.findCoverPath(e),this.spineNodeIndex=oe(r),this.spine=this.parseSpine(r,this.manifest),this.metadata=this.parseMetadata(t),this.metadata.direction=r.getAttribute('page-progression-direction'),{metadata:this.metadata,spine:this.spine,manifest:this.manifest,navPath:this.navPath,ncxPath:this.ncxPath,coverPath:this.coverPath,spineNodeIndex:this.spineNodeIndex}}/**
	  * Parse Metadata
	  * @private
	  * @param  {document} xml
	  * @return {object} metadata
	  */parseMetadata(e){var t={title:this.getElementText(e,'title'),creator:this.getElementText(e,'creator'),description:this.getElementText(e,'description'),pubdate:this.getElementText(e,'date'),publisher:this.getElementText(e,'publisher'),identifier:this.getElementText(e,'identifier'),language:this.getElementText(e,'language'),rights:this.getElementText(e,'rights'),modified_date:this.getPropertyText(e,'dcterms:modified'),layout:this.getPropertyText(e,'rendition:layout'),orientation:this.getPropertyText(e,'rendition:orientation'),flow:this.getPropertyText(e,'rendition:flow'),viewport:this.getPropertyText(e,'rendition:viewport')};return t}/**
	  * Parse Manifest
	  * @private
	  * @param  {document} manifestXml
	  * @return {object} manifest
	  */parseManifest(e){var t={},n=ge(e,'item'),r=Array.prototype.slice.call(n);//-- Turn items into an array
//-- Create an object with the id as key
return r.forEach(function(e){var n=e.getAttribute('id'),r=e.getAttribute('href')||'',a=e.getAttribute('media-type')||'',i=e.getAttribute('properties')||'';t[n]={href:r,type:a,properties:i.length?i.split(' '):[]}}),t}/**
	  * Parse Spine
	  * @param  {document} spineXml
	  * @param  {Packaging.manifest} manifest
	  * @return {object} spine
	  */parseSpine(e){var t=[],n=ge(e,'itemref'),r=Array.prototype.slice.call(n);// var epubcfi = new EpubCFI();
//-- Add to array to mantain ordering and cross reference with manifest
return r.forEach(function(e,n){var r=e.getAttribute('idref'),a=e.getAttribute('properties')||'',i=a.length?a.split(' '):[],s={idref:r,linear:e.getAttribute('linear')||'yes',properties:i,// "href" : manifest[Id].href,
// "url" :  manifest[Id].url,
index:n// "cfiBase" : cfiBase
};// var cfiBase = epubcfi.generateChapterComponent(spineNodeIndex, index, Id);
// var manifestProps = manifest[Id].properties;
// var manifestPropArray = manifestProps.length ? manifestProps.split(" ") : [];
t.push(s)}),t}/**
	  * Find TOC NAV
	  * @private
	  */findNavPath(e){// Find item with property "nav"
// Should catch nav irregardless of order
var t=_e(e,'item',{properties:'nav'});return!!t&&t.getAttribute('href')}/**
	  * Find TOC NCX
	  * media-type="application/x-dtbncx+xml" href="toc.ncx"
	  * @private
	  */findNcxPath(e,t){var n=_e(e,'item',{"media-type":'application/x-dtbncx+xml'}),r;// If we can't find the toc by media-type then try to look for id of the item in the spine attributes as
// according to http://www.idpf.org/epub/20/spec/OPF_2.0.1_draft.htm#Section2.4.1.2,
// "The item that describes the NCX must be referenced by the spine toc attribute."
return n||(r=t.getAttribute('toc'),r&&(n=e.getElementById(r))),!!n&&n.getAttribute('href')}/**
	  * Find the Cover Path
	  * <item properties="cover-image" id="ci" href="cover.svg" media-type="image/svg+xml" />
	  * Fallback for Epub 2.0
	  * @param  {document} packageXml
	  * @return {string} href
	  */findCoverPath(e){var t=fe(e,'package'),n=t.getAttribute('version');if('2.0'===n){var r=_e(e,'meta',{name:'cover'});if(r){var a=r.getAttribute('content'),i=e.getElementById(a);return i?i.getAttribute('href'):''}return!1}var s=_e(e,'item',{properties:'cover-image'});return s?s.getAttribute('href'):''}/**
	  * Get text of a namespaced element
	  * @private
	  * @param  {document} xml
	  * @param  {string} tag
	  * @return {string} text
	  */getElementText(e,t){var n=e.getElementsByTagNameNS('http://purl.org/dc/elements/1.1/',t),r;return n&&0!==n.length?(r=n[0],r.childNodes.length?r.childNodes[0].nodeValue:''):''}/**
	  * Get text by property
	  * @private
	  * @param  {document} xml
	  * @param  {string} property
	  * @return {string} text
	  */getPropertyText(e,t){var n=_e(e,'meta',{property:t});return n&&n.childNodes.length?n.childNodes[0].nodeValue:''}/**
	  * Load JSON Manifest
	  * @param  {document} packageDocument OPF XML
	  * @return {object} parsed package parts
	  */load(e){return this.metadata=e.metadata,this.spine=e.spine.map((e,t)=>{let n=e.idref;return n||(e.idref=encodeURIComponent(e.href)),'undefined'==typeof e.linear&&(e.linear='yes'),e.rel&&'cover'===e.rel[0]&&(this.coverPath=e.href),e.index=t,this.manifest[e.idref]=e,e}),e.resource&&e.resources.forEach((e)=>{let t=e.id||e.href;this.manifest[t]=e,e.rel&&'cover'===e.rel[0]&&(this.coverPath=e.href)}),this.spineNodeIndex=0,this.toc=e.toc,{metadata:this.metadata,spine:this.spine,manifest:this.manifest,navPath:this.navPath,ncxPath:this.ncxPath,coverPath:this.coverPath,spineNodeIndex:this.spineNodeIndex,toc:this.toc}}destroy(){this.manifest=void 0,this.navPath=void 0,this.ncxPath=void 0,this.coverPath=void 0,this.spineNodeIndex=void 0,this.spine=void 0,this.metadata=void 0}}/**
	 * Navigation Parser
	 * @param {document} xml navigation html / xhtml / ncx
	 */class zn{constructor(e,t){this.toc=[],this.tocByHref={},this.tocById={},this.landmarks=[],this.landmarksByType={},this.length=0,this.url=t||'',e&&this.parse(e)}/**
	  * Parse out the navigation items
	  * @param {document} xml navigation html / xhtml / ncx
	  */parse(e){let t=e.nodeType,n,r;t&&(n=fe(e,'html'),r=fe(e,'ncx')),t?n?(this.toc=this.parseNav(e),this.landmarks=this.parseLandmarks(e)):r&&(this.toc=this.parseNcx(e)):this.toc=this.load(e),this.length=0,this.unpack(this.toc)}/**
	  * Unpack navigation items
	  * @private
	  * @param  {array} toc
	  */unpack(e){for(var t=0,n,r;t<e.length;t++)n=e[t],r=n.href,n.href&&(this.tocByHref[r]=t),n.id&&(this.tocById[r]=t),this.length++,n.children.length&&this.unpack(n.children)}/**
	  * Get an item from the navigation
	  * @param  {string} target
	  * @return {object} navItems
	  */get(e){var t;return e?(0===e.indexOf('#')?t=this.tocById[e.substring(1)]:e in this.tocByHref&&(t=this.tocByHref[e]),this.toc[t]):this.toc}/**
	  * Get a landmark by type
	  * List of types: https://idpf.github.io/epub-vocabs/structure/
	  * @param  {string} type
	  * @return {object} landmarkItems
	  */landmark(e){var t;return e?(t=this.landmarksByType[e],this.landmarks[t]):this.landmarks}/**
	  * Parse toc from a Epub > 3.0 Nav
	  * @private
	  * @param  {document} navHtml
	  * @return {array} navigation list
	  */parseNav(e){var t=we(e,'nav','toc'),n=t?ge(t,'li'):[],r=n.length,a={},s=[],o,i,d;if(!n||0===r)return s;for(o=0;o<r;++o)i=this.navItem(n[o]),i&&(a[i.id]=i,i.parentIndex?(d=a[i.parent],d.children.push(i)):s.push(i));return s}/**
	  * Create a navItem
	  * @private
	  * @param  {element} item
	  * @return {object} navItem
	  */navItem(e){let t=e.getAttribute('id')||void 0,n=Ee(e,'a',!0);if(!n)return;t||(t='epubjs-autogen-toc-id-'+te(),e.setAttribute('id',t));let r=n.getAttribute('href')||'',a=n.textContent||'',i=Se(e,'li'),s=r.split('#'),o;for(''===s[0]&&(r=this.url+r),i&&(o=i.getAttribute('id'));!o&&i;)i=Se(i,'li'),i&&(o=i.getAttribute('id'));return{id:t,href:r,title:a,children:[],parent:o}}/**
	  * Parse landmarks from a Epub > 3.0 Nav
	  * @private
	  * @param  {document} navHtml
	  * @return {array} landmarks list
	  */parseLandmarks(e){var t=we(e,'nav','landmarks'),n=t?ge(t,'li'):[],r=n.length,a=[],s,i;if(!n||0===r)return a;for(s=0;s<r;++s)i=this.landmarkItem(n[s]),i&&(a.push(i),this.landmarksByType[i.type]=s);return a}/**
	  * Create a landmarkItem
	  * @private
	  * @param  {element} item
	  * @return {object} landmarkItem
	  */landmarkItem(e){let t=Ee(e,'a',!0);if(!t)return;let n=t.getAttributeNS('http://www.idpf.org/2007/ops','type')||void 0,r=t.getAttribute('href')||'',a=t.textContent||'',i=r.split('#');return''===i[0]&&(r=this.url+r),{href:r,title:a,type:n}}/**
	  * Parse from a Epub > 3.0 NC
	  * @private
	  * @param  {document} navHtml
	  * @return {array} navigation list
	  */parseNcx(e){var t=ge(e,'navPoint'),n=t.length,r={},a=[],s,i,o;if(!t||0===n)return a;for(s=0;s<n;++s)i=this.ncxItem(t[s]),r[i.id]=i,i.parent?(o=r[i.parent],o.children.push(i)):a.push(i);return a}/**
	  * Create a ncxItem
	  * @private
	  * @param  {element} item
	  * @return {object} ncxItem
	  */ncxItem(e){var t=e.getAttribute('id')||!1,n=fe(e,'content'),r=n.getAttribute('src'),a=fe(e,'navLabel'),i=a.textContent?a.textContent:'',s=e.parentNode,o;return s&&'navPoint'===s.nodeName&&(o=s.getAttribute('id')),t||(t='epubjs-autogen-toc-id-'+te(),e.setAttribute('id',t)),{id:t,href:r,title:i,children:[],parent:o}}/**
	  * Load Spine Items
	  * @param  {object} json the items to be loaded
	  */load(e){return e.map((e)=>(e.children&&(e.children=this.load(e.children)),e))}/**
	  * forEach pass through
	  * @param  {Function} fn function to run on each item
	  * @return {method} forEach loop
	  */forEach(e){return this.toc.forEach(e)}/**
	  * Get an Array of all Table of Contents Items
	  */getTocArray(e){return this.toc.map((t)=>{let n=e?e(t.href):t.href,r={href:n,title:t.title};return t.children.length&&(r.children=t.children),r})}/**
	  * Get an Array of all landmarks
	  */getLandmarksArray(e){return this.landmarks.map((t)=>{let n=e?e(t.href):t.href,r={href:n,title:t.title,type:t.type};return r})}}/*
	 From Zip.js, by Gildas Lormeau
	edited down
	 */var Dn={application:{ecmascript:['es','ecma'],javascript:'js',ogg:'ogx',pdf:'pdf',postscript:['ps','ai','eps','epsi','epsf','eps2','eps3'],"rdf+xml":'rdf',smil:['smi','smil'],"xhtml+xml":['xhtml','xht'],xml:['xml','xsl','xsd','opf','ncx'],zip:'zip',"x-httpd-eruby":'rhtml',"x-latex":'latex',"x-maker":['frm','maker','frame','fm','fb','book','fbdoc'],"x-object":'o',"x-shockwave-flash":['swf','swfl'],"x-silverlight":'scr',"epub+zip":'epub',"font-tdpfr":'pfr',"inkml+xml":['ink','inkml'],json:'json',"jsonml+json":'jsonml',"mathml+xml":'mathml',"metalink+xml":'metalink',mp4:'mp4s',// "oebps-package+xml" : "opf",
"omdoc+xml":'omdoc',oxps:'oxps',"vnd.amazon.ebook":'azw',widget:'wgt',// "x-dtbncx+xml" : "ncx",
"x-dtbook+xml":'dtb',"x-dtbresource+xml":'res',"x-font-bdf":'bdf',"x-font-ghostscript":'gsf',"x-font-linux-psf":'psf',"x-font-otf":'otf',"x-font-pcf":'pcf',"x-font-snf":'snf',"x-font-ttf":['ttf','ttc'],"x-font-type1":['pfa','pfb','pfm','afm'],"x-font-woff":'woff',"x-mobipocket-ebook":['prc','mobi'],"x-mspublisher":'pub',"x-nzb":'nzb',"x-tgif":'obj',"xaml+xml":'xaml',"xml-dtd":'dtd',"xproc+xml":'xpl',"xslt+xml":'xslt',"internet-property-stream":'acx',"x-compress":'z',"x-compressed":'tgz',"x-gzip":'gz'},audio:{flac:'flac',midi:['mid','midi','kar','rmi'],mpeg:['mpga','mpega','mp2','mp3','m4a','mp2a','m2a','m3a'],mpegurl:'m3u',ogg:['oga','ogg','spx'],"x-aiff":['aif','aiff','aifc'],"x-ms-wma":'wma',"x-wav":'wav',adpcm:'adp',mp4:'mp4a',webm:'weba',"x-aac":'aac',"x-caf":'caf',"x-matroska":'mka',"x-pn-realaudio-plugin":'rmp',xm:'xm',mid:['mid','rmi']},image:{gif:'gif',ief:'ief',jpeg:['jpeg','jpg','jpe'],pcx:'pcx',png:'png',"svg+xml":['svg','svgz'],tiff:['tiff','tif'],"x-icon":'ico',bmp:'bmp',webp:'webp',"x-pict":['pic','pct'],"x-tga":'tga',"cis-cod":'cod'},text:{"cache-manifest":['manifest','appcache'],css:'css',csv:'csv',html:['html','htm','shtml','stm'],mathml:'mml',plain:['txt','text','brf','conf','def','list','log','in','bas'],richtext:'rtx',"tab-separated-values":'tsv',"x-bibtex":'bib'},video:{mpeg:['mpeg','mpg','mpe','m1v','m2v','mp2','mpa','mpv2'],mp4:['mp4','mp4v','mpg4'],quicktime:['qt','mov'],ogg:'ogv',"vnd.mpegurl":['mxu','m4u'],"x-flv":'flv',"x-la-asf":['lsf','lsx'],"x-mng":'mng',"x-ms-asf":['asf','asx','asr'],"x-ms-wm":'wm',"x-ms-wmv":'wmv',"x-ms-wmx":'wmx',"x-ms-wvx":'wvx',"x-msvideo":'avi',"x-sgi-movie":'movie',"x-matroska":['mpv','mkv','mk3d','mks'],"3gpp2":'3g2',h261:'h261',h263:'h263',h264:'h264',jpeg:'jpgv',jpm:['jpm','jpgm'],mj2:['mj2','mjp2'],"vnd.ms-playready.media.pyv":'pyv',"vnd.uvvu.mp4":['uvu','uvvu'],"vnd.vivo":'viv',webm:'webm',"x-f4v":'f4v',"x-m4v":'m4v',"x-ms-vob":'vob',"x-smv":'smv'}},Rn=function(){var e={},t,n,r,a;for(t in Dn)if(Dn.hasOwnProperty(t))for(n in Dn[t])if(Dn[t].hasOwnProperty(n))if(r=Dn[t][n],'string'==typeof r)e[r]=t+'/'+n;else for(a=0;a<r.length;a++)e[r[a]]=t+'/'+n;return e}(),Bn={lookup:function(e){return e&&Rn[e.split('.').pop().toLowerCase()]||'text/plain'}};// import path from "path-webpack";
/**
	 * Handles Package Resources
	 * @class
	 * @param {object} resources
	 * @param {object} [options]
	 * @param {string} [options.replacements="base64"]
	 * @param {Archive} [options.archive]
	 * @param {method} [options.load]
	 * @param {string} [options.url]
	 * @param {string} [options.inject]
	 */class Pn{constructor(e,t){this.settings={replacements:t&&t.replacements||'blobUrl',archive:t&&t.archive,load:t&&t.load,url:t&&t.url,// path: (options && options.path),
inject:t&&t.inject||{}},this.urlCache={},this.resources=Object.assign({},e),this.resourcesByHref={},this.ids=[],this.html=[],this.assets=[],this.css=[],'string'==typeof this.settings.url?(this.url=new gn(this.settings.url),this.path=new fn(this.settings.url)):'object'==typeof this.settings.url?(this.url=this.settings.url,this.path=new fn(this.url.toString())):this.path=new fn('/'),e&&this.split(e)}/**
	  * Split resources by type
	  * @private
	  */split(e){let t=Object.keys(e),n=t.filter(function(t){let n=e[t];if('application/xhtml+xml'===n.type||'text/html'===n.type)return!0}),r=t.filter(function(t){let n=e[t];if('application/xhtml+xml'!==n.type&&'text/html'!==n.type&&'text/css'!==n.type)return!0}),a=t.filter(function(t){let n=e[t];if('text/css'===n.type)return!0});// HTML
// Exclude HTML & CSS
// Only CSS
return t.forEach((t)=>{let n=e[t];// set ID from keys
n.id=t,n.source||(n.source=n.href),this.resourcesByHref[n.href]=t}),this.ids=t,this.html=n,this.assets=r,this.css=a,{html:n,assets:r,css:a}}/**
	  * Save all resources into the cache
	  * @return {array}
	  */cache(e,t){if('undefined'==typeof caches)return new Promise(function(e){e([])});this.cacheKey=e;let n=this.url;return'string'==typeof t&&(n=new gn(t)),this.ids.map((r)=>{let a=this.resources[r],i=a.source||a.href,s=-1<i.indexOf('://'),o=s?i:this.path.resolve(i),d;if(!s&&n)d=n.resolve(i);else{let n=new gn(i,t),r=encodeURIComponent(n.origin);o=o.replace(n.origin,''),d=new gn(e+r+o,location.href).toString()}this.resources[r].path=o,this.resources[r].cached=d,this.urlCache[o]=d}),caches.open(e).then((e)=>{let t=this.ids.map((t)=>{let n=this.resources[t],r=n.cached,a=n.path,i=Bn.lookup(a);return e.match(r).then((t)=>{if(!t){let t;return t='application/xhtml+xml'===n.type||'text/html'===n.type?this.settings.load(a,'text').then((e)=>(this.settings.inject.identifier&&(e=this.injectIdentifier(e,this.settings.inject.identifier)),this.settings.inject.script&&(e=this.injectScript(e,this.settings.inject.script)),this.settings.inject.stylesheet&&(e=this.injectStylesheet(e,this.settings.inject.script)),le(e,n.type))):this.settings.load(a,'blob'),t.then((t)=>{let n=new Response(t,{status:200,headers:{"Content-Type":i}});return this.urlCache[a]=r,e.put(r,n)},()=>(console.warn('Missing Resource',a),a)).then(()=>r)}return this.urlCache[a]=r,r})});return Promise.all(t)})}/**
	  * Create blob urls for all the assets
	  * @return {Promise}         returns replacement urls
	  */replacements(){if('none'===this.settings.replacements)return new Promise(function(e){e([])}.bind(this));var e=[];// Replace all the assets
let t=this.assets.map((t)=>{let n=this.replacementUrl(t);return e.push(n),n}),n=Promise.all(t).then(()=>this.css.map((t)=>{let n=this.replacementCss(t);return e.push(n),n})),r=n.then(()=>this.html.map((t)=>{let n=this.replacementHtml(t);return e.push(n),n}));// Re-write and replace css files
// Re-write and replace htmls files
return r.then(()=>Promise.all(e)).then((e)=>e)}/**
	  * Create a replacement url from a resource
	  * @param  {number} resourceId
	  * @return {promise}
	  */replacementUrl(e){let t=this.resources[e],n=this.url.resolve(t.href),r;return r='base64'===this.settings.replacements?this.base64UrlFrom(n):this.blobUrlFrom(n),r.then((t)=>(this.resources[e].replacement=t,this.urlCache[n]=t,t)).catch((e)=>(console.error(e),null))}/**
	  * Replace URLs in CSS resources
	  * @private
	  * @param  {number} resourceId
	  * @return {Promise}
	  */replacementCss(e){let t=this.resources[e],n=t.href,r;if(this.path.isAbsolute(n))return new Promise(function(e){e(n)});let a=this.path.resolve(n),i=new fn(a);// Get the text of the css file from the archive
var s;return s=this.settings.archive?this.settings.archive.getText(a):this.settings.load(a,'text'),s.then((e)=>{let t={};// Get asset links relative to css file
return this.ids.forEach((e)=>{let n=this.resources[e];if(n.replacement){let e=n.href,r=this.path.resolve(e),a=i.relative(r);t[a]=n.replacement}}),e=this.substitute(e,t),r='base64'===this.settings.replacements?ue(e,'text/css'):pe(e,'text/css'),r},()=>new Promise(function(e){e()})).then((t)=>(t&&(this.resources[e].replacement=t,this.urlCache[i]=t),t))}/**
	  * Replace URLs in HTML resources
	  * @private
	  * @param  {number} resourceId
	  * @return {Promise}
	  */replacementHtml(e){let t=this.resources[e],n=t.href,r=Bn.lookup(n),a;if(this.path.isAbsolute(n))return new Promise(function(e){e(n)});let i=this.path.resolve(n),s=new fn(i);// Get the text of the css file from the archive
var o;return o=this.settings.archive?this.settings.archive.getText(i):this.settings.load(i,'text'),o.then((e)=>{let t={};// Get asset links relative to html file
return this.ids.forEach((e)=>{let n=this.resources[e];if(n.replacement){let e=n.href,r=this.path.resolve(e),a=s.relative(r);t[a]=n.replacement}}),e=this.substitute(e,t),this.settings.inject.base&&(e=this.injectBase(e,this.settings.inject.base)),this.settings.inject.identifier&&(e=this.injectIdentifier(e,this.settings.inject.identifier)),this.settings.inject.script&&(e=this.injectScript(e,this.settings.inject.script)),this.settings.inject.stylesheet&&(e=this.injectStylesheet(e,this.settings.inject.script)),a='base64'===this.settings.replacements?ue(e,r):pe(e,r),a},()=>new Promise(function(e){e()})).then((t)=>(t&&(this.resources[e].replacement=t,this.urlCache[s]=t),t))}/**
	  * Create a blob url from a resource absolute url
	  * @param  {string} url
	  * @return {string}          the resolved path string
	  */blobUrlFrom(e){var t=new gn(e),n=Bn.lookup(t.filename);return this.settings.archive?this.settings.archive.createUrl(e,{base64:!1}):this.settings.load(e,'blob').then((e)=>pe(e,n))}/**
	  * Create a base64 encoded url from a resource absolute url
	  * @param  {string} url
	  * @return {string}          the resolved path string
	  */base64UrlFrom(e){var t=new gn(e),n=Bn.lookup(t.filename);return this.settings.archive?this.settings.archive.createUrl(e,{base64:!0}):this.settings.load(e,'blob').then((e)=>ke(e)).then((e)=>ue(e,n))}/**
	  * Substitute urls in a resource
	  */substitute(e,t){let n=Object.keys(t).map((e)=>e.replace(/[.?*+^$[\]\\(){}|-]/g,'\\$&')).join('|'),r=new RegExp('('+n+')','g');return e.replace(r,function(e){return t[e]})}injectStylesheet(e,t){let n=/<[ ]*\/head[ ]*>/,r=`<link href="${t}" rel="stylesheet" />`;return e.replace(n,r+'$&')}injectScript(e,t){let n=/<[ ]*\/head[ ]*>/,r=`<script src="${t}" type="text/javascript"></script>`;return e.replace(n,r+'$&')}injectIdentifier(e,t){let n=/<[ ]*\/head[ ]*>/,r=`<meta name="dc.relation.ispartof" content="${t}" />`;return e.replace(n,r+'$&')}injectBase(e,t){let n=/<[ ]*head[ ]*>/,r=-1<t.indexOf('://');// Fix for Safari crashing if the url doesn't have an origin
if(!r&&'undefined'!=typeof window&&window.location){let e=window.location.href.split('/'),n='';e.pop(),n=e.join('/'),t=n+t}let a=`<base href="${t}" />`;return e.replace(n,'$&'+a)}origin(e){this.url=new gn(e)}/**
	  * Resolve a path to its absolute url (or replaced url)
	  * @param  {string} path
	  * @return {string}          the resolved path string
	  */resolve(e){if(!e)return;let t=-1<e.indexOf('://'),n=t?e:this.path.resolve(e),r=n,a=n.split('?'),i=n.split('#'),s=n;1<a.length?s=a[0]:1<i.length&&(s=i[0]);let o=this.urlCache[s];return o?(r=o,1<a.length?r+='?'+a[1]:1<i.length&&(r+='#'+i[1])):this.url?r=this.url.resolve(e):r=e,r}/**
	  * Export an Array of all resources
	  * @return {array}
	  */toArray(){return this.ids.map((e)=>{let t=this.resources[e],{type:n,properties:r,id:a}=t,i=t.href,s=t.cached||t.replacement||this.url&&this.url.resolve(t.href)||t.href;return{href:s,source:i,type:n,properties:r,id:a}})}forEach(e){return this.ids.forEach((t)=>{let n=this.resources[t];n.id=key,e(n)})}map(e){return this.ids.map((t)=>{let n=this.resources[t];return n.id=key,e(n)})}filter(e){return this.ids.filter((t)=>{let n=this.resources[t];return n.id=key,e(n)})}get(e){if(e in this.resources)return this.resources[e];if(e in this.resourcesByHref){let t=this.resourcesByHref[e];return this.resources[t]}}revokeBlobUrls(){this.ids.forEach((e)=>{let t=this.resources[e];t.replacement&&ce(t.replacement)})}destroy(){this.revokeBlobUrls(),this.settings=void 0,this.manifest=void 0,this.html=void 0,this.assets=void 0,this.css=void 0,this.urls=void 0,this.cssUrls=void 0}}/**
	 * Page List Parser
	 * @param {document} [xml]
	 */class Ln{constructor(e){this.pages=[],this.locations=[],this.epubcfi=new yn,this.firstPage=0,this.lastPage=0,this.totalPages=0,this.toc=void 0,this.ncx=void 0,e&&(this.pageList=this.parse(e)),this.pageList&&this.pageList.length&&this.process(this.pageList)}/**
	  * Parse PageList Xml
	  * @param  {document} xml
	  */parse(e){var t=fe(e,'html'),n=fe(e,'ncx');if(t)return this.parseNav(e)}/**
	  * Parse a Nav PageList
	  * @private
	  * @param  {document} navHtml
	  * @return {PageList.item[]} list
	  */parseNav(e){var t=we(e,'nav','page-list'),n=t?ge(t,'li'):[],r=n.length,a=[],s,i;if(!n||0===r)return a;for(s=0;s<r;++s)i=this.item(n[s]),a.push(i);return a}/**
	  * Page List Item
	  * @private
	  * @param  {object} item
	  * @return {object} pageListItem
	  */item(e){var t=fe(e,'a'),n=t.getAttribute('href')||'',r=t.textContent||'',a=parseInt(r),i=n.indexOf('epubcfi'),s,o,d;return-1==i?{href:n,page:a}:(s=n.split('#'),o=s[0],d=!!(1<s.length)&&s[1],{cfi:d,href:n,packageUrl:o,page:a})}/**
	  * Process pageList items
	  * @private
	  * @param  {array} pageList
	  */process(e){e.forEach(function(e){this.pages.push(e.page),e.cfi&&this.locations.push(e.cfi)},this),this.firstPage=parseInt(this.pages[0]),this.lastPage=parseInt(this.pages[this.pages.length-1]),this.totalPages=this.lastPage-this.firstPage}/**
	  * Get a PageList result from a EpubCFI
	  * @param  {string} cfi EpubCFI String
	  * @return {string} page
	  */pageFromCfi(e){var t=-1;// Check if the pageList has not been set yet
if(0===this.locations.length)return-1;// TODO: check if CFI is valid?
// check if the cfi is in the location list
// var index = this.locations.indexOf(cfi);
var n=ie(e,this.locations,this.epubcfi.compare);return-1==n?(n=ae(e,this.locations,this.epubcfi.compare),t=0<=n-1?this.pages[n-1]:this.pages[0],void 0!==t||(t=-1)):t=this.pages[n],t}/**
	  * Get an EpubCFI from a Page List Item
	  * @param  {string} pg
	  * @return {string} cfi
	  */cfiFromPage(e){var t=-1;// check that pg is an int
'number'!=typeof e&&(e=parseInt(e));// check if the cfi is in the page list
// Pages could be unsorted.
var n=this.pages.indexOf(e);// TODO: handle pages not in the list
return-1!=n&&(t=this.locations[n]),t}/**
	  * Get a Page from Book percentage
	  * @param  {number} percent
	  * @return {string} page
	  */pageFromPercentage(e){var t=Be(this.totalPages*e);return t}/**
	  * Returns a value between 0 - 1 corresponding to the location of a page
	  * @param  {int} pg the page
	  * @return {number} percentage
	  */percentageFromPage(e){var t=(e-this.firstPage)/this.totalPages;return Be(1e3*t)/1e3}/**
	  * Returns a value between 0 - 1 corresponding to the location of a cfi
	  * @param  {string} cfi EpubCFI String
	  * @return {number} percentage
	  */percentageFromCfi(e){var t=this.pageFromCfi(e),n=this.percentageFromPage(t);return n}/**
	  * Export pages as an Array
	  * @return {array}
	  */toArray(){return this.locations}/**
	  * Export pages as JSON
	  * @return {json}
	  */toJSON(){return JSON.stringify(this.locations)}destroy(){this.pages=void 0,this.locations=void 0,this.epubcfi=void 0,this.pageList=void 0,this.toc=void 0,this.ncx=void 0}}var Fn=t(function(t){(function(e){t.exports=e()})(function(){var t=Math.min;return function d(p,t,n){function r(i,o){if(!t[i]){if(!p[i]){var c='function'==typeof e&&e;if(!o&&c)return c(i,!0);if(s)return s(i,!0);var a=new Error('Cannot find module \''+i+'\'');throw a.code='MODULE_NOT_FOUND',a}var h=t[i]={exports:{}};p[i][0].call(h.exports,function(t){var e=p[i][1][t];return r(e?e:t)},h,h.exports,d,p,t,n)}return t[i].exports}for(var s='function'==typeof e&&e,a=0;a<n.length;a++)r(n[a]);return r}({1:[function(e,t,n){var r=e('./utils'),a=e('./support'),s='ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=';// private property
// public method for encoding
n.encode=function(e){for(var t=[],n=0,a=e.length,i=a,o='string'!==r.getTypeOf(e),d,l,p,c,u,h,m;n<e.length;)i=a-n,o?(d=e[n++],l=n<a?e[n++]:0,p=n<a?e[n++]:0):(d=e.charCodeAt(n++),l=n<a?e.charCodeAt(n++):0,p=n<a?e.charCodeAt(n++):0),c=d>>2,u=(3&d)<<4|l>>4,h=1<i?(15&l)<<2|p>>6:64,m=2<i?63&p:64,t.push(s.charAt(c)+s.charAt(u)+s.charAt(h)+s.charAt(m));return t.join('')},n.decode=function(e){var t=0,n=0,r='data:',i,o,d,l,p,c,u;if(e.substr(0,r.length)===r)// This is a common error: people give a data url
// (data:image/png;base64,iVBOR...) with a {base64: true} and
// wonders why things don't work.
// We can detect that the string input looks like a data url but we
// *can't* be sure it is one: removing everything up to the comma would
// be too dangerous.
throw new Error('Invalid base64 input, it looks like a data url.');e=e.replace(/[^A-Za-z0-9\+\/\=]/g,'');var h=3*e.length/4;if(e.charAt(e.length-1)===s.charAt(64)&&h--,e.charAt(e.length-2)===s.charAt(64)&&h--,0!=h%1)// totalLength is not an integer, the length does not match a valid
// base64 content. That can happen if:
// - the input is not a base64 content
// - the input is *almost* a base64 content, with a extra chars at the
//   beginning or at the end
// - the input uses a base64 variant (base64url for example)
throw new Error('Invalid base64 input, bad content length.');var m;for(m=a.uint8array?new Uint8Array(0|h):Array(0|h);t<e.length;)l=s.indexOf(e.charAt(t++)),p=s.indexOf(e.charAt(t++)),c=s.indexOf(e.charAt(t++)),u=s.indexOf(e.charAt(t++)),i=l<<2|p>>4,o=(15&p)<<4|c>>2,d=(3&c)<<6|u,m[n++]=i,64!==c&&(m[n++]=o),64!==u&&(m[n++]=d);return m}},{"./support":30,"./utils":32}],2:[function(e,t){/**
	 * Represent a compressed object, with everything needed to decompress it.
	 * @constructor
	 * @param {number} compressedSize the size of the data compressed.
	 * @param {number} uncompressedSize the size of the data after decompression.
	 * @param {number} crc32 the crc32 of the decompressed file.
	 * @param {object} compression the type of compression, see lib/compressions.js.
	 * @param {String|ArrayBuffer|Uint8Array|Buffer} data the compressed data.
	 */function n(e,t,n,r,a){this.compressedSize=e,this.uncompressedSize=t,this.crc32=n,this.compression=r,this.compressedContent=a}var r=e('./external'),a=e('./stream/DataWorker'),i=e('./stream/DataLengthProbe'),s=e('./stream/Crc32Probe'),i=e('./stream/DataLengthProbe');n.prototype={/**
	     * Create a worker to get the uncompressed content.
	     * @return {GenericWorker} the worker.
	     */getContentWorker:function(){var e=new a(r.Promise.resolve(this.compressedContent)).pipe(this.compression.uncompressWorker()).pipe(new i('data_length')),t=this;return e.on('end',function(){if(this.streamInfo.data_length!==t.uncompressedSize)throw new Error('Bug : uncompressed data size mismatch')}),e},/**
	     * Create a worker to get the compressed content.
	     * @return {GenericWorker} the worker.
	     */getCompressedWorker:function(){return new a(r.Promise.resolve(this.compressedContent)).withStreamInfo('compressedSize',this.compressedSize).withStreamInfo('uncompressedSize',this.uncompressedSize).withStreamInfo('crc32',this.crc32).withStreamInfo('compression',this.compression)}},n.createWorkerFrom=function(e,t,n){return e.pipe(new s).pipe(new i('uncompressedSize')).pipe(t.compressWorker(n)).pipe(new i('compressedSize')).withStreamInfo('compression',t)},t.exports=n},{"./external":6,"./stream/Crc32Probe":25,"./stream/DataLengthProbe":26,"./stream/DataWorker":27}],3:[function(e,t,n){var r=e('./stream/GenericWorker');n.STORE={magic:'\0\0',compressWorker:function(){return new r('STORE compression')},uncompressWorker:function(){return new r('STORE decompression')}},n.DEFLATE=e('./flate')},{"./flate":7,"./stream/GenericWorker":28}],4:[function(e,t){// Create table on load. Just 255 signed longs. Not a problem.
function n(e,t,n,r){e^=-1;for(var a=r;a<r+n;a++)e=e>>>8^s[255&(e^t[a])];return-1^e;// >>> 0;
}// That's all for the pako functions.
/**
	 * Compute the crc32 of a string.
	 * This is almost the same as the function crc32, but for strings. Using the
	 * same function for the two use cases leads to horrible performances.
	 * @param {Number} crc the starting value of the crc.
	 * @param {String} str the string to use.
	 * @param {Number} len the length of the string.
	 * @param {Number} pos the starting position for the crc32 computation.
	 * @return {Number} the computed crc32.
	 *//**
	 * The following functions come from pako, from pako/lib/zlib/crc32.js
	 * released under the MIT license, see pako https://github.com/nodeca/pako/
	 */// Use ordinary array, since untyped makes no boost here
function r(e,t,n,r){e^=-1;for(var a=r;a<r+n;a++)e=e>>>8^s[255&(e^t.charCodeAt(a))];return-1^e;// >>> 0;
}var a=e('./utils'),s=function(){for(var e=[],t=0,n;256>t;t++){n=t;for(var r=0;8>r;r++)n=1&n?3988292384^n>>>1:n>>>1;e[t]=n}return e}();t.exports=function(e,t){if('undefined'==typeof e||!e.length)return 0;var i='string'!==a.getTypeOf(e);return i?n(0|t,e,e.length,0):r(0|t,e,e.length,0)}},{"./utils":32}],5:[function(e,t,n){n.base64=!1,n.binary=!1,n.dir=!1,n.createFolders=!0,n.date=null,n.compression=null,n.compressionOptions=null,n.comment=null,n.unixPermissions=null,n.dosPermissions=null},{}],6:[function(e,t){// load the global object first:
// - it should be better integrated in the system (unhandledRejection in node)
// - the environment may have a custom Promise implementation (see zone.js)
var n=null;n='undefined'==typeof Promise?e('lie'):Promise,t.exports={Promise:n}},{lie:37}],7:[function(e,t,n){/**
	 * Create a worker that uses pako to inflate/deflate.
	 * @constructor
	 * @param {String} action the name of the pako function to call : either "Deflate" or "Inflate".
	 * @param {Object} options the options to use when (de)compressing.
	 */function r(e,t){o.call(this,'FlateWorker/'+e),this._pako=null,this._pakoAction=e,this._pakoOptions=t,this.meta={}}var a='undefined'!=typeof Uint8Array&&'undefined'!=typeof Uint16Array&&'undefined'!=typeof Uint32Array,i=e('pako'),s=e('./utils'),o=e('./stream/GenericWorker'),d=a?'uint8array':'array';n.magic='\b\0',s.inherits(r,o),r.prototype.processChunk=function(e){this.meta=e.meta,null===this._pako&&this._createPako(),this._pako.push(s.transformTo(d,e.data),!1)},r.prototype.flush=function(){o.prototype.flush.call(this),null===this._pako&&this._createPako(),this._pako.push([],!0)},r.prototype.cleanUp=function(){o.prototype.cleanUp.call(this),this._pako=null},r.prototype._createPako=function(){this._pako=new i[this._pakoAction]({raw:!0,level:this._pakoOptions.level||-1// default compression
});var e=this;this._pako.onData=function(t){e.push({data:t,meta:e.meta})}},n.compressWorker=function(e){return new r('Deflate',e)},n.uncompressWorker=function(){return new r('Inflate',{})}},{"./stream/GenericWorker":28,"./utils":32,pako:38}],8:[function(e,t){/**
	 * A worker to concatenate other workers to create a zip file.
	 * @param {Boolean} streamFiles `true` to stream the content of the files,
	 * `false` to accumulate it.
	 * @param {String} comment the comment to use.
	 * @param {String} platform the platform to use, "UNIX" or "DOS".
	 * @param {Function} encodeFileName the function to encode file names and comments.
	 */function n(e,t,n,r){a.call(this,'ZipFileWorker'),this.bytesWritten=0,this.zipComment=t,this.zipPlatform=n,this.encodeFileName=r,this.streamFiles=e,this.accumulate=!1,this.contentBuffer=[],this.dirRecords=[],this.currentSourceOffset=0,this.entriesCount=0,this.currentFile=null,this._sources=[]}var r=e('../utils'),a=e('../stream/GenericWorker'),i=e('../utf8'),s=e('../crc32'),o=e('../signature'),d=function(e,t){var n='',r;for(r=0;r<t;r++)n+=Fe(255&e),e>>>=8;return n},l=function(e,t){var n=e;return e||(n=t?16893:33204),(65535&n)<<16},p=function(e){// the dir flag is already set for compatibility
return 63&(e||0)},c=function(e,t,n,a,c,u){var h=e.file,m=e.compression,f=u!==i.utf8encode,g=r.transformTo('string',u(h.name)),_=r.transformTo('string',i.utf8encode(h.name)),b=h.comment,y=r.transformTo('string',u(b)),x=r.transformTo('string',i.utf8encode(b)),k=_.length!==h.name.length,v=x.length!==b.length,w='',N='',C='',E=h.dir,S=h.date,I={crc32:0,compressedSize:0,uncompressedSize:0},A,T;// if the content is streamed, the sizes/crc32 are only available AFTER
// the end of the stream.
(!t||n)&&(I.crc32=e.crc32,I.compressedSize=e.compressedSize,I.uncompressedSize=e.uncompressedSize);var O=0;t&&(O|=8),!f&&(k||v)&&(O|=2048);var z=0,D=0;E&&(z|=16),'UNIX'===c?(D=798,z|=l(h.unixPermissions,E)):(D=20,z|=p(h.dosPermissions,E)),A=S.getUTCHours(),A<<=6,A|=S.getUTCMinutes(),A<<=5,A|=S.getUTCSeconds()/2,T=S.getUTCFullYear()-1980,T<<=4,T|=S.getUTCMonth()+1,T<<=5,T|=S.getUTCDate(),k&&(N=// Version
d(1,1)+// NameCRC32
d(s(g),4)+// UnicodeName
_,w+=// Info-ZIP Unicode Path Extra Field
'up'+// size
d(N.length,2)+// content
N),v&&(C=// Version
d(1,1)+// CommentCRC32
d(s(y),4)+// UnicodeName
x,w+=// Info-ZIP Unicode Path Extra Field
'uc'+// size
d(C.length,2)+// content
C);var R='';// version needed to extract
R+='\n\0',R+=d(O,2),R+=m.magic,R+=d(A,2),R+=d(T,2),R+=d(I.crc32,4),R+=d(I.compressedSize,4),R+=d(I.uncompressedSize,4),R+=d(g.length,2),R+=d(w.length,2);var B=o.LOCAL_FILE_HEADER+R+g+w,P=o.CENTRAL_FILE_HEADER+// version made by (00: DOS)
d(D,2)+// file header (common to file and central directory)
R+// file comment length
d(y.length,2)+// disk number start
'\0\0\0\0'+// external file attributes
d(z,4)+// relative offset of local header
d(a,4)+// file name
g+// extra field
w+// file comment
y;return{fileRecord:B,dirRecord:P}},u=function(e,t,n,a,i){var s='',l=r.transformTo('string',i(a));// end of central dir signature
return s=o.CENTRAL_DIRECTORY_END+// number of this disk
'\0\0\0\0'+// total number of entries in the central directory on this disk
d(e,2)+// total number of entries in the central directory
d(e,2)+// size of the central directory   4 bytes
d(t,4)+// offset of start of central directory with respect to the starting disk number
d(n,4)+// .ZIP file comment length
d(l.length,2)+// .ZIP file comment
l,s},h=function(e){var t='';return t=o.DATA_DESCRIPTOR+// crc-32                          4 bytes
d(e.crc32,4)+// compressed size                 4 bytes
d(e.compressedSize,4)+// uncompressed size               4 bytes
d(e.uncompressedSize,4),t};/**
	 * Transform an integer into a string in hexadecimal.
	 * @private
	 * @param {number} dec the number to convert.
	 * @param {number} bytes the number of bytes to generate.
	 * @returns {string} the result.
	 *//**
	 * Generate the UNIX part of the external file attributes.
	 * @param {Object} unixPermissions the unix permissions or null.
	 * @param {Boolean} isDir true if the entry is a directory, false otherwise.
	 * @return {Number} a 32 bit integer.
	 *
	 * adapted from http://unix.stackexchange.com/questions/14705/the-zip-formats-external-file-attribute :
	 *
	 * TTTTsstrwxrwxrwx0000000000ADVSHR
	 * ^^^^____________________________ file type, see zipinfo.c (UNX_*)
	 *     ^^^_________________________ setuid, setgid, sticky
	 *        ^^^^^^^^^________________ permissions
	 *                 ^^^^^^^^^^______ not used ?
	 *                           ^^^^^^ DOS attribute bits : Archive, Directory, Volume label, System file, Hidden, Read only
	 *//**
	 * Generate the DOS part of the external file attributes.
	 * @param {Object} dosPermissions the dos permissions or null.
	 * @param {Boolean} isDir true if the entry is a directory, false otherwise.
	 * @return {Number} a 32 bit integer.
	 *
	 * Bit 0     Read-Only
	 * Bit 1     Hidden
	 * Bit 2     System
	 * Bit 3     Volume Label
	 * Bit 4     Directory
	 * Bit 5     Archive
	 *//**
	 * Generate the various parts used in the construction of the final zip file.
	 * @param {Object} streamInfo the hash with information about the compressed file.
	 * @param {Boolean} streamedContent is the content streamed ?
	 * @param {Boolean} streamingEnded is the stream finished ?
	 * @param {number} offset the current offset from the start of the zip file.
	 * @param {String} platform let's pretend we are this platform (change platform dependents fields)
	 * @param {Function} encodeFileName the function to encode the file name / comment.
	 * @return {Object} the zip parts.
	 *//**
	 * Generate the EOCD record.
	 * @param {Number} entriesCount the number of entries in the zip file.
	 * @param {Number} centralDirLength the length (in bytes) of the central dir.
	 * @param {Number} localDirLength the length (in bytes) of the local dir.
	 * @param {String} comment the zip file comment as a binary string.
	 * @param {Function} encodeFileName the function to encode the comment.
	 * @return {String} the EOCD record.
	 *//**
	 * Generate data descriptors for a file entry.
	 * @param {Object} streamInfo the hash generated by a worker, containing information
	 * on the file entry.
	 * @return {String} the data descriptors.
	 */r.inherits(n,a),n.prototype.push=function(e){var t=e.meta.percent||0,n=this.entriesCount,r=this._sources.length;this.accumulate?this.contentBuffer.push(e):(this.bytesWritten+=e.data.length,a.prototype.push.call(this,{data:e.data,meta:{currentFile:this.currentFile,percent:n?(t+100*(n-r-1))/n:100}}))},n.prototype.openedSource=function(e){this.currentSourceOffset=this.bytesWritten,this.currentFile=e.file.name;var t=this.streamFiles&&!e.file.dir;// don't stream folders (because they don't have any content)
if(t){var n=c(e,t,!1,this.currentSourceOffset,this.zipPlatform,this.encodeFileName);this.push({data:n.fileRecord,meta:{percent:0}})}else this.accumulate=!0},n.prototype.closedSource=function(e){this.accumulate=!1;var t=this.streamFiles&&!e.file.dir,n=c(e,t,!0,this.currentSourceOffset,this.zipPlatform,this.encodeFileName);if(this.dirRecords.push(n.dirRecord),t)this.push({data:h(e),meta:{percent:100}});else for(this.push({data:n.fileRecord,meta:{percent:0}});this.contentBuffer.length;)this.push(this.contentBuffer.shift());this.currentFile=null},n.prototype.flush=function(){for(var e=this.bytesWritten,t=0;t<this.dirRecords.length;t++)this.push({data:this.dirRecords[t],meta:{percent:100}});var n=this.bytesWritten-e,r=u(this.dirRecords.length,n,e,this.zipComment,this.encodeFileName);this.push({data:r,meta:{percent:100}})},n.prototype.prepareNextSource=function(){this.previous=this._sources.shift(),this.openedSource(this.previous.streamInfo),this.isPaused?this.previous.pause():this.previous.resume()},n.prototype.registerPrevious=function(e){this._sources.push(e);var t=this;return e.on('data',function(e){t.processChunk(e)}),e.on('end',function(){t.closedSource(t.previous.streamInfo),t._sources.length?t.prepareNextSource():t.end()}),e.on('error',function(n){t.error(n)}),this},n.prototype.resume=function(){return!!a.prototype.resume.call(this)&&(!this.previous&&this._sources.length?(this.prepareNextSource(),!0):this.previous||this._sources.length||this.generatedError?void 0:(this.end(),!0))},n.prototype.error=function(t){var e=this._sources;if(!a.prototype.error.call(this,t))return!1;for(var n=0;n<e.length;n++)try{e[n].error(t)}catch(t){// the `error` exploded, nothing to do
}return!0},n.prototype.lock=function(){a.prototype.lock.call(this);for(var e=this._sources,t=0;t<e.length;t++)e[t].lock()},t.exports=n},{"../crc32":4,"../signature":23,"../stream/GenericWorker":28,"../utf8":31,"../utils":32}],9:[function(e,t,n){var r=e('../compressions'),a=e('./ZipFileWorker'),i=function(e,t){var n=e||t,a=r[n];if(!a)throw new Error(n+' is not a valid compression method !');return a};/**
	 * Find the compression to use.
	 * @param {String} fileCompression the compression defined at the file level, if any.
	 * @param {String} zipCompression the compression defined at the load() level.
	 * @return {Object} the compression object to use.
	 *//**
	 * Create a worker to generate a zip file.
	 * @param {JSZip} zip the JSZip instance at the right root level.
	 * @param {Object} options to generate the zip file.
	 * @param {String} comment the comment to use.
	 */n.generateWorker=function(e,t,n){var r=new a(t.streamFiles,n,t.platform,t.encodeFileName),s=0;try{e.forEach(function(e,n){s++;var a=i(n.options.compression,t.compression),o=n.options.compressionOptions||t.compressionOptions||{},d=n.dir,l=n.date;n._compressWorker(a,o).withStreamInfo('file',{name:e,dir:d,date:l,comment:n.comment||'',unixPermissions:n.unixPermissions,dosPermissions:n.dosPermissions}).pipe(r)}),r.entriesCount=s}catch(t){r.error(t)}return r}},{"../compressions":3,"./ZipFileWorker":8}],10:[function(e,t){/**
	 * Representation a of zip file in js
	 * @constructor
	 */function n(){// if this constructor is used without `new`, it adds `new` before itself:
if(!(this instanceof n))return new n;if(arguments.length)throw new Error('The constructor with parameters has been removed in JSZip 3.0, please check the upgrade guide.');// object containing the files :
// {
//   "folder/" : {...},
//   "folder/data.txt" : {...}
// }
this.files={},this.comment=null,this.root='',this.clone=function(){var e=new n;for(var t in this)'function'!=typeof this[t]&&(e[t]=this[t]);return e}}n.prototype=e('./object'),n.prototype.loadAsync=e('./load'),n.support=e('./support'),n.defaults=e('./defaults'),n.version='3.5.0',n.loadAsync=function(e,t){return new n().loadAsync(e,t)},n.external=e('./external'),t.exports=n},{"./defaults":5,"./external":6,"./load":11,"./object":15,"./support":30}],11:[function(e,t){/**
	 * Check the CRC32 of an entry.
	 * @param {ZipEntry} zipEntry the zip entry to check.
	 * @return {Promise} the result.
	 */function n(e){return new a.Promise(function(t,n){var r=e.decompressed.getContentWorker().pipe(new o);r.on('error',function(t){n(t)}).on('end',function(){r.streamInfo.crc32===e.decompressed.crc32?t():n(new Error('Corrupted zip : CRC32 mismatch'))}).resume()})}var r=e('./utils'),a=e('./external'),i=e('./utf8'),r=e('./utils'),s=e('./zipEntries'),o=e('./stream/Crc32Probe'),d=e('./nodejsUtils');t.exports=function(e,t){var o=this;return t=r.extend(t||{},{base64:!1,checkCRC32:!1,optimizedBinaryString:!1,createFolders:!1,decodeFileName:i.utf8decode}),d.isNode&&d.isStream(e)?a.Promise.reject(new Error('JSZip can\'t accept a stream when loading a zip file.')):r.prepareContent('the loaded zip file',e,!0,t.optimizedBinaryString,t.base64).then(function(e){var n=new s(t);return n.load(e),n}).then(function(e){var r=[a.Promise.resolve(e)],s=e.files;if(t.checkCRC32)for(var o=0;o<s.length;o++)r.push(n(s[o]));return a.Promise.all(r)}).then(function(e){for(var n=e.shift(),r=n.files,a=0,i;a<r.length;a++)i=r[a],o.file(i.fileNameStr,i.decompressed,{binary:!0,optimizedBinaryString:!0,date:i.date,dir:i.dir,comment:i.fileCommentStr.length?i.fileCommentStr:null,unixPermissions:i.unixPermissions,dosPermissions:i.dosPermissions,createFolders:t.createFolders});return n.zipComment.length&&(o.comment=n.zipComment),o})}},{"./external":6,"./nodejsUtils":14,"./stream/Crc32Probe":25,"./utf8":31,"./utils":32,"./zipEntries":33}],12:[function(e,t){/**
	 * A worker that use a nodejs stream as source.
	 * @constructor
	 * @param {String} filename the name of the file entry for this stream.
	 * @param {Readable} stream the nodejs stream.
	 */function n(e,t){a.call(this,'Nodejs stream input adapter for '+e),this._upstreamEnded=!1,this._bindStream(t)}var r=e('../utils'),a=e('../stream/GenericWorker');r.inherits(n,a),n.prototype._bindStream=function(e){var t=this;this._stream=e,e.pause(),e.on('data',function(e){t.push({data:e,meta:{percent:0}})}).on('error',function(n){t.isPaused?this.generatedError=n:t.error(n)}).on('end',function(){t.isPaused?t._upstreamEnded=!0:t.end()})},n.prototype.pause=function(){return!!a.prototype.pause.call(this)&&(this._stream.pause(),!0)},n.prototype.resume=function(){return!!a.prototype.resume.call(this)&&(this._upstreamEnded?this.end():this._stream.resume(),!0)},t.exports=n},{"../stream/GenericWorker":28,"../utils":32}],13:[function(e,t){/**
	* A nodejs stream using a worker as source.
	* @see the SourceWrapper in http://nodejs.org/api/stream.html
	* @constructor
	* @param {StreamHelper} helper the helper wrapping the worker
	* @param {Object} options the nodejs stream options
	* @param {Function} updateCb the update callback.
	*/function n(e,t,n){r.call(this,t),this._helper=e;var a=this;e.on('data',function(e,t){a.push(e)||a._helper.pause(),n&&n(t)}).on('error',function(t){a.emit('error',t)}).on('end',function(){a.push(null)})}var r=e('readable-stream').Readable,a=e('../utils');a.inherits(n,r),n.prototype._read=function(){this._helper.resume()},t.exports=n},{"../utils":32,"readable-stream":16}],14:[function(e,t){t.exports={/**
	     * True if this is running in Nodejs, will be undefined in a browser.
	     * In a browser, browserify won't include this file and the whole module
	     * will be resolved an empty object.
	     */isNode:'undefined'!=typeof Buffer,/**
	     * Create a new nodejs Buffer from an existing content.
	     * @param {Object} data the data to pass to the constructor.
	     * @param {String} encoding the encoding to use.
	     * @return {Buffer} a new Buffer.
	     */newBufferFrom:function(e,t){if(Buffer.from&&Buffer.from!==Uint8Array.from)return Buffer.from(e,t);if('number'==typeof e)// Safeguard for old Node.js versions. On newer versions,
// Buffer.from(number) / Buffer(number, encoding) already throw.
throw new Error('The "data" argument must not be a number');return new Buffer(e,t)},/**
	     * Create a new nodejs Buffer with the specified size.
	     * @param {Integer} size the size of the buffer.
	     * @return {Buffer} a new Buffer.
	     */allocBuffer:function(e){if(Buffer.alloc)return Buffer.alloc(e);var t=new Buffer(e);return t.fill(0),t},/**
	     * Find out if an object is a Buffer.
	     * @param {Object} b the object to test.
	     * @return {Boolean} true if the object is a Buffer, false otherwise.
	     */isBuffer:function(e){return Buffer.isBuffer(e)},isStream:function(e){return e&&'function'==typeof e.on&&'function'==typeof e.pause&&'function'==typeof e.resume}}},{}],15:[function(e,t){/**
	* Cross-window, cross-Node-context regular expression detection
	* @param  {Object}  object Anything
	* @return {Boolean}        true if the object is a regular expression,
	* false otherwise
	*/function n(e){return'[object RegExp]'===Object.prototype.toString.call(e)}// return the actual prototype of JSZip
var r=e('./utf8'),a=e('./utils'),i=e('./stream/GenericWorker'),s=e('./stream/StreamHelper'),d=e('./defaults'),l=e('./compressedObject'),p=e('./zipObject'),o=e('./generate'),c=e('./nodejsUtils'),u=e('./nodejs/NodejsStreamInputAdapter'),h=function(e,t,n){// be sure sub folders exist
var r=a.getTypeOf(t),s=a.extend(n||{},d),o;/*
	     * Correct options.
	     */s.date=s.date||new Date,null!==s.compression&&(s.compression=s.compression.toUpperCase()),'string'==typeof s.unixPermissions&&(s.unixPermissions=parseInt(s.unixPermissions,8)),s.unixPermissions&&16384&s.unixPermissions&&(s.dir=!0),s.dosPermissions&&16&s.dosPermissions&&(s.dir=!0),s.dir&&(e=f(e)),s.createFolders&&(o=m(e))&&g.call(this,o,!0);var h='string'===r&&!1===s.binary&&!1===s.base64;n&&'undefined'!=typeof n.binary||(s.binary=!h);var _=t instanceof l&&0===t.uncompressedSize;(_||s.dir||!t||0===t.length)&&(s.base64=!1,s.binary=!0,t='',s.compression='STORE',r='string');/*
	     * Convert content to fit.
	     */var b=null;b=t instanceof l||t instanceof i?t:c.isNode&&c.isStream(t)?new u(e,t):a.prepareContent(e,t,s.binary,s.optimizedBinaryString,s.base64);var y=new p(e,b,s);this.files[e]=y},m=function(e){'/'===e.slice(-1)&&(e=e.substring(0,e.length-1));var t=e.lastIndexOf('/');return 0<t?e.substring(0,t):''},f=function(e){return'/'!==e.slice(-1)&&(e+='/'),e},g=function(e,t){return t='undefined'==typeof t?d.createFolders:t,e=f(e),this.files[e]||h.call(this,e,null,{dir:!0,createFolders:t}),this.files[e]};/**
	 * Add a file in the current folder.
	 * @private
	 * @param {string} name the name of the file
	 * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data of the file
	 * @param {Object} originalOptions the options of the file
	 * @return {Object} the new file.
	 *//**
	 * Find the parent folder of the path.
	 * @private
	 * @param {string} path the path to use
	 * @return {string} the parent folder, or ""
	 *//**
	 * Returns the path with a slash at the end.
	 * @private
	 * @param {String} path the path to check.
	 * @return {String} the path with a trailing slash.
	 *//**
	 * Add a (sub) folder in the current folder.
	 * @private
	 * @param {string} name the folder's name
	 * @param {boolean=} [createFolders] If true, automatically create sub
	 *  folders. Defaults to false.
	 * @return {Object} the new folder.
	 */t.exports={/**
	     * @see loadAsync
	     */load:function(){throw new Error('This method has been removed in JSZip 3.0, please check the upgrade guide.')},/**
	     * Call a callback function for each entry at this folder level.
	     * @param {Function} cb the callback function:
	     * function (relativePath, file) {...}
	     * It takes 2 arguments : the relative path and the file.
	     */forEach:function(e){var t,n,r;for(t in this.files)this.files.hasOwnProperty(t)&&(r=this.files[t],n=t.slice(this.root.length,t.length),n&&t.slice(0,this.root.length)===this.root&&e(n,r))},/**
	     * Filter nested files/folders with the specified function.
	     * @param {Function} search the predicate to use :
	     * function (relativePath, file) {...}
	     * It takes 2 arguments : the relative path and the file.
	     * @return {Array} An array of matching elements.
	     */filter:function(e){var t=[];return this.forEach(function(n,r){e(n,r)&&t.push(r)}),t},/**
	     * Add a file to the zip file, or search a file.
	     * @param   {string|RegExp} name The name of the file to add (if data is defined),
	     * the name of the file to find (if no data) or a regex to match files.
	     * @param   {String|ArrayBuffer|Uint8Array|Buffer} data  The file data, either raw or base64 encoded
	     * @param   {Object} o     File options
	     * @return  {JSZip|Object|Array} this JSZip object (when adding a file),
	     * a file (when searching by string) or an array of files (when searching by regex).
	     */file:function(e,t,r){if(1===arguments.length){if(n(e)){var a=e;return this.filter(function(e,t){return!t.dir&&a.test(e)})}// text
var i=this.files[this.root+e];return i&&!i.dir?i:null}return e=this.root+e,h.call(this,e,t,r),this},/**
	     * Add a directory to the zip file, or search.
	     * @param   {String|RegExp} arg The name of the directory to add, or a regex to search folders.
	     * @return  {JSZip} an object with the new directory as the root, or an array containing matching folders.
	     */folder:function(e){if(!e)return this;if(n(e))return this.filter(function(t,n){return n.dir&&e.test(t)});// else, name is a new folder
var t=this.root+e,r=g.call(this,t),a=this.clone();// Allow chaining by returning a new object with this folder as the root
return a.root=r.name,a},/**
	     * Delete a file, or a directory and all sub-files, from the zip
	     * @param {string} name the name of the file to delete
	     * @return {JSZip} this JSZip object
	     */remove:function(e){e=this.root+e;var t=this.files[e];if(t||('/'!==e.slice(-1)&&(e+='/'),t=this.files[e]),t&&!t.dir)delete this.files[e];else for(var n=this.filter(function(t,n){return n.name.slice(0,e.length)===e}),r=0;r<n.length;r++)delete this.files[n[r].name];// maybe a folder, delete recursively
return this},/**
	     * Generate the complete zip file
	     * @param {Object} options the options to generate the zip file :
	     * - compression, "STORE" by default.
	     * - type, "base64" by default. Values are : string, base64, uint8array, arraybuffer, blob.
	     * @return {String|Uint8Array|ArrayBuffer|Buffer|Blob} the zip file
	     */generate:function(){throw new Error('This method has been removed in JSZip 3.0, please check the upgrade guide.')},/**
	     * Generate the complete zip file as an internal stream.
	     * @param {Object} options the options to generate the zip file :
	     * - compression, "STORE" by default.
	     * - type, "base64" by default. Values are : string, base64, uint8array, arraybuffer, blob.
	     * @return {StreamHelper} the streamed zip file.
	     */generateInternalStream:function(e){var t={},n;try{if(t=a.extend(e||{},{streamFiles:!1,compression:'STORE',compressionOptions:null,type:'',platform:'DOS',comment:null,mimeType:'application/zip',encodeFileName:r.utf8encode}),t.type=t.type.toLowerCase(),t.compression=t.compression.toUpperCase(),'binarystring'===t.type&&(t.type='string'),!t.type)throw new Error('No output type specified.');a.checkSupport(t.type),('darwin'===t.platform||'freebsd'===t.platform||'linux'===t.platform||'sunos'===t.platform)&&(t.platform='UNIX'),'win32'===t.platform&&(t.platform='DOS');var d=t.comment||this.comment||'';n=o.generateWorker(this,t,d)}catch(t){n=new i('error'),n.error(t)}return new s(n,t.type||'string',t.mimeType)},/**
	     * Generate the complete zip file asynchronously.
	     * @see generateInternalStream
	     */generateAsync:function(e,t){return this.generateInternalStream(e).accumulate(t)},/**
	     * Generate the complete zip file asynchronously.
	     * @see generateInternalStream
	     */generateNodeStream:function(e,t){return e=e||{},e.type||(e.type='nodebuffer'),this.generateInternalStream(e).toNodejsStream(t)}}},{"./compressedObject":2,"./defaults":5,"./generate":9,"./nodejs/NodejsStreamInputAdapter":12,"./nodejsUtils":14,"./stream/GenericWorker":28,"./stream/StreamHelper":29,"./utf8":31,"./utils":32,"./zipObject":35}],16:[function(e,t){t.exports=e('stream')},{stream:void 0}],17:[function(e,t){function n(e){r.call(this,e);for(var t=0;t<this.data.length;t++)e[t]&=255}var r=e('./DataReader'),a=e('../utils');a.inherits(n,r),n.prototype.byteAt=function(e){return this.data[this.zero+e]},n.prototype.lastIndexOfSignature=function(e){for(var t=e.charCodeAt(0),n=e.charCodeAt(1),r=e.charCodeAt(2),a=e.charCodeAt(3),s=this.length-4;0<=s;--s)if(this.data[s]===t&&this.data[s+1]===n&&this.data[s+2]===r&&this.data[s+3]===a)return s-this.zero;return-1},n.prototype.readAndCheckSignature=function(e){var t=e.charCodeAt(0),n=e.charCodeAt(1),r=e.charCodeAt(2),a=e.charCodeAt(3),i=this.readData(4);return t===i[0]&&n===i[1]&&r===i[2]&&a===i[3]},n.prototype.readData=function(e){if(this.checkOffset(e),0===e)return[];var t=this.data.slice(this.zero+this.index,this.zero+this.index+e);return this.index+=e,t},t.exports=n},{"../utils":32,"./DataReader":18}],18:[function(e,t){function n(e){this.data=e,this.length=e.length,this.index=0,this.zero=0}var r=e('../utils');n.prototype={/**
	     * Check that the offset will not go too far.
	     * @param {string} offset the additional offset to check.
	     * @throws {Error} an Error if the offset is out of bounds.
	     */checkOffset:function(e){this.checkIndex(this.index+e)},/**
	     * Check that the specified index will not be too far.
	     * @param {string} newIndex the index to check.
	     * @throws {Error} an Error if the index is out of bounds.
	     */checkIndex:function(e){if(this.length<this.zero+e||0>e)throw new Error('End of data reached (data length = '+this.length+', asked index = '+e+'). Corrupted zip ?')},/**
	     * Change the index.
	     * @param {number} newIndex The new index.
	     * @throws {Error} if the new index is out of the data.
	     */setIndex:function(e){this.checkIndex(e),this.index=e},/**
	     * Skip the next n bytes.
	     * @param {number} n the number of bytes to skip.
	     * @throws {Error} if the new index is out of the data.
	     */skip:function(e){this.setIndex(this.index+e)},/**
	     * Get the byte at the specified index.
	     * @param {number} i the index to use.
	     * @return {number} a byte.
	     */byteAt:function(){// see implementations
},/**
	     * Get the next number with a given byte size.
	     * @param {number} size the number of bytes to read.
	     * @return {number} the corresponding number.
	     */readInt:function(e){var t=0,n;for(this.checkOffset(e),n=this.index+e-1;n>=this.index;n--)t=(t<<8)+this.byteAt(n);return this.index+=e,t},/**
	     * Get the next string with a given byte size.
	     * @param {number} size the number of bytes to read.
	     * @return {string} the corresponding string.
	     */readString:function(e){return r.transformTo('string',this.readData(e))},/**
	     * Get raw data without conversion, <size> bytes.
	     * @param {number} size the number of bytes to read.
	     * @return {Object} the raw data, implementation specific.
	     */readData:function(){// see implementations
},/**
	     * Find the last occurrence of a zip signature (4 bytes).
	     * @param {string} sig the signature to find.
	     * @return {number} the index of the last occurrence, -1 if not found.
	     */lastIndexOfSignature:function(){// see implementations
},/**
	     * Read the signature (4 bytes) at the current position and compare it with sig.
	     * @param {string} sig the expected signature
	     * @return {boolean} true if the signature matches, false otherwise.
	     */readAndCheckSignature:function(){// see implementations
},/**
	     * Get the next date.
	     * @return {Date} the date.
	     */readDate:function(){var e=this.readInt(4);return new Date(Date.UTC((127&e>>25)+1980,// year
(15&e>>21)-1,// month
31&e>>16,// day
31&e>>11,// hour
63&e>>5,// minute
(31&e)<<1));// second
}},t.exports=n},{"../utils":32}],19:[function(e,t){function n(e){r.call(this,e)}var r=e('./Uint8ArrayReader'),a=e('../utils');a.inherits(n,r),n.prototype.readData=function(e){this.checkOffset(e);var t=this.data.slice(this.zero+this.index,this.zero+this.index+e);return this.index+=e,t},t.exports=n},{"../utils":32,"./Uint8ArrayReader":21}],20:[function(e,t){function n(e){r.call(this,e)}var r=e('./DataReader'),a=e('../utils');a.inherits(n,r),n.prototype.byteAt=function(e){return this.data.charCodeAt(this.zero+e)},n.prototype.lastIndexOfSignature=function(e){return this.data.lastIndexOf(e)-this.zero},n.prototype.readAndCheckSignature=function(e){var t=this.readData(4);return e===t},n.prototype.readData=function(e){this.checkOffset(e);// this will work because the constructor applied the "& 0xff" mask.
var t=this.data.slice(this.zero+this.index,this.zero+this.index+e);return this.index+=e,t},t.exports=n},{"../utils":32,"./DataReader":18}],21:[function(e,t){function n(e){r.call(this,e)}var r=e('./ArrayReader'),a=e('../utils');a.inherits(n,r),n.prototype.readData=function(e){if(this.checkOffset(e),0===e)// in IE10, when using subarray(idx, idx), we get the array [0x00] instead of [].
return new Uint8Array(0);var t=this.data.subarray(this.zero+this.index,this.zero+this.index+e);return this.index+=e,t},t.exports=n},{"../utils":32,"./ArrayReader":17}],22:[function(e,t){var n=e('../utils'),r=e('../support'),a=e('./ArrayReader'),i=e('./StringReader'),s=e('./NodeBufferReader'),o=e('./Uint8ArrayReader');/**
	 * Create a reader adapted to the data.
	 * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data to read.
	 * @return {DataReader} the data reader.
	 */t.exports=function(e){var t=n.getTypeOf(e);return n.checkSupport(t),'string'!==t||r.uint8array?'nodebuffer'===t?new s(e):r.uint8array?new o(n.transformTo('uint8array',e)):new a(n.transformTo('array',e)):new i(e)}},{"../support":30,"../utils":32,"./ArrayReader":17,"./NodeBufferReader":19,"./StringReader":20,"./Uint8ArrayReader":21}],23:[function(e,t,n){n.LOCAL_FILE_HEADER='PK\x03\x04',n.CENTRAL_FILE_HEADER='PK\x01\x02',n.CENTRAL_DIRECTORY_END='PK\x05\x06',n.ZIP64_CENTRAL_DIRECTORY_LOCATOR='PK\x06\x07',n.ZIP64_CENTRAL_DIRECTORY_END='PK\x06\x06',n.DATA_DESCRIPTOR='PK\x07\b'},{}],24:[function(e,t){/**
	 * A worker which convert chunks to a specified type.
	 * @constructor
	 * @param {String} destType the destination type.
	 */function n(e){r.call(this,'ConvertWorker to '+e),this.destType=e}var r=e('./GenericWorker'),a=e('../utils');a.inherits(n,r),n.prototype.processChunk=function(e){this.push({data:a.transformTo(this.destType,e.data),meta:e.meta})},t.exports=n},{"../utils":32,"./GenericWorker":28}],25:[function(e,t){/**
	 * A worker which calculate the crc32 of the data flowing through.
	 * @constructor
	 */function n(){r.call(this,'Crc32Probe'),this.withStreamInfo('crc32',0)}var r=e('./GenericWorker'),a=e('../crc32'),i=e('../utils');i.inherits(n,r),n.prototype.processChunk=function(e){this.streamInfo.crc32=a(e.data,this.streamInfo.crc32||0),this.push(e)},t.exports=n},{"../crc32":4,"../utils":32,"./GenericWorker":28}],26:[function(e,t){/**
	 * A worker which calculate the total length of the data flowing through.
	 * @constructor
	 * @param {String} propName the name used to expose the length
	 */function n(e){a.call(this,'DataLengthProbe for '+e),this.propName=e,this.withStreamInfo(e,0)}var r=e('../utils'),a=e('./GenericWorker');r.inherits(n,a),n.prototype.processChunk=function(e){if(e){var t=this.streamInfo[this.propName]||0;this.streamInfo[this.propName]=t+e.data.length}a.prototype.processChunk.call(this,e)},t.exports=n},{"../utils":32,"./GenericWorker":28}],27:[function(e,n){/**
	 * A worker that reads a content and emits chunks.
	 * @constructor
	 * @param {Promise} dataP the promise of the data to split
	 */function r(e){i.call(this,'DataWorker');var t=this;this.dataIsReady=!1,this.index=0,this.max=0,this.data=null,this.type='',this._tickScheduled=!1,e.then(function(e){t.dataIsReady=!0,t.data=e,t.max=e&&e.length||0,t.type=a.getTypeOf(e),t.isPaused||t._tickAndRepeat()},function(n){t.error(n)})}var a=e('../utils'),i=e('./GenericWorker');// the size of the generated chunks
// TODO expose this as a public variable
a.inherits(r,i),r.prototype.cleanUp=function(){i.prototype.cleanUp.call(this),this.data=null},r.prototype.resume=function(){return!!i.prototype.resume.call(this)&&(!this._tickScheduled&&this.dataIsReady&&(this._tickScheduled=!0,a.delay(this._tickAndRepeat,[],this)),!0)},r.prototype._tickAndRepeat=function(){this._tickScheduled=!1;this.isPaused||this.isFinished||(this._tick(),!this.isFinished&&(a.delay(this._tickAndRepeat,[],this),this._tickScheduled=!0))},r.prototype._tick=function(){if(this.isPaused||this.isFinished)return!1;var e=null,n=t(this.max,this.index+16384);if(this.index>=this.max)// EOF
return this.end();switch(this.type){case'string':e=this.data.substring(this.index,n);break;case'uint8array':e=this.data.subarray(this.index,n);break;case'array':case'nodebuffer':e=this.data.slice(this.index,n);}return this.index=n,this.push({data:e,meta:{percent:this.max?100*(this.index/this.max):0}})},n.exports=r},{"../utils":32,"./GenericWorker":28}],28:[function(e,t){/**
	 * A worker that does nothing but passing chunks to the next one. This is like
	 * a nodejs stream but with some differences. On the good side :
	 * - it works on IE 6-9 without any issue / polyfill
	 * - it weights less than the full dependencies bundled with browserify
	 * - it forwards errors (no need to declare an error handler EVERYWHERE)
	 *
	 * A chunk is an object with 2 attributes : `meta` and `data`. The former is an
	 * object containing anything (`percent` for example), see each worker for more
	 * details. The latter is the real data (String, Uint8Array, etc).
	 *
	 * @constructor
	 * @param {String} name the name of the stream (mainly used for debugging purposes)
	 */function n(e){this.name=e||'default',this.streamInfo={},this.generatedError=null,this.extraStreamInfo={},this.isPaused=!0,this.isFinished=!1,this.isLocked=!1,this._listeners={data:[],end:[],error:[]},this.previous=null}n.prototype={/**
	     * Push a chunk to the next workers.
	     * @param {Object} chunk the chunk to push
	     */push:function(e){this.emit('data',e)},/**
	     * End the stream.
	     * @return {Boolean} true if this call ended the worker, false otherwise.
	     */end:function(){if(this.isFinished)return!1;this.flush();try{this.emit('end'),this.cleanUp(),this.isFinished=!0}catch(t){this.emit('error',t)}return!0},/**
	     * End the stream with an error.
	     * @param {Error} e the error which caused the premature end.
	     * @return {Boolean} true if this call ended the worker with an error, false otherwise.
	     */error:function(t){return!this.isFinished&&(this.isPaused?this.generatedError=t:(this.isFinished=!0,this.emit('error',t),this.previous&&this.previous.error(t),this.cleanUp()),!0)},/**
	     * Add a callback on an event.
	     * @param {String} name the name of the event (data, end, error)
	     * @param {Function} listener the function to call when the event is triggered
	     * @return {GenericWorker} the current object for chainability
	     */on:function(e,t){return this._listeners[e].push(t),this},/**
	     * Clean any references when a worker is ending.
	     */cleanUp:function(){this.streamInfo=this.generatedError=this.extraStreamInfo=null,this._listeners=[]},/**
	     * Trigger an event. This will call registered callback with the provided arg.
	     * @param {String} name the name of the event (data, end, error)
	     * @param {Object} arg the argument to call the callback with.
	     */emit:function(e,t){if(this._listeners[e])for(var n=0;n<this._listeners[e].length;n++)this._listeners[e][n].call(this,t)},/**
	     * Chain a worker with an other.
	     * @param {Worker} next the worker receiving events from the current one.
	     * @return {worker} the next worker for chainability
	     */pipe:function(e){return e.registerPrevious(this)},/**
	     * Same as `pipe` in the other direction.
	     * Using an API with `pipe(next)` is very easy.
	     * Implementing the API with the point of view of the next one registering
	     * a source is easier, see the ZipFileWorker.
	     * @param {Worker} previous the previous worker, sending events to this one
	     * @return {Worker} the current worker for chainability
	     */registerPrevious:function(e){if(this.isLocked)throw new Error('The stream \''+this+'\' has already been used.');// sharing the streamInfo...
this.streamInfo=e.streamInfo,this.mergeStreamInfo(),this.previous=e;var t=this;return e.on('data',function(e){t.processChunk(e)}),e.on('end',function(){t.end()}),e.on('error',function(n){t.error(n)}),this},/**
	     * Pause the stream so it doesn't send events anymore.
	     * @return {Boolean} true if this call paused the worker, false otherwise.
	     */pause:function(){return!(this.isPaused||this.isFinished)&&(this.isPaused=!0,this.previous&&this.previous.pause(),!0)},/**
	     * Resume a paused stream.
	     * @return {Boolean} true if this call resumed the worker, false otherwise.
	     */resume:function(){if(!this.isPaused||this.isFinished)return!1;this.isPaused=!1;// if true, the worker tried to resume but failed
var e=!1;return this.generatedError&&(this.error(this.generatedError),e=!0),this.previous&&this.previous.resume(),!e},/**
	     * Flush any remaining bytes as the stream is ending.
	     */flush:function(){},/**
	     * Process a chunk. This is usually the method overridden.
	     * @param {Object} chunk the chunk to process.
	     */processChunk:function(e){this.push(e)},/**
	     * Add a key/value to be added in the workers chain streamInfo once activated.
	     * @param {String} key the key to use
	     * @param {Object} value the associated value
	     * @return {Worker} the current worker for chainability
	     */withStreamInfo:function(e,t){return this.extraStreamInfo[e]=t,this.mergeStreamInfo(),this},/**
	     * Merge this worker's streamInfo into the chain's streamInfo.
	     */mergeStreamInfo:function(){for(var e in this.extraStreamInfo)this.extraStreamInfo.hasOwnProperty(e)&&(this.streamInfo[e]=this.extraStreamInfo[e])},/**
	     * Lock the stream to prevent further updates on the workers chain.
	     * After calling this method, all calls to pipe will fail.
	     */lock:function(){if(this.isLocked)throw new Error('The stream \''+this+'\' has already been used.');this.isLocked=!0,this.previous&&this.previous.lock()},/**
	     *
	     * Pretty print the workers chain.
	     */toString:function(){var e='Worker '+this.name;return this.previous?this.previous+' -> '+e:e}},t.exports=n},{}],29:[function(e,t){/**
	 * Apply the final transformation of the data. If the user wants a Blob for
	 * example, it's easier to work with an U8intArray and finally do the
	 * ArrayBuffer/Blob conversion.
	 * @param {String} type the name of the final type
	 * @param {String|Uint8Array|Buffer} content the content to transform
	 * @param {String} mimeType the mime type of the content, if applicable.
	 * @return {String|Uint8Array|ArrayBuffer|Buffer|Blob} the content in the right format.
	 */function n(e,t,n){return'blob'===e?s.newBlob(s.transformTo('arraybuffer',t),n):'base64'===e?l.encode(t):s.transformTo(e,t)}/**
	 * Concatenate an array of data of the given type.
	 * @param {String} type the type of the data in the given array.
	 * @param {Array} dataArray the array containing the data chunks to concatenate
	 * @return {String|Uint8Array|Buffer} the concatenated data
	 * @throws Error if the asked type is unsupported
	 */function r(e,t){var n=0,r=null,a=0,s;for(s=0;s<t.length;s++)a+=t[s].length;switch(e){case'string':return t.join('');case'array':return Array.prototype.concat.apply([],t);case'uint8array':for(r=new Uint8Array(a),s=0;s<t.length;s++)r.set(t[s],n),n+=t[s].length;return r;case'nodebuffer':return Buffer.concat(t);default:throw new Error('concat : unsupported type \''+e+'\'');}}/**
	 * Listen a StreamHelper, accumulate its content and concatenate it into a
	 * complete block.
	 * @param {StreamHelper} helper the helper to use.
	 * @param {Function} updateCallback a callback called on each update. Called
	 * with one arg :
	 * - the metadata linked to the update received.
	 * @return Promise the promise for the accumulation.
	 */function a(e,t){return new c.Promise(function(a,i){var s=[],o=e._internalType,d=e._outputType,l=e._mimeType;e.on('data',function(e,n){s.push(e),t&&t(n)}).on('error',function(e){s=[],i(e)}).on('end',function(){try{var e=n(d,r(o,s),l);a(e)}catch(t){i(t)}s=[]}).resume()})}/**
	 * An helper to easily use workers outside of JSZip.
	 * @constructor
	 * @param {Worker} worker the worker to wrap
	 * @param {String} outputType the type of data expected by the use
	 * @param {String} mimeType the mime type of the content, if applicable.
	 */function i(e,t,n){var r=t;'blob'===t||'arraybuffer'===t?r='uint8array':'base64'===t?r='string':void 0;try{this._internalType=r,this._outputType=t,this._mimeType=n,s.checkSupport(r),this._worker=e.pipe(new o(r)),e.lock()}catch(t){this._worker=new d('error'),this._worker.error(t)}}var s=e('../utils'),o=e('./ConvertWorker'),d=e('./GenericWorker'),l=e('../base64'),p=e('../support'),c=e('../external'),u=null;if(p.nodestream)try{u=e('../nodejs/NodejsStreamOutputAdapter')}catch(t){}i.prototype={/**
	     * Listen a StreamHelper, accumulate its content and concatenate it into a
	     * complete block.
	     * @param {Function} updateCb the update callback.
	     * @return Promise the promise for the accumulation.
	     */accumulate:function(e){return a(this,e)},/**
	     * Add a listener on an event triggered on a stream.
	     * @param {String} evt the name of the event
	     * @param {Function} fn the listener
	     * @return {StreamHelper} the current helper.
	     */on:function(e,t){var n=this;return'data'===e?this._worker.on(e,function(e){t.call(n,e.data,e.meta)}):this._worker.on(e,function(){s.delay(t,arguments,n)}),this},/**
	     * Resume the flow of chunks.
	     * @return {StreamHelper} the current helper.
	     */resume:function(){return s.delay(this._worker.resume,[],this._worker),this},/**
	     * Pause the flow of chunks.
	     * @return {StreamHelper} the current helper.
	     */pause:function(){return this._worker.pause(),this},/**
	     * Return a nodejs stream for this helper.
	     * @param {Function} updateCb the update callback.
	     * @return {NodejsStreamOutputAdapter} the nodejs stream.
	     */toNodejsStream:function(e){if(s.checkSupport('nodestream'),'nodebuffer'!==this._outputType)// an object stream containing blob/arraybuffer/uint8array/string
// is strange and I don't know if it would be useful.
// I you find this comment and have a good usecase, please open a
// bug report !
throw new Error(this._outputType+' is not supported by this method');return new u(this,{objectMode:'nodebuffer'!==this._outputType},e)}},t.exports=i},{"../base64":1,"../external":6,"../nodejs/NodejsStreamOutputAdapter":13,"../support":30,"../utils":32,"./ConvertWorker":24,"./GenericWorker":28}],30:[function(e,t,n){if(n.base64=!0,n.array=!0,n.string=!0,n.arraybuffer='undefined'!=typeof ArrayBuffer&&'undefined'!=typeof Uint8Array,n.nodebuffer='undefined'!=typeof Buffer,n.uint8array='undefined'!=typeof Uint8Array,'undefined'==typeof ArrayBuffer)n.blob=!1;else{var r=new ArrayBuffer(0);try{n.blob=0===new Blob([r],{type:'application/zip'}).size}catch(t){try{var a=self.BlobBuilder||self.WebKitBlobBuilder||self.MozBlobBuilder||self.MSBlobBuilder,i=new a;i.append(r),n.blob=0===i.getBlob('application/zip').size}catch(t){n.blob=!1}}}try{n.nodestream=!!e('readable-stream').Readable}catch(t){n.nodestream=!1}},{"readable-stream":16}],31:[function(e,t,n){/**
	 * A worker to decode utf8 encoded binary chunks into string chunks.
	 * @constructor
	 */function r(){l.call(this,'utf-8 decode'),this.leftOver=null}/**
	 * A worker to endcode string chunks into utf8 encoded binary chunks.
	 * @constructor
	 */function a(){l.call(this,'utf-8 encode')}/**
	 * The following functions come from pako, from pako/lib/utils/strings
	 * released under the MIT license, see pako https://github.com/nodeca/pako/
	 */// Table with utf8 lengths (calculated by first byte of sequence)
// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,
// because max possible codepoint is 0x10ffff
for(var s=e('./utils'),o=e('./support'),d=e('./nodejsUtils'),l=e('./stream/GenericWorker'),p=Array(256),c=0;256>c;c++)p[c]=252<=c?6:248<=c?5:240<=c?4:224<=c?3:192<=c?2:1;p[254]=p[254]=1;// Invalid sequence start
// convert string to array (typed, when possible)
var i=function(e){var t=e.length,n=0,r,a,s,d,l;// count binary size
for(d=0;d<t;d++)a=e.charCodeAt(d),55296==(64512&a)&&d+1<t&&(s=e.charCodeAt(d+1),56320==(64512&s)&&(a=65536+(a-55296<<10)+(s-56320),d++)),n+=128>a?1:2048>a?2:65536>a?3:4;// allocate buffer
// convert
for(r=o.uint8array?new Uint8Array(n):Array(n),l=0,d=0;l<n;d++)a=e.charCodeAt(d),55296==(64512&a)&&d+1<t&&(s=e.charCodeAt(d+1),56320==(64512&s)&&(a=65536+(a-55296<<10)+(s-56320),d++)),128>a?r[l++]=a:2048>a?(r[l++]=192|a>>>6,r[l++]=128|63&a):65536>a?(r[l++]=224|a>>>12,r[l++]=128|63&a>>>6,r[l++]=128|63&a):(r[l++]=240|a>>>18,r[l++]=128|63&a>>>12,r[l++]=128|63&a>>>6,r[l++]=128|63&a);return r},u=function(e,t){var n;for(t=t||e.length,t>e.length&&(t=e.length),n=t-1;0<=n&&128==(192&e[n]);)n--;// Fuckup - very small and broken sequence,
// return max, because we should return something anyway.
return 0>n?t:0===n?t:n+p[e[n]]>t?n:t;// If we came to start of buffer - that means vuffer is too small,
// return max too.
},h=function(e){var t=e.length,n=Array(2*t),r,a,i,o;// Reserve max possible length (2 words per char)
// NB: by unknown reasons, Array is significantly faster for
//     String.fromCharCode.apply than Uint16Array.
for(a=0,r=0;r<t;){// quick process ascii
if(i=e[r++],128>i){n[a++]=i;continue}// skip 5 & 6 byte codes
if(o=p[i],4<o){n[a++]=65533,r+=o-1;continue}// apply mask on first byte
// join the rest
for(i&=2===o?31:3===o?15:7;1<o&&r<t;)i=i<<6|63&e[r++],o--;// terminated by end of string?
if(1<o){n[a++]=65533;continue}65536>i?n[a++]=i:(i-=65536,n[a++]=55296|1023&i>>10,n[a++]=56320|1023&i)}// shrinkBuf(utf16buf, out)
// return String.fromCharCode.apply(null, utf16buf);
return n.length!==a&&(n.subarray?n=n.subarray(0,a):n.length=a),s.applyFromCharCode(n)};// Calculate max possible position in utf8 buffer,
// that will not break sequence. If that's not possible
// - (very small limits) return max size as is.
//
// buf[] - utf8 bytes array
// max   - length limit (mandatory);
// convert array to string
// That's all for the pako functions.
/**
	 * Transform a javascript string into an array (typed if possible) of bytes,
	 * UTF-8 encoded.
	 * @param {String} str the string to encode
	 * @return {Array|Uint8Array|Buffer} the UTF-8 encoded string.
	 */n.utf8encode=function(e){return o.nodebuffer?d.newBufferFrom(e,'utf-8'):i(e)},n.utf8decode=function(e){return o.nodebuffer?s.transformTo('nodebuffer',e).toString('utf-8'):(e=s.transformTo(o.uint8array?'uint8array':'array',e),h(e))},s.inherits(r,l),r.prototype.processChunk=function(e){var t=s.transformTo(o.uint8array?'uint8array':'array',e.data);// 1st step, re-use what's left of the previous chunk
if(this.leftOver&&this.leftOver.length){if(o.uint8array){var r=t;t=new Uint8Array(r.length+this.leftOver.length),t.set(this.leftOver,0),t.set(r,this.leftOver.length)}else t=this.leftOver.concat(t);this.leftOver=null}var a=u(t),i=t;a!==t.length&&(o.uint8array?(i=t.subarray(0,a),this.leftOver=t.subarray(a,t.length)):(i=t.slice(0,a),this.leftOver=t.slice(a,t.length))),this.push({data:n.utf8decode(i),meta:e.meta})},r.prototype.flush=function(){this.leftOver&&this.leftOver.length&&(this.push({data:n.utf8decode(this.leftOver),meta:{}}),this.leftOver=null)},n.Utf8DecodeWorker=r,s.inherits(a,l),a.prototype.processChunk=function(e){this.push({data:n.utf8encode(e.data),meta:e.meta})},n.Utf8EncodeWorker=a},{"./nodejsUtils":14,"./stream/GenericWorker":28,"./support":30,"./utils":32}],32:[function(e,n,r){/**
	 * Convert a string that pass as a "binary string": it should represent a byte
	 * array but may have > 255 char codes. Be sure to take only the first byte
	 * and returns the byte array.
	 * @param {String} str the string to transform.
	 * @return {Array|Uint8Array} the string in a binary format.
	 */function a(e){var t=null;return t=l.uint8array?new Uint8Array(e.length):Array(e.length),s(e,t)}/**
	 * Create a new blob with the given content and the given type.
	 * @param {String|ArrayBuffer} part the content to put in the blob. DO NOT use
	 * an Uint8Array because the stock browser of android 4 won't accept it (it
	 * will be silently converted to a string, "[object Uint8Array]").
	 *
	 * Use only ONE part to build the blob to avoid a memory leak in IE11 / Edge:
	 * when a large amount of Array is used to create the Blob, the amount of
	 * memory consumed is nearly 100 times the original data amount.
	 *
	 * @param {String} type the mime type of the blob.
	 * @return {Blob} the created blob.
	 *//**
	 * The identity function.
	 * @param {Object} input the input.
	 * @return {Object} the same input.
	 */function i(e){return e}/**
	 * Fill in an array with a string.
	 * @param {String} str the string to use.
	 * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to fill in (will be mutated).
	 * @return {Array|ArrayBuffer|Uint8Array|Buffer} the updated array.
	 */function s(e,t){for(var n=0;n<e.length;++n)t[n]=255&e.charCodeAt(n);return t}/**
	 * An helper for the function arrayLikeToString.
	 * This contains static information and functions that
	 * can be optimized by the browser JIT compiler.
	 *//**
	 * Transform an array-like object to a string.
	 * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.
	 * @return {String} the result.
	 */function o(e){// Performances notes :
// --------------------
// String.fromCharCode.apply(null, array) is the fastest, see
// see http://jsperf.com/converting-a-uint8array-to-a-string/2
// but the stack is limited (and we can get huge arrays !).
//
// result += String.fromCharCode(array[i]); generate too many strings !
//
// This code is inspired by http://jsperf.com/arraybuffer-to-string-apply-performance/2
// TODO : we now have workers that split the work. Do we still need that ?
var t=65536,n=r.getTypeOf(e),a=!0;if('uint8array'===n?a=m.applyCanBeUsed.uint8array:'nodebuffer'===n&&(a=m.applyCanBeUsed.nodebuffer),a)for(;1<t;)try{return m.stringifyByChunk(e,n,t)}catch(n){t=Le(t/2)}// no apply or chunk error : slow and painful algorithm
// default browser on android 4.*
return m.stringifyByChar(e)}/**
	 * Copy the data from an array-like to an other array-like.
	 * @param {Array|ArrayBuffer|Uint8Array|Buffer} arrayFrom the origin array.
	 * @param {Array|ArrayBuffer|Uint8Array|Buffer} arrayTo the destination array which will be mutated.
	 * @return {Array|ArrayBuffer|Uint8Array|Buffer} the updated destination array.
	 */function d(e,t){for(var n=0;n<e.length;n++)t[n]=e[n];return t}// a matrix containing functions to transform everything into everything.
var l=e('./support'),p=e('./base64'),c=e('./nodejsUtils'),u=e('set-immediate-shim'),h=e('./external');r.newBlob=function(e,t){r.checkSupport('blob');try{// Blob constructor
return new Blob([e],{type:t})}catch(r){try{// deprecated, browser only, old way
var n=self.BlobBuilder||self.WebKitBlobBuilder||self.MozBlobBuilder||self.MSBlobBuilder,a=new n;return a.append(e),a.getBlob(t)}catch(t){// well, fuck ?!
throw new Error('Bug : can\'t construct the Blob.')}}};var m={/**
	     * Transform an array of int into a string, chunk by chunk.
	     * See the performances notes on arrayLikeToString.
	     * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.
	     * @param {String} type the type of the array.
	     * @param {Integer} chunk the chunk size.
	     * @return {String} the resulting string.
	     * @throws Error if the chunk is too big for the stack.
	     */stringifyByChunk:function(e,n,r){var a=[],i=0,s=e.length;// shortcut
if(s<=r)return Fe.apply(null,e);for(;i<s;)'array'===n||'nodebuffer'===n?a.push(Fe.apply(null,e.slice(i,t(i+r,s)))):a.push(Fe.apply(null,e.subarray(i,t(i+r,s)))),i+=r;return a.join('')},/**
	     * Call String.fromCharCode on every item in the array.
	     * This is the naive implementation, which generate A LOT of intermediate string.
	     * This should be used when everything else fail.
	     * @param {Array|ArrayBuffer|Uint8Array|Buffer} array the array to transform.
	     * @return {String} the result.
	     */stringifyByChar:function(e){for(var t='',n=0;n<e.length;n++)t+=Fe(e[n]);return t},applyCanBeUsed:{/**
	         * true if the browser accepts to use String.fromCharCode on Uint8Array
	         */uint8array:function(){try{return l.uint8array&&1===Fe.apply(null,new Uint8Array(1)).length}catch(t){return!1}}(),/**
	         * true if the browser accepts to use String.fromCharCode on nodejs Buffer.
	         */nodebuffer:function(){try{return l.nodebuffer&&1===Fe.apply(null,c.allocBuffer(1)).length}catch(t){return!1}}()}};r.applyFromCharCode=o;var f={};// string to ?
f.string={string:i,array:function(e){return s(e,Array(e.length))},arraybuffer:function(e){return f.string.uint8array(e).buffer},uint8array:function(e){return s(e,new Uint8Array(e.length))},nodebuffer:function(e){return s(e,c.allocBuffer(e.length))}},f.array={string:o,array:i,arraybuffer:function(e){return new Uint8Array(e).buffer},uint8array:function(e){return new Uint8Array(e)},nodebuffer:function(e){return c.newBufferFrom(e)}},f.arraybuffer={string:function(e){return o(new Uint8Array(e))},array:function(e){return d(new Uint8Array(e),Array(e.byteLength))},arraybuffer:i,uint8array:function(e){return new Uint8Array(e)},nodebuffer:function(e){return c.newBufferFrom(new Uint8Array(e))}},f.uint8array={string:o,array:function(e){return d(e,Array(e.length))},arraybuffer:function(e){return e.buffer},uint8array:i,nodebuffer:function(e){return c.newBufferFrom(e)}},f.nodebuffer={string:o,array:function(e){return d(e,Array(e.length))},arraybuffer:function(e){return f.nodebuffer.uint8array(e).buffer},uint8array:function(e){return d(e,new Uint8Array(e.length))},nodebuffer:i},r.transformTo=function(e,t){if(t||(t=''),!e)return t;r.checkSupport(e);var n=r.getTypeOf(t),a=f[n][e](t);return a},r.getTypeOf=function(e){return'string'==typeof e?'string':'[object Array]'===Object.prototype.toString.call(e)?'array':l.nodebuffer&&c.isBuffer(e)?'nodebuffer':l.uint8array&&e instanceof Uint8Array?'uint8array':l.arraybuffer&&e instanceof ArrayBuffer?'arraybuffer':void 0},r.checkSupport=function(e){var t=l[e.toLowerCase()];if(!t)throw new Error(e+' is not supported by this platform')},r.MAX_VALUE_16BITS=65535,r.MAX_VALUE_32BITS=-1,r.pretty=function(e){var t='',n,r;for(r=0;r<(e||'').length;r++)n=e.charCodeAt(r),t+='\\x'+(16>n?'0':'')+n.toString(16).toUpperCase();return t},r.delay=function(e,t,n){u(function(){e.apply(n||null,t||[])})},r.inherits=function(e,t){var n=function(){};n.prototype=t.prototype,e.prototype=new n},r.extend=function(){var e={},t,n;for(t=0;t<arguments.length;t++)// arguments is not enumerable in some browsers
for(n in arguments[t])arguments[t].hasOwnProperty(n)&&'undefined'==typeof e[n]&&(e[n]=arguments[t][n]);return e},r.prepareContent=function(e,t,n,i,s){// if inputData is already a promise, this flatten it.
var o=h.Promise.resolve(t).then(function(e){var t=l.blob&&(e instanceof Blob||-1!==['[object File]','[object Blob]'].indexOf(Object.prototype.toString.call(e)));return t&&'undefined'!=typeof FileReader?new h.Promise(function(t,n){var r=new FileReader;r.onload=function(n){t(n.target.result)},r.onerror=function(t){n(t.target.error)},r.readAsArrayBuffer(e)}):e});return o.then(function(t){var o=r.getTypeOf(t);return o?('arraybuffer'===o?t=r.transformTo('uint8array',t):'string'===o&&(s?t=p.decode(t):n&&!0!==i&&(t=a(t))),t):h.Promise.reject(new Error('Can\'t read the data of \''+e+'\'. Is it in a supported JavaScript type (String, Blob, ArrayBuffer, etc) ?'));// special case : it's way easier to work with Uint8Array than with ArrayBuffer
})}},{"./base64":1,"./external":6,"./nodejsUtils":14,"./support":30,"set-immediate-shim":54}],33:[function(e,t){//  class ZipEntries {{{
/**
	 * All the entries in the zip file.
	 * @constructor
	 * @param {Object} loadOptions Options for loading the stream.
	 */function n(e){this.files=[],this.loadOptions=e}var r=e('./reader/readerFor'),a=e('./utils'),s=e('./signature'),i=e('./zipEntry'),o=e('./utf8'),d=e('./support');n.prototype={/**
	     * Check that the reader is on the specified signature.
	     * @param {string} expectedSignature the expected signature.
	     * @throws {Error} if it is an other signature.
	     */checkSignature:function(e){if(!this.reader.readAndCheckSignature(e)){this.reader.index-=4;var t=this.reader.readString(4);throw new Error('Corrupted zip or bug: unexpected signature ('+a.pretty(t)+', expected '+a.pretty(e)+')')}},/**
	     * Check if the given signature is at the given index.
	     * @param {number} askedIndex the index to check.
	     * @param {string} expectedSignature the signature to expect.
	     * @return {boolean} true if the signature is here, false otherwise.
	     */isSignature:function(e,t){var n=this.reader.index;this.reader.setIndex(e);var r=this.reader.readString(4);return this.reader.setIndex(n),r===t},/**
	     * Read the end of the central directory.
	     */readBlockEndOfCentral:function(){this.diskNumber=this.reader.readInt(2),this.diskWithCentralDirStart=this.reader.readInt(2),this.centralDirRecordsOnThisDisk=this.reader.readInt(2),this.centralDirRecords=this.reader.readInt(2),this.centralDirSize=this.reader.readInt(4),this.centralDirOffset=this.reader.readInt(4),this.zipCommentLength=this.reader.readInt(2);// warning : the encoding depends of the system locale
// On a linux machine with LANG=en_US.utf8, this field is utf8 encoded.
// On a windows machine, this field is encoded with the localized windows code page.
var e=this.reader.readData(this.zipCommentLength),t=d.uint8array?'uint8array':'array',n=a.transformTo(t,e);// To get consistent behavior with the generation part, we will assume that
// this is utf8 encoded unless specified otherwise.
this.zipComment=this.loadOptions.decodeFileName(n)},/**
	     * Read the end of the Zip 64 central directory.
	     * Not merged with the method readEndOfCentral :
	     * The end of central can coexist with its Zip64 brother,
	     * I don't want to read the wrong number of bytes !
	     */readBlockZip64EndOfCentral:function(){this.zip64EndOfCentralSize=this.reader.readInt(8),this.reader.skip(4),this.diskNumber=this.reader.readInt(4),this.diskWithCentralDirStart=this.reader.readInt(4),this.centralDirRecordsOnThisDisk=this.reader.readInt(8),this.centralDirRecords=this.reader.readInt(8),this.centralDirSize=this.reader.readInt(8),this.centralDirOffset=this.reader.readInt(8),this.zip64ExtensibleData={};for(var e=this.zip64EndOfCentralSize-44,t,n,r;0<e;)t=this.reader.readInt(2),n=this.reader.readInt(4),r=this.reader.readData(n),this.zip64ExtensibleData[t]={id:t,length:n,value:r}},/**
	     * Read the end of the Zip 64 central directory locator.
	     */readBlockZip64EndOfCentralLocator:function(){if(this.diskWithZip64CentralDirStart=this.reader.readInt(4),this.relativeOffsetEndOfZip64CentralDir=this.reader.readInt(8),this.disksCount=this.reader.readInt(4),1<this.disksCount)throw new Error('Multi-volumes zip are not supported')},/**
	     * Read the local files, based on the offset read in the central part.
	     */readLocalFiles:function(){var e,t;for(e=0;e<this.files.length;e++)t=this.files[e],this.reader.setIndex(t.localHeaderOffset),this.checkSignature(s.LOCAL_FILE_HEADER),t.readLocalPart(this.reader),t.handleUTF8(),t.processAttributes()},/**
	     * Read the central directory.
	     */readCentralDir:function(){var e;for(this.reader.setIndex(this.centralDirOffset);this.reader.readAndCheckSignature(s.CENTRAL_FILE_HEADER);)e=new i({zip64:this.zip64},this.loadOptions),e.readCentralPart(this.reader),this.files.push(e);if(this.centralDirRecords!==this.files.length)if(0!==this.centralDirRecords&&0===this.files.length)// We expected some records but couldn't find ANY.
// This is really suspicious, as if something went wrong.
throw new Error('Corrupted zip or bug: expected '+this.centralDirRecords+' records in central dir, got '+this.files.length);else;},/**
	     * Read the end of central directory.
	     */readEndOfCentral:function(){var e=this.reader.lastIndexOfSignature(s.CENTRAL_DIRECTORY_END);if(0>e){// Check if the content is a truncated zip or complete garbage.
// A "LOCAL_FILE_HEADER" is not required at the beginning (auto
// extractible zip for example) but it can give a good hint.
// If an ajax request was used without responseType, we will also
// get unreadable data.
var t=!this.isSignature(0,s.LOCAL_FILE_HEADER);if(t)throw new Error('Can\'t find end of central directory : is this a zip file ? If it is, see https://stuk.github.io/jszip/documentation/howto/read_zip.html');else throw new Error('Corrupted zip: can\'t find end of central directory')}this.reader.setIndex(e);var n=e;/* extract from the zip spec :
	            4)  If one of the fields in the end of central directory
	                record is too small to hold required data, the field
	                should be set to -1 (0xFFFF or 0xFFFFFFFF) and the
	                ZIP64 format record should be created.
	            5)  The end of central directory record and the
	                Zip64 end of central directory locator record must
	                reside on the same disk when splitting or spanning
	                an archive.
	         */if(this.checkSignature(s.CENTRAL_DIRECTORY_END),this.readBlockEndOfCentral(),this.diskNumber===a.MAX_VALUE_16BITS||this.diskWithCentralDirStart===a.MAX_VALUE_16BITS||this.centralDirRecordsOnThisDisk===a.MAX_VALUE_16BITS||this.centralDirRecords===a.MAX_VALUE_16BITS||this.centralDirSize===a.MAX_VALUE_32BITS||this.centralDirOffset===a.MAX_VALUE_32BITS){if(this.zip64=!0,e=this.reader.lastIndexOfSignature(s.ZIP64_CENTRAL_DIRECTORY_LOCATOR),0>e)throw new Error('Corrupted zip: can\'t find the ZIP64 end of central directory locator');// now the zip64 EOCD record
if(this.reader.setIndex(e),this.checkSignature(s.ZIP64_CENTRAL_DIRECTORY_LOCATOR),this.readBlockZip64EndOfCentralLocator(),!this.isSignature(this.relativeOffsetEndOfZip64CentralDir,s.ZIP64_CENTRAL_DIRECTORY_END)&&(this.relativeOffsetEndOfZip64CentralDir=this.reader.lastIndexOfSignature(s.ZIP64_CENTRAL_DIRECTORY_END),0>this.relativeOffsetEndOfZip64CentralDir))throw new Error('Corrupted zip: can\'t find the ZIP64 end of central directory');this.reader.setIndex(this.relativeOffsetEndOfZip64CentralDir),this.checkSignature(s.ZIP64_CENTRAL_DIRECTORY_END),this.readBlockZip64EndOfCentral()}var r=this.centralDirOffset+this.centralDirSize;this.zip64&&(r+=20,r+=12/* should not include the leading 12 bytes */+this.zip64EndOfCentralSize);var i=n-r;if(0<i)this.isSignature(n,s.CENTRAL_FILE_HEADER)||(this.reader.zero=i);else if(0>i)throw new Error('Corrupted zip: missing '+Math.abs(i)+' bytes.')},prepareReader:function(e){this.reader=r(e)},/**
	     * Read a zip file and create ZipEntries.
	     * @param {String|ArrayBuffer|Uint8Array|Buffer} data the binary string representing a zip file.
	     */load:function(e){this.prepareReader(e),this.readEndOfCentral(),this.readCentralDir(),this.readLocalFiles()}},t.exports=n},{"./reader/readerFor":22,"./signature":23,"./support":30,"./utf8":31,"./utils":32,"./zipEntry":34}],34:[function(e,t){// class ZipEntry {{{
/**
	 * An entry in the zip file.
	 * @constructor
	 * @param {Object} options Options of the current file.
	 * @param {Object} loadOptions Options for loading the stream.
	 */function n(e,t){this.options=e,this.loadOptions=t}var r=e('./reader/readerFor'),a=e('./utils'),i=e('./compressedObject'),s=e('./crc32'),o=e('./utf8'),d=e('./compressions'),l=e('./support'),p=function(e){for(var t in d)if(d.hasOwnProperty(t)&&d[t].magic===e)return d[t];return null};/**
	 * Find a compression registered in JSZip.
	 * @param {string} compressionMethod the method magic to find.
	 * @return {Object|null} the JSZip compression object, null if none found.
	 */n.prototype={/**
	     * say if the file is encrypted.
	     * @return {boolean} true if the file is encrypted, false otherwise.
	     */isEncrypted:function(){// bit 1 is set
return 1==(1&this.bitFlag)},/**
	     * say if the file has utf-8 filename/comment.
	     * @return {boolean} true if the filename/comment is in utf-8, false otherwise.
	     */useUTF8:function(){// bit 11 is set
return 2048==(2048&this.bitFlag)},/**
	     * Read the local part of a zip file and add the info in this object.
	     * @param {DataReader} reader the reader to use.
	     */readLocalPart:function(e){var t,n;// we already know everything from the central dir !
// If the central dir data are false, we are doomed.
// On the bright side, the local part is scary  : zip64, data descriptors, both, etc.
// The less data we get here, the more reliable this should be.
// Let's skip the whole header and dash to the data !
if(e.skip(22),this.fileNameLength=e.readInt(2),n=e.readInt(2),this.fileName=e.readData(this.fileNameLength),e.skip(n),-1===this.compressedSize||-1===this.uncompressedSize)throw new Error('Bug or corrupted zip : didn\'t get enough information from the central directory (compressedSize === -1 || uncompressedSize === -1)');if(t=p(this.compressionMethod),null===t)// no compression found
throw new Error('Corrupted zip : compression '+a.pretty(this.compressionMethod)+' unknown (inner file : '+a.transformTo('string',this.fileName)+')');this.decompressed=new i(this.compressedSize,this.uncompressedSize,this.crc32,t,e.readData(this.compressedSize))},/**
	     * Read the central part of a zip file and add the info in this object.
	     * @param {DataReader} reader the reader to use.
	     */readCentralPart:function(e){this.versionMadeBy=e.readInt(2),e.skip(2),this.bitFlag=e.readInt(2),this.compressionMethod=e.readString(2),this.date=e.readDate(),this.crc32=e.readInt(4),this.compressedSize=e.readInt(4),this.uncompressedSize=e.readInt(4);var t=e.readInt(2);if(this.extraFieldsLength=e.readInt(2),this.fileCommentLength=e.readInt(2),this.diskNumberStart=e.readInt(2),this.internalFileAttributes=e.readInt(2),this.externalFileAttributes=e.readInt(4),this.localHeaderOffset=e.readInt(4),this.isEncrypted())throw new Error('Encrypted zip are not supported');// will be read in the local part, see the comments there
e.skip(t),this.readExtraFields(e),this.parseZIP64ExtraField(e),this.fileComment=e.readData(this.fileCommentLength)},/**
	     * Parse the external file attributes and get the unix/dos permissions.
	     */processAttributes:function(){this.unixPermissions=null,this.dosPermissions=null;var e=this.versionMadeBy>>8;// Check if we have the DOS directory flag set.
// We look for it in the DOS and UNIX permissions
// but some unknown platform could set it as a compatibility flag.
this.dir=!!(16&this.externalFileAttributes),e==0&&(this.dosPermissions=63&this.externalFileAttributes),e==3&&(this.unixPermissions=65535&this.externalFileAttributes>>16),this.dir||'/'!==this.fileNameStr.slice(-1)||(this.dir=!0)},/**
	     * Parse the ZIP64 extra field and merge the info in the current ZipEntry.
	     * @param {DataReader} reader the reader to use.
	     */parseZIP64ExtraField:function(){if(this.extraFields[1]){// should be something, preparing the extra reader
var e=r(this.extraFields[1].value);// I really hope that these 64bits integer can fit in 32 bits integer, because js
// won't let us have more.
this.uncompressedSize===a.MAX_VALUE_32BITS&&(this.uncompressedSize=e.readInt(8)),this.compressedSize===a.MAX_VALUE_32BITS&&(this.compressedSize=e.readInt(8)),this.localHeaderOffset===a.MAX_VALUE_32BITS&&(this.localHeaderOffset=e.readInt(8)),this.diskNumberStart===a.MAX_VALUE_32BITS&&(this.diskNumberStart=e.readInt(4))}},/**
	     * Read the central part of a zip file and add the info in this object.
	     * @param {DataReader} reader the reader to use.
	     */readExtraFields:function(e){var t=e.index+this.extraFieldsLength,n,r,a;for(this.extraFields||(this.extraFields={});e.index+4<t;)n=e.readInt(2),r=e.readInt(2),a=e.readData(r),this.extraFields[n]={id:n,length:r,value:a};e.setIndex(t)},/**
	     * Apply an UTF8 transformation if needed.
	     */handleUTF8:function(){var e=l.uint8array?'uint8array':'array';if(this.useUTF8())this.fileNameStr=o.utf8decode(this.fileName),this.fileCommentStr=o.utf8decode(this.fileComment);else{var t=this.findExtraFieldUnicodePath();if(null!==t)this.fileNameStr=t;else{// ASCII text or unsupported code page
var n=a.transformTo(e,this.fileName);this.fileNameStr=this.loadOptions.decodeFileName(n)}var r=this.findExtraFieldUnicodeComment();if(null!==r)this.fileCommentStr=r;else{// ASCII text or unsupported code page
var i=a.transformTo(e,this.fileComment);this.fileCommentStr=this.loadOptions.decodeFileName(i)}}},/**
	     * Find the unicode path declared in the extra field, if any.
	     * @return {String} the unicode path, null otherwise.
	     */findExtraFieldUnicodePath:function(){var e=this.extraFields[28789];if(e){var t=r(e.value);// wrong version
return 1===t.readInt(1)?s(this.fileName)===t.readInt(4)?o.utf8decode(t.readData(e.length-5)):null:null;// the crc of the filename changed, this field is out of date.
}return null},/**
	     * Find the unicode comment declared in the extra field, if any.
	     * @return {String} the unicode comment, null otherwise.
	     */findExtraFieldUnicodeComment:function(){var e=this.extraFields[25461];if(e){var t=r(e.value);// wrong version
return 1===t.readInt(1)?s(this.fileComment)===t.readInt(4)?o.utf8decode(t.readData(e.length-5)):null:null;// the crc of the comment changed, this field is out of date.
}return null}},t.exports=n},{"./compressedObject":2,"./compressions":3,"./crc32":4,"./reader/readerFor":22,"./support":30,"./utf8":31,"./utils":32}],35:[function(e,t){var n=e('./stream/StreamHelper'),r=e('./stream/DataWorker'),a=e('./utf8'),s=e('./compressedObject'),o=e('./stream/GenericWorker'),d=function(e,t,n){this.name=e,this.dir=n.dir,this.date=n.date,this.comment=n.comment,this.unixPermissions=n.unixPermissions,this.dosPermissions=n.dosPermissions,this._data=t,this._dataBinary=n.binary,this.options={compression:n.compression,compressionOptions:n.compressionOptions}};/**
	 * A simple object representing a file in the zip file.
	 * @constructor
	 * @param {string} name the name of the file
	 * @param {String|ArrayBuffer|Uint8Array|Buffer} data the data
	 * @param {Object} options the options of the file
	 */d.prototype={/**
	     * Create an internal stream for the content of this object.
	     * @param {String} type the type of each chunk.
	     * @return StreamHelper the stream.
	     */internalStream:function(e){var t=null,r='string';try{if(!e)throw new Error('No output type specified.');r=e.toLowerCase();var i='string'===r||'text'===r;('binarystring'===r||'text'===r)&&(r='string'),t=this._decompressWorker();var s=!this._dataBinary;s&&!i&&(t=t.pipe(new a.Utf8EncodeWorker)),!s&&i&&(t=t.pipe(new a.Utf8DecodeWorker))}catch(n){t=new o('error'),t.error(n)}return new n(t,r,'')},/**
	     * Prepare the content in the asked type.
	     * @param {String} type the type of the result.
	     * @param {Function} onUpdate a function to call on each internal update.
	     * @return Promise the promise of the result.
	     */async:function(e,t){return this.internalStream(e).accumulate(t)},/**
	     * Prepare the content as a nodejs stream.
	     * @param {String} type the type of each chunk.
	     * @param {Function} onUpdate a function to call on each internal update.
	     * @return Stream the stream.
	     */nodeStream:function(e,t){return this.internalStream(e||'nodebuffer').toNodejsStream(t)},/**
	     * Return a worker for the compressed content.
	     * @private
	     * @param {Object} compression the compression object to use.
	     * @param {Object} compressionOptions the options to use when compressing.
	     * @return Worker the worker.
	     */_compressWorker:function(e,t){if(this._data instanceof s&&this._data.compression.magic===e.magic)return this._data.getCompressedWorker();var n=this._decompressWorker();return this._dataBinary||(n=n.pipe(new a.Utf8EncodeWorker)),s.createWorkerFrom(n,e,t)},/**
	     * Return a worker for the decompressed content.
	     * @private
	     * @return Worker the worker.
	     */_decompressWorker:function(){return this._data instanceof s?this._data.getContentWorker():this._data instanceof o?this._data:new r(this._data)}};for(var l=['asText','asBinary','asNodeBuffer','asUint8Array','asArrayBuffer'],p=function(){throw new Error('This method has been removed in JSZip 3.0, please check the upgrade guide.')},c=0;c<l.length;c++)d.prototype[l[c]]=p;t.exports=d},{"./compressedObject":2,"./stream/DataWorker":27,"./stream/GenericWorker":28,"./stream/StreamHelper":29,"./utf8":31}],36:[function(e,t){(function(e){//named nextTick for less confusing stack traces
function n(){c=!0;for(var e=p.length,t,n;e;){for(n=p,p=[],t=-1;++t<e;)n[t]();e=p.length}c=!1}function r(e){1!==p.push(e)||c||i()}var a=e.MutationObserver||e.WebKitMutationObserver,i;if(a){var s=0,o=new a(n),d=e.document.createTextNode('');o.observe(d,{characterData:!0}),i=function(){d.data=s=++s%2}}else if(!e.setImmediate&&'undefined'!=typeof e.MessageChannel){var l=new e.MessageChannel;l.port1.onmessage=n,i=function(){l.port2.postMessage(0)}}else i='document'in e&&'onreadystatechange'in e.document.createElement('script')?function(){// Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted
// into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.
var t=e.document.createElement('script');t.onreadystatechange=function(){n(),t.onreadystatechange=null,t.parentNode.removeChild(t),t=null},e.document.documentElement.appendChild(t)}:function(){setTimeout(n,0)};var p=[],c;t.exports=r}).call(this,'undefined'==typeof Me?'undefined'==typeof self?'undefined'==typeof window?{}:window:self:Me)},{}],37:[function(e,t){/* istanbul ignore next */function n(){}function r(e){if('function'!=typeof e)throw new TypeError('resolver must be a function');this.state=h,this.queue=[],this.outcome=void 0,e!==n&&o(this,e)}function a(e,t,n){this.promise=e,'function'==typeof t&&(this.onFulfilled=t,this.callFulfilled=this.otherCallFulfilled),'function'==typeof n&&(this.onRejected=n,this.callRejected=this.otherCallRejected)}function i(t,e,n){l(function(){var r;try{r=e(n)}catch(n){return p.reject(t,n)}r===t?p.reject(t,new TypeError('Cannot resolve promise with itself')):p.resolve(t,r)})}function s(e){// Make sure we only access the accessor once as required by the spec
var t=e&&e.then;if(e&&('object'==typeof e||'function'==typeof e)&&'function'==typeof t)return function(){t.apply(e,arguments)}}function o(e,t){function n(t){a||(a=!0,p.reject(e,t))}function r(t){a||(a=!0,p.resolve(e,t))}// Either fulfill, reject or reject with error
var a=!1,i=d(function(){t(r,n)});'error'===i.status&&n(i.value)}function d(e,t){var n={};try{n.value=e(t),n.status='success'}catch(t){n.status='error',n.value=t}return n}var l=e('immediate'),p={},c=['REJECTED'],u=['FULFILLED'],h=['PENDING'];t.exports=r,r.prototype['finally']=function(e){if('function'!=typeof e)return this;var t=this.constructor;return this.then(function(n){return t.resolve(e()).then(function(){return n})},function(n){return t.resolve(e()).then(function(){throw n})})},r.prototype['catch']=function(e){return this.then(null,e)},r.prototype.then=function(e,t){if('function'!=typeof e&&this.state===u||'function'!=typeof t&&this.state===c)return this;var r=new this.constructor(n);if(this.state!==h){var s=this.state===u?e:t;i(r,s,this.outcome)}else this.queue.push(new a(r,e,t));return r},a.prototype.callFulfilled=function(e){p.resolve(this.promise,e)},a.prototype.otherCallFulfilled=function(e){i(this.promise,this.onFulfilled,e)},a.prototype.callRejected=function(e){p.reject(this.promise,e)},a.prototype.otherCallRejected=function(e){i(this.promise,this.onRejected,e)},p.resolve=function(e,t){var n=d(s,t);if('error'===n.status)return p.reject(e,n.value);var r=n.value;if(r)o(e,r);else{e.state=u,e.outcome=t;for(var a=-1,i=e.queue.length;++a<i;)e.queue[a].callFulfilled(t)}return e},p.reject=function(e,t){e.state=c,e.outcome=t;for(var n=-1,r=e.queue.length;++n<r;)e.queue[n].callRejected(t);return e},r.resolve=function(e){return e instanceof this?e:p.resolve(new this(n),e)},r.reject=function(e){var t=new this(n);return p.reject(t,e)},r.all=function(e){function t(e,t){function n(e){o[t]=e,++d!==a||s||(s=!0,p.resolve(c,o))}r.resolve(e).then(n,function(e){s||(s=!0,p.reject(c,e))})}var r=this;if('[object Array]'!==Object.prototype.toString.call(e))return this.reject(new TypeError('must be an array'));var a=e.length,s=!1;if(!a)return this.resolve([]);for(var o=Array(a),d=0,l=-1,c=new this(n);++l<a;)t(e[l],l);return c},r.race=function(e){function t(e){r.resolve(e).then(function(e){s||(s=!0,p.resolve(i,e))},function(e){s||(s=!0,p.reject(i,e))})}var r=this;if('[object Array]'!==Object.prototype.toString.call(e))return this.reject(new TypeError('must be an array'));var a=e.length,s=!1;if(!a)return this.resolve([]);for(var o=-1,i=new this(n);++o<a;)t(e[o]);return i}},{immediate:36}],38:[function(e,t){var n=e('./lib/utils/common').assign,r=e('./lib/deflate'),a=e('./lib/inflate'),i=e('./lib/zlib/constants'),s={};n(s,r,a,i),t.exports=s},{"./lib/deflate":39,"./lib/inflate":40,"./lib/utils/common":41,"./lib/zlib/constants":44}],39:[function(e,t,n){/* ===========================================================================*//**
	 * class Deflate
	 *
	 * Generic JS-style wrapper for zlib calls. If you don't need
	 * streaming behaviour - use more simple functions: [[deflate]],
	 * [[deflateRaw]] and [[gzip]].
	 **//* internal
	 * Deflate.chunks -> Array
	 *
	 * Chunks of output data, if [[Deflate#onData]] not overriden.
	 **//**
	 * Deflate.result -> Uint8Array|Array
	 *
	 * Compressed result, generated by default [[Deflate#onData]]
	 * and [[Deflate#onEnd]] handlers. Filled after you push last chunk
	 * (call [[Deflate#push]] with `Z_FINISH` / `true` param)  or if you
	 * push a chunk with explicit flush (call [[Deflate#push]] with
	 * `Z_SYNC_FLUSH` param).
	 **//**
	 * Deflate.err -> Number
	 *
	 * Error code after deflate finished. 0 (Z_OK) on success.
	 * You will not need it in real life, because deflate errors
	 * are possible only on wrong options or bad `onData` / `onEnd`
	 * custom handlers.
	 **//**
	 * Deflate.msg -> String
	 *
	 * Error message, if [[Deflate.err]] != 0
	 **//**
	 * new Deflate(options)
	 * - options (Object): zlib deflate options.
	 *
	 * Creates new deflator instance with specified params. Throws exception
	 * on bad params. Supported options:
	 *
	 * - `level`
	 * - `windowBits`
	 * - `memLevel`
	 * - `strategy`
	 * - `dictionary`
	 *
	 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
	 * for more information on these.
	 *
	 * Additional options, for internal needs:
	 *
	 * - `chunkSize` - size of generated data chunks (16K by default)
	 * - `raw` (Boolean) - do raw deflate
	 * - `gzip` (Boolean) - create gzip wrapper
	 * - `to` (String) - if equal to 'string', then result will be "binary string"
	 *    (each char code [0..255])
	 * - `header` (Object) - custom header for gzip
	 *   - `text` (Boolean) - true if compressed data believed to be text
	 *   - `time` (Number) - modification time, unix timestamp
	 *   - `os` (Number) - operation system code
	 *   - `extra` (Array) - array of bytes with extra data (max 65536)
	 *   - `name` (String) - file name (binary string)
	 *   - `comment` (String) - comment (binary string)
	 *   - `hcrc` (Boolean) - true if header crc should be added
	 *
	 * ##### Example:
	 *
	 * ```javascript
	 * var pako = require('pako')
	 *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])
	 *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);
	 *
	 * var deflate = new pako.Deflate({ level: 3});
	 *
	 * deflate.push(chunk1, false);
	 * deflate.push(chunk2, true);  // true -> last chunk
	 *
	 * if (deflate.err) { throw new Error(deflate.err); }
	 *
	 * console.log(deflate.result);
	 * ```
	 **/function r(e){if(!(this instanceof r))return new r(e);this.options=s.assign({level:f,method:_,chunkSize:16384,windowBits:15,memLevel:8,strategy:g,to:''},e||{});var t=this.options;t.raw&&0<t.windowBits?t.windowBits=-t.windowBits:t.gzip&&0<t.windowBits&&16>t.windowBits&&(t.windowBits+=16),this.err=0,this.msg='',this.ended=!1,this.chunks=[],this.strm=new l,this.strm.avail_out=0;var n=i.deflateInit2(this.strm,t.level,t.method,t.windowBits,t.memLevel,t.strategy);if(n!==u)throw new Error(d[n]);if(t.header&&i.deflateSetHeader(this.strm,t.header),t.dictionary){var a;// Convert data if needed
if(a='string'==typeof t.dictionary?o.string2buf(t.dictionary):'[object ArrayBuffer]'===p.call(t.dictionary)?new Uint8Array(t.dictionary):t.dictionary,n=i.deflateSetDictionary(this.strm,a),n!==u)throw new Error(d[n]);this._dict_set=!0}}/**
	 * Deflate#push(data[, mode]) -> Boolean
	 * - data (Uint8Array|Array|ArrayBuffer|String): input data. Strings will be
	 *   converted to utf8 byte sequence.
	 * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.
	 *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` meansh Z_FINISH.
	 *
	 * Sends input data to deflate pipe, generating [[Deflate#onData]] calls with
	 * new compressed chunks. Returns `true` on success. The last data block must have
	 * mode Z_FINISH (or `true`). That will flush internal pending buffers and call
	 * [[Deflate#onEnd]]. For interim explicit flushes (without ending the stream) you
	 * can use mode Z_SYNC_FLUSH, keeping the compression context.
	 *
	 * On fail call [[Deflate#onEnd]] with error code and return false.
	 *
	 * We strongly recommend to use `Uint8Array` on input for best speed (output
	 * array format is detected automatically). Also, don't skip last param and always
	 * use the same type in your code (boolean or number). That will improve JS speed.
	 *
	 * For regular `Array`-s make sure all elements are [0..255].
	 *
	 * ##### Example
	 *
	 * ```javascript
	 * push(chunk, false); // push one of data chunks
	 * ...
	 * push(chunk, true);  // push last chunk
	 * ```
	 **//**
	 * deflate(data[, options]) -> Uint8Array|Array|String
	 * - data (Uint8Array|Array|String): input data to compress.
	 * - options (Object): zlib deflate options.
	 *
	 * Compress `data` with deflate algorithm and `options`.
	 *
	 * Supported options are:
	 *
	 * - level
	 * - windowBits
	 * - memLevel
	 * - strategy
	 * - dictionary
	 *
	 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
	 * for more information on these.
	 *
	 * Sugar (options):
	 *
	 * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify
	 *   negative windowBits implicitly.
	 * - `to` (String) - if equal to 'string', then result will be "binary string"
	 *    (each char code [0..255])
	 *
	 * ##### Example:
	 *
	 * ```javascript
	 * var pako = require('pako')
	 *   , data = Uint8Array([1,2,3,4,5,6,7,8,9]);
	 *
	 * console.log(pako.deflate(data));
	 * ```
	 **/function a(e,t){var n=new r(t);// That will never happens, if you don't cheat with options :)
if(n.push(e,!0),n.err)throw n.msg||d[n.err];return n.result}/**
	 * deflateRaw(data[, options]) -> Uint8Array|Array|String
	 * - data (Uint8Array|Array|String): input data to compress.
	 * - options (Object): zlib deflate options.
	 *
	 * The same as [[deflate]], but creates raw data, without wrapper
	 * (header and adler32 crc).
	 **//**
	 * gzip(data[, options]) -> Uint8Array|Array|String
	 * - data (Uint8Array|Array|String): input data to compress.
	 * - options (Object): zlib deflate options.
	 *
	 * The same as [[deflate]], but create gzip wrapper instead of
	 * deflate one.
	 **/var i=e('./zlib/deflate'),s=e('./utils/common'),o=e('./utils/strings'),d=e('./zlib/messages'),l=e('./zlib/zstream'),p=Object.prototype.toString,c=4,u=0,h=1,m=2,f=-1,g=0,_=8;/* Public constants ==========================================================*//* ===========================================================================*/r.prototype.push=function(e,t){var n=this.strm,r=this.options.chunkSize,a,d;if(this.ended)return!1;d=t===~~t?t:!0===t?c:0,n.input='string'==typeof e?o.string2buf(e):'[object ArrayBuffer]'===p.call(e)?new Uint8Array(e):e,n.next_in=0,n.avail_in=n.input.length;do{/* no bad return value */if(0===n.avail_out&&(n.output=new s.Buf8(r),n.next_out=0,n.avail_out=r),a=i.deflate(n,d),a!==h&&a!==u)return this.onEnd(a),this.ended=!0,!1;(0===n.avail_out||0===n.avail_in&&(d===c||d===m))&&('string'===this.options.to?this.onData(o.buf2binstring(s.shrinkBuf(n.output,n.next_out))):this.onData(s.shrinkBuf(n.output,n.next_out)))}while((0<n.avail_in||0===n.avail_out)&&a!==h);// Finalize on the last chunk.
return d===c?(a=i.deflateEnd(this.strm),this.onEnd(a),this.ended=!0,a===u):d!==m||(this.onEnd(u),n.avail_out=0,!0);// callback interim results if Z_SYNC_FLUSH.
},r.prototype.onData=function(e){this.chunks.push(e)},r.prototype.onEnd=function(e){e===u&&('string'===this.options.to?this.result=this.chunks.join(''):this.result=s.flattenChunks(this.chunks)),this.chunks=[],this.err=e,this.msg=this.strm.msg},n.Deflate=r,n.deflate=a,n.deflateRaw=function(e,t){return t=t||{},t.raw=!0,a(e,t)},n.gzip=function(e,t){return t=t||{},t.gzip=!0,a(e,t)}},{"./utils/common":41,"./utils/strings":42,"./zlib/deflate":46,"./zlib/messages":51,"./zlib/zstream":53}],40:[function(e,t,n){/**
	 * class Inflate
	 *
	 * Generic JS-style wrapper for zlib calls. If you don't need
	 * streaming behaviour - use more simple functions: [[inflate]]
	 * and [[inflateRaw]].
	 **//* internal
	 * inflate.chunks -> Array
	 *
	 * Chunks of output data, if [[Inflate#onData]] not overriden.
	 **//**
	 * Inflate.result -> Uint8Array|Array|String
	 *
	 * Uncompressed result, generated by default [[Inflate#onData]]
	 * and [[Inflate#onEnd]] handlers. Filled after you push last chunk
	 * (call [[Inflate#push]] with `Z_FINISH` / `true` param) or if you
	 * push a chunk with explicit flush (call [[Inflate#push]] with
	 * `Z_SYNC_FLUSH` param).
	 **//**
	 * Inflate.err -> Number
	 *
	 * Error code after inflate finished. 0 (Z_OK) on success.
	 * Should be checked if broken data possible.
	 **//**
	 * Inflate.msg -> String
	 *
	 * Error message, if [[Inflate.err]] != 0
	 **//**
	 * new Inflate(options)
	 * - options (Object): zlib inflate options.
	 *
	 * Creates new inflator instance with specified params. Throws exception
	 * on bad params. Supported options:
	 *
	 * - `windowBits`
	 * - `dictionary`
	 *
	 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
	 * for more information on these.
	 *
	 * Additional options, for internal needs:
	 *
	 * - `chunkSize` - size of generated data chunks (16K by default)
	 * - `raw` (Boolean) - do raw inflate
	 * - `to` (String) - if equal to 'string', then result will be converted
	 *   from utf8 to utf16 (javascript) string. When string output requested,
	 *   chunk length can differ from `chunkSize`, depending on content.
	 *
	 * By default, when no options set, autodetect deflate/gzip data format via
	 * wrapper header.
	 *
	 * ##### Example:
	 *
	 * ```javascript
	 * var pako = require('pako')
	 *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])
	 *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);
	 *
	 * var inflate = new pako.Inflate({ level: 3});
	 *
	 * inflate.push(chunk1, false);
	 * inflate.push(chunk2, true);  // true -> last chunk
	 *
	 * if (inflate.err) { throw new Error(inflate.err); }
	 *
	 * console.log(inflate.result);
	 * ```
	 **/function r(e){if(!(this instanceof r))return new r(e);this.options=s.assign({chunkSize:16384,windowBits:0,to:''},e||{});var t=this.options;// Force window size for `raw` data, if not set directly,
// because we have no header for autodetect.
t.raw&&0<=t.windowBits&&16>t.windowBits&&(t.windowBits=-t.windowBits,0===t.windowBits&&(t.windowBits=-15)),0<=t.windowBits&&16>t.windowBits&&!(e&&e.windowBits)&&(t.windowBits+=32),15<t.windowBits&&48>t.windowBits&&0==(15&t.windowBits)&&(t.windowBits|=15),this.err=0,this.msg='',this.ended=!1,this.chunks=[],this.strm=new p,this.strm.avail_out=0;var n=i.inflateInit2(this.strm,t.windowBits);if(n!==d.Z_OK)throw new Error(l[n]);this.header=new c,i.inflateGetHeader(this.strm,this.header)}/**
	 * Inflate#push(data[, mode]) -> Boolean
	 * - data (Uint8Array|Array|ArrayBuffer|String): input data
	 * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.
	 *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` meansh Z_FINISH.
	 *
	 * Sends input data to inflate pipe, generating [[Inflate#onData]] calls with
	 * new output chunks. Returns `true` on success. The last data block must have
	 * mode Z_FINISH (or `true`). That will flush internal pending buffers and call
	 * [[Inflate#onEnd]]. For interim explicit flushes (without ending the stream) you
	 * can use mode Z_SYNC_FLUSH, keeping the decompression context.
	 *
	 * On fail call [[Inflate#onEnd]] with error code and return false.
	 *
	 * We strongly recommend to use `Uint8Array` on input for best speed (output
	 * format is detected automatically). Also, don't skip last param and always
	 * use the same type in your code (boolean or number). That will improve JS speed.
	 *
	 * For regular `Array`-s make sure all elements are [0..255].
	 *
	 * ##### Example
	 *
	 * ```javascript
	 * push(chunk, false); // push one of data chunks
	 * ...
	 * push(chunk, true);  // push last chunk
	 * ```
	 **//**
	 * inflate(data[, options]) -> Uint8Array|Array|String
	 * - data (Uint8Array|Array|String): input data to decompress.
	 * - options (Object): zlib inflate options.
	 *
	 * Decompress `data` with inflate/ungzip and `options`. Autodetect
	 * format via wrapper header by default. That's why we don't provide
	 * separate `ungzip` method.
	 *
	 * Supported options are:
	 *
	 * - windowBits
	 *
	 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
	 * for more information.
	 *
	 * Sugar (options):
	 *
	 * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify
	 *   negative windowBits implicitly.
	 * - `to` (String) - if equal to 'string', then result will be converted
	 *   from utf8 to utf16 (javascript) string. When string output requested,
	 *   chunk length can differ from `chunkSize`, depending on content.
	 *
	 *
	 * ##### Example:
	 *
	 * ```javascript
	 * var pako = require('pako')
	 *   , input = pako.deflate([1,2,3,4,5,6,7,8,9])
	 *   , output;
	 *
	 * try {
	 *   output = pako.inflate(input);
	 * } catch (err)
	 *   console.log(err);
	 * }
	 * ```
	 **/function a(e,t){var n=new r(t);// That will never happens, if you don't cheat with options :)
if(n.push(e,!0),n.err)throw n.msg||l[n.err];return n.result}/**
	 * inflateRaw(data[, options]) -> Uint8Array|Array|String
	 * - data (Uint8Array|Array|String): input data to decompress.
	 * - options (Object): zlib inflate options.
	 *
	 * The same as [[inflate]], but creates raw data, without wrapper
	 * (header and adler32 crc).
	 **//**
	 * ungzip(data[, options]) -> Uint8Array|Array|String
	 * - data (Uint8Array|Array|String): input data to decompress.
	 * - options (Object): zlib inflate options.
	 *
	 * Just shortcut to [[inflate]], because it autodetects format
	 * by header.content. Done for convenience.
	 **/var i=e('./zlib/inflate'),s=e('./utils/common'),o=e('./utils/strings'),d=e('./zlib/constants'),l=e('./zlib/messages'),p=e('./zlib/zstream'),c=e('./zlib/gzheader'),u=Object.prototype.toString;r.prototype.push=function(e,t){var n=this.strm,r=this.options.chunkSize,a=this.options.dictionary,l=!1,p,c,h,m,f,g;// Flag to properly process Z_BUF_ERROR on testing inflate call
// when we check that all output data was flushed.
if(this.ended)return!1;c=t===~~t?t:!0===t?d.Z_FINISH:d.Z_NO_FLUSH,n.input='string'==typeof e?o.binstring2buf(e):'[object ArrayBuffer]'===u.call(e)?new Uint8Array(e):e,n.next_in=0,n.avail_in=n.input.length;do{if(0===n.avail_out&&(n.output=new s.Buf8(r),n.next_out=0,n.avail_out=r),p=i.inflate(n,d.Z_NO_FLUSH),p===d.Z_NEED_DICT&&a&&(g='string'==typeof a?o.string2buf(a):'[object ArrayBuffer]'===u.call(a)?new Uint8Array(a):a,p=i.inflateSetDictionary(this.strm,g)),p===d.Z_BUF_ERROR&&!0==l&&(p=d.Z_OK,l=!1),p!==d.Z_STREAM_END&&p!==d.Z_OK)return this.onEnd(p),this.ended=!0,!1;n.next_out&&(0===n.avail_out||p===d.Z_STREAM_END||0===n.avail_in&&(c===d.Z_FINISH||c===d.Z_SYNC_FLUSH))&&('string'===this.options.to?(h=o.utf8border(n.output,n.next_out),m=n.next_out-h,f=o.buf2string(n.output,h),n.next_out=m,n.avail_out=r-m,m&&s.arraySet(n.output,n.output,h,m,0),this.onData(f)):this.onData(s.shrinkBuf(n.output,n.next_out))),0===n.avail_in&&0===n.avail_out&&(l=!0)}while((0<n.avail_in||0===n.avail_out)&&p!==d.Z_STREAM_END);// Finalize on the last chunk.
return p===d.Z_STREAM_END&&(c=d.Z_FINISH),c===d.Z_FINISH?(p=i.inflateEnd(this.strm),this.onEnd(p),this.ended=!0,p===d.Z_OK):c!==d.Z_SYNC_FLUSH||(this.onEnd(d.Z_OK),n.avail_out=0,!0);// callback interim results if Z_SYNC_FLUSH.
},r.prototype.onData=function(e){this.chunks.push(e)},r.prototype.onEnd=function(e){e===d.Z_OK&&('string'===this.options.to?this.result=this.chunks.join(''):this.result=s.flattenChunks(this.chunks)),this.chunks=[],this.err=e,this.msg=this.strm.msg},n.Inflate=r,n.inflate=a,n.inflateRaw=function(e,t){return t=t||{},t.raw=!0,a(e,t)},n.ungzip=a},{"./utils/common":41,"./utils/strings":42,"./zlib/constants":44,"./zlib/gzheader":47,"./zlib/inflate":49,"./zlib/messages":51,"./zlib/zstream":53}],41:[function(e,t,n){var r='undefined'!=typeof Uint8Array&&'undefined'!=typeof Uint16Array&&'undefined'!=typeof Int32Array;n.assign=function(e/*from1, from2, from3, ...*/){for(var t=Array.prototype.slice.call(arguments,1);t.length;){var n=t.shift();if(n){if('object'!=typeof n)throw new TypeError(n+'must be non-object');for(var r in n)n.hasOwnProperty(r)&&(e[r]=n[r])}}return e},n.shrinkBuf=function(e,t){return e.length===t?e:e.subarray?e.subarray(0,t):(e.length=t,e)};var a={arraySet:function(e,t,n,r,a){if(t.subarray&&e.subarray)return void e.set(t.subarray(n,n+r),a);// Fallback to ordinary array
for(var s=0;s<r;s++)e[a+s]=t[n+s]},// Join array of chunks to single array.
flattenChunks:function(e){var t,n,r,a,i,s;// calculate data length
for(r=0,t=0,n=e.length;t<n;t++)r+=e[t].length;// join chunks
for(s=new Uint8Array(r),a=0,(t=0,n=e.length);t<n;t++)i=e[t],s.set(i,a),a+=i.length;return s}},i={arraySet:function(e,t,n,r,a){for(var s=0;s<r;s++)e[a+s]=t[n+s]},// Join array of chunks to single array.
flattenChunks:function(e){return[].concat.apply([],e)}};// Enable/Disable typed arrays use, for testing
//
n.setTyped=function(e){e?(n.Buf8=Uint8Array,n.Buf16=Uint16Array,n.Buf32=Int32Array,n.assign(n,a)):(n.Buf8=Array,n.Buf16=Array,n.Buf32=Array,n.assign(n,i))},n.setTyped(r)},{}],42:[function(e,t,n){// Helper (used in 2 places)
function r(e,t){// use fallback for big arrays to avoid stack overflow
if(65537>t&&(e.subarray&&o||!e.subarray&&s))return Fe.apply(null,a.shrinkBuf(e,t));for(var n='',r=0;r<t;r++)n+=Fe(e[r]);return n}// Convert byte array to binary string
var a=e('./common'),s=!0,o=!0;// Quick check if we can use fast array to bin string conversion
//
// - apply(Array) can fail on Android 2.2
// - apply(Uint8Array) can fail on iOS 5.1 Safary
//
try{Fe.apply(null,[0])}catch(e){s=!1}try{Fe.apply(null,new Uint8Array(1))}catch(e){o=!1}// Table with utf8 lengths (calculated by first byte of sequence)
// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,
// because max possible codepoint is 0x10ffff
for(var d=new a.Buf8(256),i=0;256>i;i++)d[i]=252<=i?6:248<=i?5:240<=i?4:224<=i?3:192<=i?2:1;d[254]=d[254]=1,n.string2buf=function(e){var t=e.length,n=0,r,s,o,d,l;// count binary size
for(d=0;d<t;d++)s=e.charCodeAt(d),55296==(64512&s)&&d+1<t&&(o=e.charCodeAt(d+1),56320==(64512&o)&&(s=65536+(s-55296<<10)+(o-56320),d++)),n+=128>s?1:2048>s?2:65536>s?3:4;// allocate buffer
// convert
for(r=new a.Buf8(n),l=0,d=0;l<n;d++)s=e.charCodeAt(d),55296==(64512&s)&&d+1<t&&(o=e.charCodeAt(d+1),56320==(64512&o)&&(s=65536+(s-55296<<10)+(o-56320),d++)),128>s?r[l++]=s:2048>s?(r[l++]=192|s>>>6,r[l++]=128|63&s):65536>s?(r[l++]=224|s>>>12,r[l++]=128|63&s>>>6,r[l++]=128|63&s):(r[l++]=240|s>>>18,r[l++]=128|63&s>>>12,r[l++]=128|63&s>>>6,r[l++]=128|63&s);return r},n.buf2binstring=function(e){return r(e,e.length)},n.binstring2buf=function(e){for(var t=new a.Buf8(e.length),n=0,r=t.length;n<r;n++)t[n]=e.charCodeAt(n);return t},n.buf2string=function(e,t){var n=t||e.length,a=Array(2*n),s,i,o,l;// Reserve max possible length (2 words per char)
// NB: by unknown reasons, Array is significantly faster for
//     String.fromCharCode.apply than Uint16Array.
for(i=0,s=0;s<n;){// quick process ascii
if(o=e[s++],128>o){a[i++]=o;continue}// skip 5 & 6 byte codes
if(l=d[o],4<l){a[i++]=65533,s+=l-1;continue}// apply mask on first byte
// join the rest
for(o&=2===l?31:3===l?15:7;1<l&&s<n;)o=o<<6|63&e[s++],l--;// terminated by end of string?
if(1<l){a[i++]=65533;continue}65536>o?a[i++]=o:(o-=65536,a[i++]=55296|1023&o>>10,a[i++]=56320|1023&o)}return r(a,i)},n.utf8border=function(e,t){var n;for(t=t||e.length,t>e.length&&(t=e.length),n=t-1;0<=n&&128==(192&e[n]);)n--;// Fuckup - very small and broken sequence,
// return max, because we should return something anyway.
return 0>n?t:0===n?t:n+d[e[n]]>t?n:t;// If we came to start of buffer - that means vuffer is too small,
// return max too.
}},{"./common":41}],43:[function(e,t){t.exports=// Note: adler32 takes 12% for level 0 and 2% for level 6.
// It doesn't worth to make additional optimizationa as in original.
// Small size is preferable.
// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.
function(e,t,r,a){for(var i=0|65535&e,s=0|65535&e>>>16,o=0;0!==r;){o=2e3<r?2e3:r,r-=o;do i=0|i+t[a++],s=0|s+i;while(--o);i%=65521,s%=65521}return 0|(i|s<<16)}},{}],44:[function(e,t){t.exports={/* Allowed flush values; see deflate() and inflate() below for details */Z_NO_FLUSH:0,Z_PARTIAL_FLUSH:1,Z_SYNC_FLUSH:2,Z_FULL_FLUSH:3,Z_FINISH:4,Z_BLOCK:5,Z_TREES:6,/* Return codes for the compression/decompression functions. Negative values
	  * are errors, positive values are used for special but normal events.
	  */Z_OK:0,Z_STREAM_END:1,Z_NEED_DICT:2,Z_ERRNO:-1,Z_STREAM_ERROR:-2,Z_DATA_ERROR:-3,//Z_MEM_ERROR:     -4,
Z_BUF_ERROR:-5,//Z_VERSION_ERROR: -6,
/* compression levels */Z_NO_COMPRESSION:0,Z_BEST_SPEED:1,Z_BEST_COMPRESSION:9,Z_DEFAULT_COMPRESSION:-1,Z_FILTERED:1,Z_HUFFMAN_ONLY:2,Z_RLE:3,Z_FIXED:4,Z_DEFAULT_STRATEGY:0,/* Possible values of the data_type field (though see inflate()) */Z_BINARY:0,Z_TEXT:1,//Z_ASCII:                1, // = Z_TEXT (deprecated)
Z_UNKNOWN:2,/* The deflate compression method */Z_DEFLATED:8//Z_NULL:                 null // Use -1 or null inline, depending on var type
}},{}],45:[function(e,t){// Create table on load. Just 255 signed longs. Not a problem.
// Note: we can't get significant speed boost here.
// So write code to minimize size - no pregenerated tables
// and array tools dependencies.
// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.
// Use ordinary array, since untyped makes no boost here
var n=function(){for(var e=[],t=0,n;256>t;t++){n=t;for(var r=0;8>r;r++)n=1&n?3988292384^n>>>1:n>>>1;e[t]=n}return e}();t.exports=function(e,t,r,a){e^=-1;for(var s=a;s<a+r;s++)e=e>>>8^n[255&(e^t[s])];return-1^e;// >>> 0;
}},{}],46:[function(e,t,n){// Unix :) . Don't detect, use this default.
function r(e,t){return e.msg=I[t],t}function a(e){return(e<<1)-(4<e?9:0)}function i(e){for(var t=e.length;0<=--t;)e[t]=0}/* =========================================================================
	 * Flush as much pending output as possible. All deflate() output goes
	 * through this function so some applications may wish to modify it
	 * to avoid allocating a large strm->output buffer and copying into it.
	 * (See also read_buf()).
	 */function o(e){var t=e.state,n=t.pending;//_tr_flush_bits(s);
n>e.avail_out&&(n=e.avail_out);0===n||(N.arraySet(e.output,t.pending_buf,t.pending_out,n,e.next_out),e.next_out+=n,t.pending_out+=n,e.total_out+=n,e.avail_out-=n,t.pending-=n,0===t.pending&&(t.pending_out=0))}function d(e,t){C._tr_flush_block(e,0<=e.block_start?e.block_start:-1,e.strstart-e.block_start,t),e.block_start=e.strstart,o(e.strm)}function l(e,t){e.pending_buf[e.pending++]=t}/* =========================================================================
	 * Put a short in the pending buffer. The 16-bit value is put in MSB order.
	 * IN assertion: the stream state is correct and there is enough room in
	 * pending_buf.
	 */function p(e,t){e.pending_buf[e.pending++]=255&t>>>8,e.pending_buf[e.pending++]=255&t}/* ===========================================================================
	 * Read a new buffer from the current input stream, update the adler32
	 * and total number of bytes read.  All deflate() input goes through
	 * this function so some applications may wish to modify it to avoid
	 * allocating a large strm->input buffer and copying from it.
	 * (See also flush_pending()).
	 */function c(e,t,n,r){var a=e.avail_in;return(a>r&&(a=r),0===a)?0:(e.avail_in-=a,N.arraySet(t,e.input,e.next_in,a,n),1===e.state.wrap?e.adler=E(e.adler,t,a,n):2===e.state.wrap&&(e.adler=S(e.adler,t,a,n)),e.next_in+=a,e.total_in+=a,a)}/* ===========================================================================
	 * Set match_start to the longest match starting at the given string and
	 * return its length. Matches shorter or equal to prev_length are discarded,
	 * in which case the result is equal to prev_length and match_start is
	 * garbage.
	 * IN assertions: cur_match is the head of the hash chain for the current
	 *   string (strstart) and its distance is <= MAX_DIST, and prev_length >= 1
	 * OUT assertion: the match length is not greater than s->lookahead.
	 */function u(e,t){var n=e.max_chain_length,r=e.strstart,a=e.prev_length,i=e.nice_match,s=e.strstart>e.w_size-Q?e.strstart-(e.w_size-Q):0/*NIL*/,o=e.window,d=e.w_mask,l=e.prev,p=e.strstart+J,c=o[r+a-1],u=o[r+a],h,m;/* max hash chain length *//* current string *//* matched string *//* length of current match *//* best match length so far *//* stop if match long enough */// shortcut
/* Stop when cur_match becomes <= limit. To simplify the code,
	   * we prevent matches with the string of window index 0.
	   *//* The code is optimized for HASH_BITS >= 8 and MAX_MATCH-2 multiple of 16.
	   * It is easy to get rid of this optimization if necessary.
	   */// Assert(s->hash_bits >= 8 && MAX_MATCH == 258, "Code too clever");
/* Do not waste too much time if we already have a good match: */e.prev_length>=e.good_match&&(n>>=2),i>e.lookahead&&(i=e.lookahead);// Assert((ulg)s->strstart <= s->window_size-MIN_LOOKAHEAD, "need lookahead");
do{/* Skip to next match if the match length cannot increase
	     * or if the match length is less than 2.  Note that the checks below
	     * for insufficient lookahead only occur occasionally for performance
	     * reasons.  Therefore uninitialized memory will be accessed, and
	     * conditional jumps will be made that depend on those values.
	     * However the length of the match is limited to the lookahead, so
	     * the output of deflate is not affected by the uninitialized values.
	     */if(h=t,o[h+a]!==u||o[h+a-1]!==c||o[h]!==o[r]||o[++h]!==o[r+1])continue;/* The check at best_len-1 can be removed because it will be made
	     * again later. (This heuristic is not always a win.)
	     * It is not necessary to compare scan[2] and match[2] since they
	     * are always equal when the other bytes match, given that
	     * the hash keys are equal and that HASH_BITS >= 8.
	     */r+=2,h++;// Assert(*scan == *match, "match[2]?");
/* We check for insufficient lookahead only every 8th comparison;
	     * the 256th check will be made at strstart+258.
	     */do;while(o[++r]===o[++h]&&o[++r]===o[++h]&&o[++r]===o[++h]&&o[++r]===o[++h]&&o[++r]===o[++h]&&o[++r]===o[++h]&&o[++r]===o[++h]&&o[++r]===o[++h]&&r<p);// Assert(scan <= s->window+(unsigned)(s->window_size-1), "wild scan");
if(m=J-(p-r),r=p-J,m>a){if(e.match_start=t,a=m,m>=i)break;c=o[r+a-1],u=o[r+a]}}while((t=l[t&d])>s&&0!=--n);return a<=e.lookahead?a:e.lookahead}/* ===========================================================================
	 * Fill the window when the lookahead becomes insufficient.
	 * Updates strstart and lookahead.
	 *
	 * IN assertion: lookahead < MIN_LOOKAHEAD
	 * OUT assertions: strstart <= window_size-MIN_LOOKAHEAD
	 *    At least one byte has been read, or avail_in == 0; reads are
	 *    performed for at least two bytes (required for the zip translate_eol
	 *    option -- not supported here).
	 */function h(e){var t=e.w_size,r,a,n,i,s;//Assert(s->lookahead < MIN_LOOKAHEAD, "already enough lookahead");
do{// JS ints have 32 bit, block below not needed
/* Deal with !@#$% 64K limit: *///if (sizeof(int) <= 2) {
//    if (more == 0 && s->strstart == 0 && s->lookahead == 0) {
//        more = wsize;
//
//  } else if (more == (unsigned)(-1)) {
//        /* Very unlikely, but possible on 16 bit machine if
//         * strstart == 0 && lookahead == 1 (input done a byte at time)
//         */
//        more--;
//    }
//}
/* If the window is almost full and there is insufficient lookahead,
	     * move the upper half to the lower one to make room in the upper half.
	     */if(i=e.window_size-e.lookahead-e.strstart,e.strstart>=t+(t-Q)){N.arraySet(e.window,e.window,t,t,0),e.match_start-=t,e.strstart-=t,e.block_start-=t,a=e.hash_size,r=a;do n=e.head[--r],e.head[r]=n>=t?n-t:0;while(--a);a=t,r=a;do n=e.prev[--r],e.prev[r]=n>=t?n-t:0;while(--a);i+=t}if(0===e.strm.avail_in)break;/* If there was no sliding:
	     *    strstart <= WSIZE+MAX_DIST-1 && lookahead <= MIN_LOOKAHEAD - 1 &&
	     *    more == window_size - lookahead - strstart
	     * => more >= window_size - (MIN_LOOKAHEAD-1 + WSIZE + MAX_DIST-1)
	     * => more >= window_size - 2*WSIZE + 2
	     * In the BIG_MEM or MMAP case (not yet supported),
	     *   window_size == input_size + MIN_LOOKAHEAD  &&
	     *   strstart + s->lookahead <= input_size => more >= MIN_LOOKAHEAD.
	     * Otherwise, window_size == 2*WSIZE so more >= 2.
	     * If there was sliding, more >= WSIZE. So in all cases, more >= 2.
	     *///Assert(more >= 2, "more < 2");
/* Initialize the hash value now that we have some input: */if(a=c(e.strm,e.window,e.strstart+e.lookahead,i),e.lookahead+=a,e.lookahead+e.insert>=$)//#if MIN_MATCH != 3
//        Call update_hash() MIN_MATCH-3 more times
//#endif
for(s=e.strstart-e.insert,e.ins_h=e.window[s],e.ins_h=(e.ins_h<<e.hash_shift^e.window[s+1])&e.hash_mask;e.insert&&(e.ins_h=(e.ins_h<<e.hash_shift^e.window[s+$-1])&e.hash_mask,e.prev[s&e.w_mask]=e.head[e.ins_h],e.head[e.ins_h]=s,s++,e.insert--,!(e.lookahead+e.insert<$)););/* If the whole input has less than MIN_MATCH bytes, ins_h is garbage,
	     * but this is not important since only literal bytes will be emitted.
	     */}while(e.lookahead<Q&&0!==e.strm.avail_in);/* If the WIN_INIT bytes after the end of the current data have never been
	   * written, then zero those bytes in order to avoid memory check reports of
	   * the use of uninitialized (or uninitialised as Julian writes) bytes by
	   * the longest match routines.  Update the high water mark for the next
	   * time through here.  WIN_INIT is set to MAX_MATCH since the longest match
	   * routines allow scanning to strstart + MAX_MATCH, ignoring lookahead.
	   *///  if (s.high_water < s.window_size) {
//    var curr = s.strstart + s.lookahead;
//    var init = 0;
//
//    if (s.high_water < curr) {
//      /* Previous high water mark below current data -- zero WIN_INIT
//       * bytes or up to end of window, whichever is less.
//       */
//      init = s.window_size - curr;
//      if (init > WIN_INIT)
//        init = WIN_INIT;
//      zmemzero(s->window + curr, (unsigned)init);
//      s->high_water = curr + init;
//    }
//    else if (s->high_water < (ulg)curr + WIN_INIT) {
//      /* High water mark at or above current data, but below current data
//       * plus WIN_INIT -- zero out to current data plus WIN_INIT, or up
//       * to end of window, whichever is less.
//       */
//      init = (ulg)curr + WIN_INIT - s->high_water;
//      if (init > s->window_size - s->high_water)
//        init = s->window_size - s->high_water;
//      zmemzero(s->window + s->high_water, (unsigned)init);
//      s->high_water += init;
//    }
//  }
//
//  Assert((ulg)s->strstart <= s->window_size - MIN_LOOKAHEAD,
//    "not enough room for search");
}/* ===========================================================================
	 * Copy without compression as much as possible from the input stream, return
	 * the current block state.
	 * This function does not insert new strings in the dictionary since
	 * uncompressible data is probably not useful. This function is used
	 * only for the level=0 compression option.
	 * NOTE: this function should be optimized to avoid extra copying from
	 * window to pending_buf.
	 *//* ===========================================================================
	 * Compress as much as possible from the input stream, return the current
	 * block state.
	 * This function does not perform lazy evaluation of matches and inserts
	 * new strings in the dictionary only for unmatched strings or for short
	 * matches. It is used only for the fast compression options.
	 */function s(e,t){/* set if current block must be flushed *//* head of the hash chain */for(var n,r;;){/* Make sure that we always have enough lookahead, except
	     * at the end of the input file. We need MAX_MATCH bytes
	     * for the next match, plus MIN_MATCH bytes to insert the
	     * string following the next match.
	     */if(e.lookahead<Q){if(h(e),e.lookahead<Q&&t===A)return de;if(0===e.lookahead)break;/* flush the current block */}/* Insert the string window[strstart .. strstart+2] in the
	     * dictionary, and set hash_head to the head of the hash chain:
	     */if(n=0/*NIL*/,e.lookahead>=$&&(e.ins_h=(e.ins_h<<e.hash_shift^e.window[e.strstart+$-1])&e.hash_mask,n=e.prev[e.strstart&e.w_mask]=e.head[e.ins_h],e.head[e.ins_h]=e.strstart),0!==n/*NIL*/&&e.strstart-n<=e.w_size-Q&&(e.match_length=u(e,n)),!(e.match_length>=$))r=C._tr_tally(e,0,e.window[e.strstart]),e.lookahead--,e.strstart++;else/* Insert new strings in the hash table only if the match length
	       * is not too large. This saves time but degrades compression.
	       */if(r=C._tr_tally(e,e.strstart-e.match_start,e.match_length-$),e.lookahead-=e.match_length,e.match_length<=e.max_lazy_match/*max_insert_length*/&&e.lookahead>=$){e.match_length--;/* string at strstart already in table */do e.strstart++,e.ins_h=(e.ins_h<<e.hash_shift^e.window[e.strstart+$-1])&e.hash_mask,n=e.prev[e.strstart&e.w_mask]=e.head[e.ins_h],e.head[e.ins_h]=e.strstart;while(0!=--e.match_length);e.strstart++}else e.strstart+=e.match_length,e.match_length=0,e.ins_h=e.window[e.strstart],e.ins_h=(e.ins_h<<e.hash_shift^e.window[e.strstart+1])&e.hash_mask;if(r&&(d(e,!1),0===e.strm.avail_out))return de;/***/}return e.insert=e.strstart<$-1?e.strstart:$-1,t===z?(d(e,!0),0===e.strm.avail_out?pe:ce):e.last_lit&&(d(e,!1),0===e.strm.avail_out)?de:le}/* ===========================================================================
	 * Same as above, but achieves better compression. We use a lazy
	 * evaluation for matches: a match is finally adopted only if there is
	 * no better match at the next window position.
	 */function m(e,t){/* Process the input block. *//* head of hash chain *//* set if current block must be flushed */for(var n,r,a;;){/* Make sure that we always have enough lookahead, except
	     * at the end of the input file. We need MAX_MATCH bytes
	     * for the next match, plus MIN_MATCH bytes to insert the
	     * string following the next match.
	     */if(e.lookahead<Q){if(h(e),e.lookahead<Q&&t===A)return de;if(0===e.lookahead)break;/* flush the current block */}/* Insert the string window[strstart .. strstart+2] in the
	     * dictionary, and set hash_head to the head of the hash chain:
	     *//* If there was a match at the previous step and the current
	     * match is not better, output the previous match:
	     */if(n=0/*NIL*/,e.lookahead>=$&&(e.ins_h=(e.ins_h<<e.hash_shift^e.window[e.strstart+$-1])&e.hash_mask,n=e.prev[e.strstart&e.w_mask]=e.head[e.ins_h],e.head[e.ins_h]=e.strstart),e.prev_length=e.match_length,e.prev_match=e.match_start,e.match_length=$-1,0!==n/*NIL*/&&e.prev_length<e.max_lazy_match&&e.strstart-n<=e.w_size-Q/*MAX_DIST(s)*/&&(e.match_length=u(e,n),5>=e.match_length&&(e.strategy===j||e.match_length===$&&4096<e.strstart-e.match_start/*TOO_FAR*/)&&(e.match_length=$-1)),e.prev_length>=$&&e.match_length<=e.prev_length){a=e.strstart+e.lookahead-$,r=C._tr_tally(e,e.strstart-1-e.prev_match,e.prev_length-$),e.lookahead-=e.prev_length-1,e.prev_length-=2;do++e.strstart<=a&&(e.ins_h=(e.ins_h<<e.hash_shift^e.window[e.strstart+$-1])&e.hash_mask,n=e.prev[e.strstart&e.w_mask]=e.head[e.ins_h],e.head[e.ins_h]=e.strstart);while(0!=--e.prev_length);if(e.match_available=0,e.match_length=$-1,e.strstart++,r&&(d(e,!1),0===e.strm.avail_out))return de;/***/}else if(!e.match_available)e.match_available=1,e.strstart++,e.lookahead--;else if(r=C._tr_tally(e,0,e.window[e.strstart-1]),r&&d(e,!1),e.strstart++,e.lookahead--,0===e.strm.avail_out)return de}//Assert (flush != Z_NO_FLUSH, "no flush?");
return e.match_available&&(r=C._tr_tally(e,0,e.window[e.strstart-1]),e.match_available=0),e.insert=e.strstart<$-1?e.strstart:$-1,t===z?(d(e,!0),0===e.strm.avail_out?pe:ce):e.last_lit&&(d(e,!1),0===e.strm.avail_out)?de:le}/* ===========================================================================
	 * For Z_RLE, simply look for runs of bytes, generate matches only of distance
	 * one.  Do not maintain a hash table.  (It will be regenerated if this run of
	 * deflate switches away from Z_RLE.)
	 */function f(e,t){/* set if current block must be flushed *//* byte at distance one to match *//* scan goes up to strend for length of run */for(var n=e.window,r,a,i,s;;){/* Make sure that we always have enough lookahead, except
	     * at the end of the input file. We need MAX_MATCH bytes
	     * for the longest run, plus one for the unrolled loop.
	     */if(e.lookahead<=J){if(h(e),e.lookahead<=J&&t===A)return de;if(0===e.lookahead)break;/* flush the current block */}/* See how many times the previous byte repeats */if(e.match_length=0,e.lookahead>=$&&0<e.strstart&&(i=e.strstart-1,a=n[i],a===n[++i]&&a===n[++i]&&a===n[++i])){s=e.strstart+J;do;while(a===n[++i]&&a===n[++i]&&a===n[++i]&&a===n[++i]&&a===n[++i]&&a===n[++i]&&a===n[++i]&&a===n[++i]&&i<s);e.match_length=J-(s-i),e.match_length>e.lookahead&&(e.match_length=e.lookahead)}//Assert(scan <= s->window+(uInt)(s->window_size-1), "wild scan");
/* Emit match if have run of MIN_MATCH or longer, else emit literal */if(e.match_length>=$?(r=C._tr_tally(e,1,e.match_length-$),e.lookahead-=e.match_length,e.strstart+=e.match_length,e.match_length=0):(r=C._tr_tally(e,0,e.window[e.strstart]),e.lookahead--,e.strstart++),r&&(d(e,!1),0===e.strm.avail_out))return de;/***/}return e.insert=0,t===z?(d(e,!0),0===e.strm.avail_out?pe:ce):e.last_lit&&(d(e,!1),0===e.strm.avail_out)?de:le}/* ===========================================================================
	 * For Z_HUFFMAN_ONLY, do not look for matches.  Do not maintain a hash table.
	 * (It will be regenerated if this run of deflate switches away from Huffman.)
	 */function g(e,t){/* set if current block must be flushed */for(var n;;){/* Make sure that we have a literal to write. */if(0===e.lookahead&&(h(e),0===e.lookahead)){if(t===A)return de;break;/* flush the current block */}/* Output a literal byte */if(e.match_length=0,n=C._tr_tally(e,0,e.window[e.strstart]),e.lookahead--,e.strstart++,n&&(d(e,!1),0===e.strm.avail_out))return de;/***/}return e.insert=0,t===z?(d(e,!0),0===e.strm.avail_out?pe:ce):e.last_lit&&(d(e,!1),0===e.strm.avail_out)?de:le}/* Values for max_lazy_match, good_match and max_chain_length, depending on
	 * the desired pack level (0..9). The values given below have been tuned to
	 * exclude worst case performance for pathological files. Better values may be
	 * found for specific files.
	 */function _(e,t,n,r,a){this.good_length=e,this.max_lazy=t,this.nice_length=n,this.max_chain=r,this.func=a}/* ===========================================================================
	 * Initialize the "longest match" routines for a new zlib stream
	 */function b(e){e.window_size=2*e.w_size,i(e.head),e.max_lazy_match=he[e.level].max_lazy,e.good_match=he[e.level].good_length,e.nice_match=he[e.level].nice_length,e.max_chain_length=he[e.level].max_chain,e.strstart=0,e.block_start=0,e.lookahead=0,e.insert=0,e.match_length=e.prev_length=$-1,e.match_available=0,e.ins_h=0}function y(){this.strm=null,this.status=0,this.pending_buf=null,this.pending_buf_size=0,this.pending_out=0,this.pending=0,this.wrap=0,this.gzhead=null,this.gzindex=0,this.method=Z,this.last_flush=-1,this.w_size=0,this.w_bits=0,this.w_mask=0,this.window=null,this.window_size=0,this.prev=null,this.head=null,this.ins_h=0,this.hash_size=0,this.hash_bits=0,this.hash_mask=0,this.hash_shift=0,this.block_start=0,this.match_length=0,this.prev_match=0,this.match_available=0,this.strstart=0,this.match_start=0,this.lookahead=0,this.prev_length=0,this.max_chain_length=0,this.max_lazy_match=0,this.level=0,this.strategy=0,this.good_match=0,this.nice_match=0,this.dyn_ltree=new N.Buf16(2*V),this.dyn_dtree=new N.Buf16(2*(2*G+1)),this.bl_tree=new N.Buf16(2*(2*X+1)),i(this.dyn_ltree),i(this.dyn_dtree),i(this.bl_tree),this.l_desc=null,this.d_desc=null,this.bl_desc=null,this.bl_count=new N.Buf16(K+1),this.heap=new N.Buf16(2*Y+1),i(this.heap),this.heap_len=0,this.heap_max=0,this.depth=new N.Buf16(2*Y+1),i(this.depth),this.l_buf=0,this.lit_bufsize=0,this.last_lit=0,this.d_buf=0,this.opt_len=0,this.static_len=0,this.matches=0,this.insert=0,this.bi_buf=0,this.bi_valid=0}function x(e){var t;return e&&e.state?(e.total_in=e.total_out=0,e.data_type=H,t=e.state,t.pending=0,t.pending_out=0,0>t.wrap&&(t.wrap=-t.wrap),t.status=t.wrap?te:se,e.adler=2===t.wrap?0// crc32(0, Z_NULL, 0)
:1,t.last_flush=A,C._tr_init(t),R):r(e,P)}function k(e){var t=x(e);return t===R&&b(e.state),t}function v(e,t,n,a,i,o){if(!e)// === Z_NULL
return P;var d=1;if(t===F&&(t=6),0>a?(d=0,a=-a):15<a&&(d=2,a-=16),1>i||i>q||n!==Z||8>a||15<a||0>t||9<t||0>o||o>W)return r(e,P);8===a&&(a=9);/* until 256-byte window bug fixed */var l=new y;return e.state=l,l.strm=e,l.wrap=d,l.gzhead=null,l.w_bits=a,l.w_size=1<<l.w_bits,l.w_mask=l.w_size-1,l.hash_bits=i+7,l.hash_size=1<<l.hash_bits,l.hash_mask=l.hash_size-1,l.hash_shift=~~((l.hash_bits+$-1)/$),l.window=new N.Buf8(2*l.w_size),l.head=new N.Buf16(l.hash_size),l.prev=new N.Buf16(l.w_size),l.lit_bufsize=1<<i+6,l.pending_buf_size=4*l.lit_bufsize,l.pending_buf=new N.Buf8(l.pending_buf_size),l.d_buf=1*l.lit_bufsize,l.l_buf=3*l.lit_bufsize,l.level=t,l.strategy=o,l.method=n,k(e)}function w(e,t){var n,d,s,c;// for gzip header write only
if(!e||!e.state||t>D||0>t)return e?r(e,P):P;if(d=e.state,!e.output||!e.input&&0!==e.avail_in||d.status===oe&&t!==z)return r(e,0===e.avail_out?L:P);/* Write the header */if(d.strm=e,n=d.last_flush,d.last_flush=t,d.status===te)if(2===d.wrap)e.adler=0,l(d,31),l(d,139),l(d,8),d.gzhead?(l(d,(d.gzhead.text?1:0)+(d.gzhead.hcrc?2:0)+(d.gzhead.extra?4:0)+(d.gzhead.name?8:0)+(d.gzhead.comment?16:0)),l(d,255&d.gzhead.time),l(d,255&d.gzhead.time>>8),l(d,255&d.gzhead.time>>16),l(d,255&d.gzhead.time>>24),l(d,9===d.level?2:d.strategy>=U||2>d.level?4:0),l(d,255&d.gzhead.os),d.gzhead.extra&&d.gzhead.extra.length&&(l(d,255&d.gzhead.extra.length),l(d,255&d.gzhead.extra.length>>8)),d.gzhead.hcrc&&(e.adler=S(e.adler,d.pending_buf,d.pending,0)),d.gzindex=0,d.status=ne):(l(d,0),l(d,0),l(d,0),l(d,0),l(d,0),l(d,9===d.level?2:d.strategy>=U||2>d.level?4:0),l(d,ue),d.status=se);else// DEFLATE header
{var u=Z+(d.w_bits-8<<4)<<8,h=-1;h=d.strategy>=U||2>d.level?0:6>d.level?1:6===d.level?2:3,u|=h<<6,0!==d.strstart&&(u|=ee),u+=31-u%31,d.status=se,p(d,u),0!==d.strstart&&(p(d,e.adler>>>16),p(d,65535&e.adler)),e.adler=1}//#ifdef GZIP
if(d.status===ne)if(d.gzhead.extra/* != Z_NULL*/){/* start of bytes to update crc */for(s=d.pending;d.gzindex<(65535&d.gzhead.extra.length)&&!(d.pending===d.pending_buf_size&&(d.gzhead.hcrc&&d.pending>s&&(e.adler=S(e.adler,d.pending_buf,d.pending-s,s)),o(e),s=d.pending,d.pending===d.pending_buf_size));)l(d,255&d.gzhead.extra[d.gzindex]),d.gzindex++;d.gzhead.hcrc&&d.pending>s&&(e.adler=S(e.adler,d.pending_buf,d.pending-s,s)),d.gzindex===d.gzhead.extra.length&&(d.gzindex=0,d.status=re)}else d.status=re;if(d.status===re)if(d.gzhead.name/* != Z_NULL*/){s=d.pending;/* start of bytes to update crc *///int val;
do{if(d.pending===d.pending_buf_size&&(d.gzhead.hcrc&&d.pending>s&&(e.adler=S(e.adler,d.pending_buf,d.pending-s,s)),o(e),s=d.pending,d.pending===d.pending_buf_size)){c=1;break}// JS specific: little magic to add zero terminator to end of string
c=d.gzindex<d.gzhead.name.length?255&d.gzhead.name.charCodeAt(d.gzindex++):0,l(d,c)}while(0!==c);d.gzhead.hcrc&&d.pending>s&&(e.adler=S(e.adler,d.pending_buf,d.pending-s,s)),0===c&&(d.gzindex=0,d.status=ae)}else d.status=ae;if(d.status===ae)if(d.gzhead.comment/* != Z_NULL*/){s=d.pending;/* start of bytes to update crc *///int val;
do{if(d.pending===d.pending_buf_size&&(d.gzhead.hcrc&&d.pending>s&&(e.adler=S(e.adler,d.pending_buf,d.pending-s,s)),o(e),s=d.pending,d.pending===d.pending_buf_size)){c=1;break}// JS specific: little magic to add zero terminator to end of string
c=d.gzindex<d.gzhead.comment.length?255&d.gzhead.comment.charCodeAt(d.gzindex++):0,l(d,c)}while(0!==c);d.gzhead.hcrc&&d.pending>s&&(e.adler=S(e.adler,d.pending_buf,d.pending-s,s)),0===c&&(d.status=ie)}else d.status=ie;//#endif
/* Flush as much pending output as possible */if(d.status===ie&&(d.gzhead.hcrc?(d.pending+2>d.pending_buf_size&&o(e),d.pending+2<=d.pending_buf_size&&(l(d,255&e.adler),l(d,255&e.adler>>8),e.adler=0,d.status=se)):d.status=se),0!==d.pending){if(o(e),0===e.avail_out)return d.last_flush=-1,R;/* Make sure there is something to do and avoid duplicate consecutive
	     * flushes. For repeated and useless calls with Z_FINISH, we keep
	     * returning Z_STREAM_END instead of Z_BUF_ERROR.
	     */}else if(0===e.avail_in&&a(t)<=a(n)&&t!==z)return r(e,L);/* User must not provide more input after the first FINISH: */if(d.status===oe&&0!==e.avail_in)return r(e,L);/* Start a new block or continue the current one.
	   */if(0!==e.avail_in||0!==d.lookahead||t!==A&&d.status!==oe){var m=d.strategy===U?g(d,t):d.strategy===M?f(d,t):he[d.level].func(d,t);if((m===pe||m===ce)&&(d.status=oe),m===de||m===pe)return 0===e.avail_out&&(d.last_flush=-1),R;/* If flush != Z_NO_FLUSH && avail_out == 0, the next call
	       * of deflate should use the same flush parameter to make sure
	       * that the flush is complete. So we don't have to output an
	       * empty block here, this will be done at next call. This also
	       * ensures that for a very small output buffer, we emit at most
	       * one empty block.
	       */if(m===le&&(t===T?C._tr_align(d):t!==D&&(C._tr_stored_block(d,0,0,!1),t===O&&(i(d.head),0===d.lookahead&&(d.strstart=0,d.block_start=0,d.insert=0))),o(e),0===e.avail_out))/* avoid BUF_ERROR at next call, see above */return d.last_flush=-1,R}//Assert(strm->avail_out > 0, "bug2");
//if (strm.avail_out <= 0) { throw new Error("bug2");}
/* Write the trailer *//* write the trailer only once! */return t===z?0>=d.wrap?B:(2===d.wrap?(l(d,255&e.adler),l(d,255&e.adler>>8),l(d,255&e.adler>>16),l(d,255&e.adler>>24),l(d,255&e.total_in),l(d,255&e.total_in>>8),l(d,255&e.total_in>>16),l(d,255&e.total_in>>24)):(p(d,e.adler>>>16),p(d,65535&e.adler)),o(e),0<d.wrap&&(d.wrap=-d.wrap),0===d.pending?B:R):R}/* =========================================================================
	 * Initializes the compression dictionary from the given byte
	 * sequence without producing any compressed output.
	 */// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.
var N=e('../utils/common'),C=e('./trees'),E=e('./adler32'),S=e('./crc32'),I=e('./messages'),A=0,T=1,O=3,z=4,D=5,R=0,B=1,P=-2,L=-5,F=-1,j=1,U=2,M=3,W=4,H=2,Z=8,q=9,Y=256+1+29,G=30,X=19,V=2*Y+1,K=15,$=3,J=258,Q=J+$+1,ee=32,te=42,ne=69,re=73,ae=91,ie=103,se=113,oe=666,de=1,le=2,pe=3,ce=4,ue=3,he;/* Public constants ==========================================================*//* ===========================================================================*//* Allowed flush values; see deflate() and inflate() below for details *///var Z_SYNC_FLUSH    = 2;
//var Z_TREES         = 6;
/* Return codes for the compression/decompression functions. Negative values
	 * are errors, positive values are used for special but normal events.
	 *///var Z_NEED_DICT     = 2;
//var Z_ERRNO         = -1;
//var Z_MEM_ERROR     = -4;
//var Z_VERSION_ERROR = -6;
/* compression levels *///var Z_NO_COMPRESSION      = 0;
//var Z_BEST_SPEED          = 1;
//var Z_BEST_COMPRESSION    = 9;
/* Possible values of the data_type field (though see inflate()) *///var Z_BINARY              = 0;
//var Z_TEXT                = 1;
//var Z_ASCII               = 1; // = Z_TEXT
/* The deflate compression method *//*============================================================================*//* Maximum value for memLevel in deflateInit2 *//* 32K LZ77 window *//* number of length codes, not counting the special END_BLOCK code *//* number of literal bytes 0..255 *//* number of Literal or Length codes, including the END_BLOCK code *//* number of distance codes *//* number of codes used to transfer the bit lengths *//* maximum heap size *//* All codes must not exceed MAX_BITS bits *//* block not completed, need more input or more output *//* block flush performed *//* finish started, need only more output at next deflate *//* finish done, accept no more input or output */he=[/*      good lazy nice chain */new _(0,0,0,0,function(e,t){/* Stored blocks are limited to 0xffff bytes, pending_buf is limited
	   * to pending_buf_size, and each stored block has a 5 byte header:
	   */var n=65535;/* Copy as much as possible from input to output: */for(n>e.pending_buf_size-5&&(n=e.pending_buf_size-5);;){/* Fill the window as much as possible: */if(1>=e.lookahead){if(h(e),0===e.lookahead&&t===A)return de;if(0===e.lookahead)break;/* flush the current block */}//Assert(s->block_start >= 0L, "block gone");
//    if (s.block_start < 0) throw new Error("block gone");
e.strstart+=e.lookahead,e.lookahead=0;/* Emit a stored block if pending_buf will be full: */var r=e.block_start+n;if((0===e.strstart||e.strstart>=r)&&(e.lookahead=e.strstart-r,e.strstart=r,d(e,!1),0===e.strm.avail_out))return de;/***//* Flush if we may have to slide, otherwise block_start may become
	     * negative and the data will be gone:
	     */if(e.strstart-e.block_start>=e.w_size-Q&&(d(e,!1),0===e.strm.avail_out))return de;/***/}return e.insert=0,t===z?(d(e,!0),0===e.strm.avail_out?pe:ce):e.strstart>e.block_start&&(d(e,!1),0===e.strm.avail_out)?de:de}),/* 0 store only */new _(4,4,8,4,s),/* 1 max speed, no lazy matches */new _(4,5,16,8,s),/* 2 */new _(4,6,32,32,s),/* 3 */new _(4,4,16,16,m),/* 4 lazy matches */new _(8,16,32,32,m),/* 5 */new _(8,16,128,128,m),/* 6 */new _(8,32,128,256,m),/* 7 */new _(32,128,258,1024,m),/* 8 */new _(32,258,258,4096,m)/* 9 max compression */],n.deflateInit=function(e,t){return v(e,t,Z,15,8,0)},n.deflateInit2=v,n.deflateReset=k,n.deflateResetKeep=x,n.deflateSetHeader=function(e,t){return e&&e.state?2===e.state.wrap?(e.state.gzhead=t,R):P:P},n.deflate=w,n.deflateEnd=function(e){var t;return e&&e.state/*== Z_NULL*/?(t=e.state.status,t!==te&&t!==ne&&t!==re&&t!==ae&&t!==ie&&t!==se&&t!==oe)?r(e,P):(e.state=null,t===se?r(e,-3):R):P},n.deflateSetDictionary=function(e,t){var r=t.length,a,s,o,n,d,l,p,c;if(!e/*== Z_NULL*/||!e.state/*== Z_NULL*/)return P;if(a=e.state,n=a.wrap,2===n||1===n&&a.status!==te||a.lookahead)return P;/* when using zlib wrappers, compute Adler-32 for provided dictionary */for(1===n&&(e.adler=E(e.adler,t,r,0)),a.wrap=0,r>=a.w_size&&(0===n&&(i(a.head),a.strstart=0,a.block_start=0,a.insert=0),c=new N.Buf8(a.w_size),N.arraySet(c,t,r-a.w_size,a.w_size,0),t=c,r=a.w_size),d=e.avail_in,l=e.next_in,p=e.input,e.avail_in=r,e.next_in=0,e.input=t,h(a);a.lookahead>=$;){s=a.strstart,o=a.lookahead-($-1);do a.ins_h=(a.ins_h<<a.hash_shift^a.window[s+$-1])&a.hash_mask,a.prev[s&a.w_mask]=a.head[a.ins_h],a.head[a.ins_h]=s,s++;while(--o);a.strstart=s,a.lookahead=$-1,h(a)}return a.strstart+=a.lookahead,a.block_start=a.strstart,a.insert=a.lookahead,a.lookahead=0,a.match_length=a.prev_length=$-1,a.match_available=0,e.next_in=l,e.input=p,e.avail_in=d,a.wrap=n,R},n.deflateInfo='pako deflate (from Nodeca project)'},{"../utils/common":41,"./adler32":43,"./crc32":45,"./messages":51,"./trees":52}],47:[function(e,t){t.exports=// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.
function(){this.text=0,this.time=0,this.xflags=0,this.os=0,this.extra=null,this.extra_len=0,this.name='',this.comment='',this.hcrc=0,this.done=!1}},{}],48:[function(e,t){// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.
// See state defs from inflate.js
var n=30;/* got a data error -- remain here until reset *//* i: waiting for type bits, including last-flag bit *//*
	   Decode literal, length, and distance codes and write out the resulting
	   literal and match bytes until either not enough input or output is
	   available, an end-of-block is encountered, or a data error is encountered.
	   When large enough input and output buffers are supplied to inflate(), for
	   example, a 16K input buffer and a 64K output buffer, more than 95% of the
	   inflate execution time is spent in this routine.

	   Entry assumptions:

	        state.mode === LEN
	        strm.avail_in >= 6
	        strm.avail_out >= 258
	        start >= strm.avail_out
	        state.bits < 8

	   On return, state.mode is one of:

	        LEN -- ran out of enough output space or enough available input
	        TYPE -- reached end of block code, inflate() to interpret next block
	        BAD -- error in block data

	   Notes:

	    - The maximum input bits used by a length/distance pair is 15 bits for the
	      length code, 5 bits for the length extra, 15 bits for the distance code,
	      and 13 bits for the distance extra.  This totals 48 bits, or six bytes.
	      Therefore if strm.avail_in >= 6, then there is enough input to avoid
	      checking for available input while decoding.

	    - The maximum bytes that a single length/distance pair can output is 258
	      bytes, which is the maximum length that can be coded.  inflate_fast()
	      requires strm.avail_out >= 258 for each loop to avoid checking for
	      output space.
	 */t.exports=function(e,t){var r,a,i,s,o,d,l,p,c,u,h,m,f,g,_,b,y,x,k,v,w,N,C,E,S;/* local strm.input *//* have enough input while in < last *//* local strm.output *//* inflate()'s initial strm.output *//* while out < end, enough space available *///#ifdef INFLATE_STRICT
/* maximum distance from zlib header *///#endif
/* window size or zero if not using window *//* valid bytes in the window *//* window write index */// Use `s_window` instead `window`, avoid conflict with instrumentation tools
/* allocated sliding window, if wsize != 0 *//* local strm.hold *//* local strm.bits *//* local strm.lencode *//* local strm.distcode *//* mask for first level of length codes *//* mask for first level of distance codes *//* retrieved table entry *//* code bits, operation, extra bits, or *//*  window position, window bytes to copy *//* match length, unused bytes *//* match distance *//* where to copy match from */r=e.state,a=e.next_in,E=e.input,i=a+(e.avail_in-5),s=e.next_out,S=e.output,o=s-(t-e.avail_out),d=s+(e.avail_out-257),l=r.dmax,p=r.wsize,c=r.whave,u=r.wnext,h=r.window,m=r.hold,f=r.bits,g=r.lencode,_=r.distcode,b=(1<<r.lenbits)-1,y=(1<<r.distbits)-1;/* decode literals and length/distances until end-of-block or not enough
	     input data or output space */top:do{15>f&&(m+=E[a++]<<f,f+=8,m+=E[a++]<<f,f+=8),x=g[m&b];dolen:for(;;){if(k=x>>>24/*here.bits*/,m>>>=k,f-=k,k=255&x>>>16/*here.op*/,0===k)S[s++]=65535&x/*here.val*/;else if(16&k){v=65535&x/*here.val*/,k&=15,k&&(f<k&&(m+=E[a++]<<f,f+=8),v+=m&(1<<k)-1,m>>>=k,f-=k),15>f&&(m+=E[a++]<<f,f+=8,m+=E[a++]<<f,f+=8),x=_[m&y];dodist:for(;;){if(k=x>>>24/*here.bits*/,m>>>=k,f-=k,k=255&x>>>16/*here.op*/,16&k){//#ifdef INFLATE_STRICT
if(w=65535&x/*here.val*/,k&=15,f<k&&(m+=E[a++]<<f,f+=8,f<k&&(m+=E[a++]<<f,f+=8)),w+=m&(1<<k)-1,w>l){e.msg='invalid distance too far back',r.mode=n;break top}//#endif
/* max distance in output */if(m>>>=k,f-=k,k=s-o,w>k){/* distance back in window */if(k=w-k,k>c&&r.sane){e.msg='invalid distance too far back',r.mode=n;break top}// (!) This block is disabled in zlib defailts,
// don't enable it for binary compatibility
//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR
//                if (len <= op - whave) {
//                  do {
//                    output[_out++] = 0;
//                  } while (--len);
//                  continue top;
//                }
//                len -= op - whave;
//                do {
//                  output[_out++] = 0;
//                } while (--op > whave);
//                if (op === 0) {
//                  from = _out - dist;
//                  do {
//                    output[_out++] = output[from++];
//                  } while (--len);
//                  continue top;
//                }
//#endif
if(N=0,C=h,0===u){if(N+=p-k,k<v){v-=k;do S[s++]=h[N++];while(--k);N=s-w,C=S}}else if(u<k){if(N+=p+u-k,k-=u,k<v){v-=k;do S[s++]=h[N++];while(--k);if(N=0,u<v){k=u,v-=k;do S[s++]=h[N++];while(--k);N=s-w,C=S}}}else if(N+=u-k,k<v){v-=k;do S[s++]=h[N++];while(--k);N=s-w,C=S}for(;2<v;)S[s++]=C[N++],S[s++]=C[N++],S[s++]=C[N++],v-=3;v&&(S[s++]=C[N++],1<v&&(S[s++]=C[N++]))}else{N=s-w;/* copy direct from output */do S[s++]=S[N++],S[s++]=S[N++],S[s++]=S[N++],v-=3;while(2<v);v&&(S[s++]=S[N++],1<v&&(S[s++]=S[N++]))}}else if(0==(64&k)){x=_[(65535&x)+(/*here.val*/m&(1<<k)-1)];continue dodist}else{e.msg='invalid distance code',r.mode=n;break top}break;// need to emulate goto via "continue"
}}else if(0==(64&k)){x=g[(65535&x)+(/*here.val*/m&(1<<k)-1)];continue dolen}else if(32&k){r.mode=12;break top}else{e.msg='invalid literal/length code',r.mode=n;break top}break;// need to emulate goto via "continue"
}}while(a<i&&s<d);/* return unused bytes (on entry, bits < 8, so in won't go too far back) */return v=f>>3,a-=v,f-=v<<3,m&=(1<<f)-1,e.next_in=a,e.next_out=s,e.avail_in=a<i?5+(i-a):5-(a-i),e.avail_out=s<d?257+(d-s):257-(s-d),r.hold=m,void(r.bits=f)}},{}],49:[function(e,t,n){function r(e){return(255&e>>>24)+(65280&e>>>8)+((65280&e)<<8)+((255&e)<<24)}function a(){this.mode=0,this.last=!1,this.wrap=0,this.havedict=!1,this.flags=0,this.dmax=0,this.check=0,this.total=0,this.head=null,this.wbits=0,this.wsize=0,this.whave=0,this.wnext=0,this.window=null,this.hold=0,this.bits=0,this.length=0,this.offset=0,this.extra=0,this.lencode=null,this.distcode=null,this.lenbits=0,this.distbits=0,this.ncode=0,this.nlen=0,this.ndist=0,this.have=0,this.next=null,this.lens=new c.Buf16(320),this.work=new c.Buf16(288),this.lendyn=null,this.distdyn=null,this.sane=0,this.back=0,this.was=0}function i(e){var t;return e&&e.state?(t=e.state,e.total_in=e.total_out=t.total=0,e.msg='',t.wrap&&(e.adler=1&t.wrap),t.mode=C,t.last=0,t.havedict=0,t.dmax=32768,t.head=null/*Z_NULL*/,t.hold=0,t.bits=0,t.lencode=t.lendyn=new c.Buf32(ne),t.distcode=t.distdyn=new c.Buf32(re),t.sane=1,t.back=-1,x):k;//Tracev((stderr, "inflate: reset\n"));
}function s(e){var t;return e&&e.state?(t=e.state,t.wsize=0,t.whave=0,t.wnext=0,i(e)):k}function o(e,t){var n,r;/* get the state */return e&&e.state?(r=e.state,0>t?(n=0,t=-t):(n=(t>>4)+1,48>t&&(t&=15)),t&&(8>t||15<t))?k:(null!==r.window&&r.wbits!==t&&(r.window=null),r.wrap=n,r.wbits=t,s(e)):k;/* set number of window bits, free window if different */}function d(e,t){var n,r;return e?(r=new a,e.state=r,r.window=null/*Z_NULL*/,n=o(e,t),n!==x&&(e.state=null/*Z_NULL*/),n):k;//strm.msg = Z_NULL;                 /* in case we return an error */
}// We have no pointers in JS, so keep tables separate
/*
	 Return state with length and distance decoding tables and index sizes set to
	 fixed code decoding.  Normally this returns fixed tables from inffixed.h.
	 If BUILDFIXED is defined, then instead this routine builds the tables the
	 first time it's called, and returns those tables the first time and
	 thereafter.  This reduces the size of the code by about 2K bytes, in
	 exchange for a little execution time.  However, BUILDFIXED should not be
	 used for threaded applications, since the rewriting of the tables and virgin
	 may not be thread-safe.
	 */function l(e){/* build fixed huffman tables if first call (may not be thread safe) */if(ae){var t;for(ie=new c.Buf32(512),se=new c.Buf32(32),t=0;144>t;)e.lens[t++]=8;for(;256>t;)e.lens[t++]=9;for(;280>t;)e.lens[t++]=7;for(;288>t;)e.lens[t++]=8;for(f(g,e.lens,0,288,ie,0,e.work,{bits:9}),t=0;32>t;)e.lens[t++]=5;f(_,e.lens,0,32,se,0,e.work,{bits:5}),ae=!1}e.lencode=ie,e.lenbits=9,e.distcode=se,e.distbits=5}/*
	 Update the window with the last wsize (normally 32K) bytes written before
	 returning.  If window does not exist yet, create it.  This is only called
	 when a window is already in use, or when output has been written during this
	 inflate call, but the end of the deflate stream has not been reached yet.
	 It is also called to create a window for dictionary data when a dictionary
	 is loaded.

	 Providing output buffers larger than 32K to inflate() should provide a speed
	 advantage, since only the last 32K of output is copied to the sliding window
	 upon return from inflate(), and since all distances after the first 32K of
	 output will fall in the output data, making match copies simpler and faster.
	 The advantage may be dependent on the size of the processor's data caches.
	 */function p(e,t,n,r){var a=e.state,i;/* if it hasn't been done already, allocate space for the window */return null===a.window&&(a.wsize=1<<a.wbits,a.wnext=0,a.whave=0,a.window=new c.Buf8(a.wsize)),r>=a.wsize?(c.arraySet(a.window,t,n-a.wsize,a.wsize,0),a.wnext=0,a.whave=a.wsize):(i=a.wsize-a.wnext,i>r&&(i=r),c.arraySet(a.window,t,n-r,i,a.wnext),r-=i,r?(c.arraySet(a.window,t,n-r,r,0),a.wnext=r,a.whave=a.wsize):(a.wnext+=i,a.wnext===a.wsize&&(a.wnext=0),a.whave<a.wsize&&(a.whave+=i))),0}// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.
var c=e('../utils/common'),u=e('./adler32'),h=e('./crc32'),m=e('./inffast'),f=e('./inftrees'),g=1,_=2,b=4,y=6,x=0,k=-2,v=-3,w=-4,N=8,C=1,E=2,S=3,I=4,A=5,T=6,O=7,z=8,D=9,R=10,B=11,P=12,L=13,F=14,j=15,U=16,M=17,W=18,H=19,Z=20,q=21,Y=22,G=23,X=24,V=25,K=26,$=27,J=28,Q=29,ee=30,te=31,ne=852,re=592,ae=!0,ie,se;/* Public constants ==========================================================*//* ===========================================================================*//* Allowed flush values; see deflate() and inflate() below for details *///var Z_NO_FLUSH      = 0;
//var Z_PARTIAL_FLUSH = 1;
//var Z_SYNC_FLUSH    = 2;
//var Z_FULL_FLUSH    = 3;
/* Return codes for the compression/decompression functions. Negative values
	 * are errors, positive values are used for special but normal events.
	 *///var Z_ERRNO         = -1;
//var Z_VERSION_ERROR = -6;
/* The deflate compression method *//* STATES ====================================================================*//* ===========================================================================*//* i: waiting for magic header *//* i: waiting for method and flags (gzip) *//* i: waiting for modification time (gzip) *//* i: waiting for extra flags and operating system (gzip) *//* i: waiting for extra length (gzip) *//* i: waiting for extra bytes (gzip) *//* i: waiting for end of file name (gzip) *//* i: waiting for end of comment (gzip) *//* i: waiting for header crc (gzip) *//* i: waiting for dictionary check value *//* waiting for inflateSetDictionary() call *//* i: waiting for type bits, including last-flag bit *//* i: same, but skip check to exit inflate on new block *//* i: waiting for stored size (length and complement) *//* i/o: same as COPY below, but only first time in *//* i/o: waiting for input or output to copy stored block *//* i: waiting for dynamic block table lengths *//* i: waiting for code length code lengths *//* i: waiting for length/lit and distance code lengths *//* i: same as LEN below, but only first time in *//* i: waiting for length/lit/eob code *//* i: waiting for length extra bits *//* i: waiting for distance code *//* i: waiting for distance extra bits *//* o: waiting for output space to copy string *//* o: waiting for output space to write literal *//* i: waiting for 32-bit check value *//* i: waiting for 32-bit length (gzip) *//* finished check, done -- remain here until reset *//* got a data error -- remain here until reset *//* got an inflate() memory error -- remain here until reset *//* looking for synchronization bytes to restart inflate() *//* ===========================================================================*///var ENOUGH =  (ENOUGH_LENS+ENOUGH_DISTS);
/* 32K LZ77 window */n.inflateReset=s,n.inflateReset2=o,n.inflateResetKeep=i,n.inflateInit=function(e){return d(e,15)},n.inflateInit2=d,n.inflate=function(e,t){var a=0,i=new c.Buf8(4),s=/* permutation of code lengths */[16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15],o,d,ne,re,ae,ie,se,oe,de,le,pe,ce,ue,he,me,fe,ge,_e,be,ye,xe,ke,ve,we;// input/output buffers
/* next input INDEX *//* next output INDEX *//* available input and output *//* bit buffer *//* bits in bit buffer *//* save starting available input and output *//* number of stored or match bytes to copy *//* where to copy match bytes from *//* current decoding table entry */// paked "here" denormalized (JS specific)
//var last;                   /* parent table entry */
// paked "last" denormalized (JS specific)
/* length to copy for repeats, bits to drop *//* return code *//* buffer for gzip header crc calculation */// temporary var for NEED_BITS
if(!e||!e.state||!e.output||!e.input&&0!==e.avail_in)return k;o=e.state,o.mode===P&&(o.mode=L),ae=e.next_out,ne=e.output,se=e.avail_out,re=e.next_in,d=e.input,ie=e.avail_in,oe=o.hold,de=o.bits,le=ie,pe=se,ke=x;inf_leave:// goto emulation
for(;;)switch(o.mode){case C:if(0===o.wrap){o.mode=L;break}//=== NEEDBITS(16);
for(;16>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
if(2&o.wrap&&35615===oe){o.check=0/*crc32(0L, Z_NULL, 0)*/,i[0]=255&oe,i[1]=255&oe>>>8,o.check=h(o.check,i,2,0),oe=0,de=0,o.mode=E;break}if(o.flags=0,o.head&&(o.head.done=!1),!(1&o.wrap)||/* check if zlib header allowed */(((255&oe)<</*BITS(8)*/8)+(oe>>8))%31){e.msg='incorrect header check',o.mode=ee;break}if((15&oe)!==/*BITS(4)*/N){e.msg='unknown compression method',o.mode=ee;break}//--- DROPBITS(4) ---//
if(oe>>>=4,de-=4,xe=(15&oe)+/*BITS(4)*/8,0===o.wbits)o.wbits=xe;else if(xe>o.wbits){e.msg='invalid window size',o.mode=ee;break}o.dmax=1<<xe,e.adler=o.check=1/*adler32(0L, Z_NULL, 0)*/,o.mode=512&oe?R:P,oe=0,de=0;//===//
break;case E://=== NEEDBITS(16); */
for(;16>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
if(o.flags=oe,(255&o.flags)!==N){e.msg='unknown compression method',o.mode=ee;break}if(57344&o.flags){e.msg='unknown header flags set',o.mode=ee;break}o.head&&(o.head.text=1&oe>>8),512&o.flags&&(i[0]=255&oe,i[1]=255&oe>>>8,o.check=h(o.check,i,2,0)),oe=0,de=0,o.mode=S;/* falls through */case S://=== NEEDBITS(32); */
for(;32>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
o.head&&(o.head.time=oe),512&o.flags&&(i[0]=255&oe,i[1]=255&oe>>>8,i[2]=255&oe>>>16,i[3]=255&oe>>>24,o.check=h(o.check,i,4,0)),oe=0,de=0,o.mode=I;/* falls through */case I://=== NEEDBITS(16); */
for(;16>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
o.head&&(o.head.xflags=255&oe,o.head.os=oe>>8),512&o.flags&&(i[0]=255&oe,i[1]=255&oe>>>8,o.check=h(o.check,i,2,0)),oe=0,de=0,o.mode=A;/* falls through */case A:if(1024&o.flags){//=== NEEDBITS(16); */
for(;16>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
o.length=oe,o.head&&(o.head.extra_len=oe),512&o.flags&&(i[0]=255&oe,i[1]=255&oe>>>8,o.check=h(o.check,i,2,0)),oe=0,de=0}else o.head&&(o.head.extra=null/*Z_NULL*/);o.mode=T;/* falls through */case T:if(1024&o.flags&&(ce=o.length,ce>ie&&(ce=ie),ce&&(o.head&&(xe=o.head.extra_len-o.length,!o.head.extra&&(o.head.extra=Array(o.head.extra_len)),c.arraySet(o.head.extra,d,re,// extra field is limited to 65536 bytes
// - no need for additional size check
ce,/*len + copy > state.head.extra_max - len ? state.head.extra_max : copy,*/xe)),512&o.flags&&(o.check=h(o.check,d,ce,re)),ie-=ce,re+=ce,o.length-=ce),o.length))break inf_leave;o.length=0,o.mode=O;/* falls through */case O:if(2048&o.flags){if(0===ie)break inf_leave;ce=0;do xe=d[re+ce++],o.head&&xe&&65536>o.length/*state.head.name_max*/&&(o.head.name+=Fe(xe));while(xe&&ce<ie);if(512&o.flags&&(o.check=h(o.check,d,ce,re)),ie-=ce,re+=ce,xe)break inf_leave}else o.head&&(o.head.name=null);o.length=0,o.mode=z;/* falls through */case z:if(4096&o.flags){if(0===ie)break inf_leave;ce=0;do xe=d[re+ce++],o.head&&xe&&65536>o.length/*state.head.comm_max*/&&(o.head.comment+=Fe(xe));while(xe&&ce<ie);if(512&o.flags&&(o.check=h(o.check,d,ce,re)),ie-=ce,re+=ce,xe)break inf_leave}else o.head&&(o.head.comment=null);o.mode=D;/* falls through */case D:if(512&o.flags){//=== NEEDBITS(16); */
for(;16>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
if(oe!==(65535&o.check)){e.msg='header crc mismatch',o.mode=ee;break}//=== INITBITS();
oe=0,de=0}o.head&&(o.head.hcrc=1&o.flags>>9,o.head.done=!0),e.adler=o.check=0,o.mode=P;break;case R://=== NEEDBITS(32); */
for(;32>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
e.adler=o.check=r(oe),oe=0,de=0,o.mode=B;/* falls through */case B:if(0===o.havedict)//---
return e.next_out=ae,e.avail_out=se,e.next_in=re,e.avail_in=ie,o.hold=oe,o.bits=de,2;e.adler=o.check=1/*adler32(0L, Z_NULL, 0)*/,o.mode=P;/* falls through */case P:if(t===5||t===y)break inf_leave;/* falls through */case L:if(o.last){oe>>>=7&de,de-=7&de,o.mode=$;break}//=== NEEDBITS(3); */
for(;3>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
//---//
switch(o.last=1&oe/*BITS(1)*/,oe>>>=1,de-=1,3&oe){/*BITS(2)*/case 0:o.mode=F;break;case 1:/* decode codes */if(l(o),o.mode=Z,t===y){oe>>>=2,de-=2;//---//
break inf_leave}break;case 2:o.mode=M;break;case 3:e.msg='invalid block type',o.mode=ee;}//--- DROPBITS(2) ---//
oe>>>=2,de-=2;//---//
break;case F://---//
//=== NEEDBITS(32); */
for(oe>>>=7&de,de-=7&de;32>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
if((65535&oe)!=(65535^oe>>>16)){e.msg='invalid stored block lengths',o.mode=ee;break}if(o.length=65535&oe,oe=0,de=0,o.mode=j,t===y)break inf_leave;/* falls through */case j:o.mode=U;/* falls through */case U:if(ce=o.length,ce){if(ce>ie&&(ce=ie),ce>se&&(ce=se),0===ce)break inf_leave;//--- zmemcpy(put, next, copy); ---
c.arraySet(ne,d,re,ce,ae),ie-=ce,re+=ce,se-=ce,ae+=ce,o.length-=ce;break}//Tracev((stderr, "inflate:       stored end\n"));
o.mode=P;break;case M://=== NEEDBITS(14); */
for(;14>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
//---//
//#ifndef PKZIP_BUG_WORKAROUND
if(o.nlen=(31&oe)+/*BITS(5)*/257,oe>>>=5,de-=5,o.ndist=(31&oe)+/*BITS(5)*/1,oe>>>=5,de-=5,o.ncode=(15&oe)+/*BITS(4)*/4,oe>>>=4,de-=4,286<o.nlen||30<o.ndist){e.msg='too many length or distance symbols',o.mode=ee;break}//#endif
//Tracev((stderr, "inflate:       table sizes ok\n"));
o.have=0,o.mode=W;/* falls through */case W:for(;o.have<o.ncode;){//=== NEEDBITS(3);
for(;3>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
o.lens[s[o.have++]]=7&oe,oe>>>=3,de-=3}for(;19>o.have;)o.lens[s[o.have++]]=0;// We have separate tables & no pointers. 2 commented lines below not needed.
//state.next = state.codes;
//state.lencode = state.next;
// Switch to use dynamic table
if(o.lencode=o.lendyn,o.lenbits=7,ve={bits:o.lenbits},ke=f(0,o.lens,0,19,o.lencode,0,o.work,ve),o.lenbits=ve.bits,ke){e.msg='invalid code lengths set',o.mode=ee;break}//Tracev((stderr, "inflate:       code lengths ok\n"));
o.have=0,o.mode=H;/* falls through */case H:for(;o.have<o.nlen+o.ndist;){for(;;){if(a=o.lencode[oe&(1<<o.lenbits)-1],me=a>>>24,fe=255&a>>>16,ge=65535&a,me<=de)break;//--- PULLBYTE() ---//
if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}if(16>ge)oe>>>=me,de-=me,o.lens[o.have++]=ge;else{if(16===ge){for(we=me+2;de<we;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
//--- DROPBITS(here.bits) ---//
//---//
if(oe>>>=me,de-=me,0===o.have){e.msg='invalid bit length repeat',o.mode=ee;break}xe=o.lens[o.have-1],ce=3+(3&oe),oe>>>=2,de-=2}else if(17===ge){for(we=me+3;de<we;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
//--- DROPBITS(here.bits) ---//
oe>>>=me,de-=me,xe=0,ce=3+(7&oe),oe>>>=3,de-=3}else{for(we=me+7;de<we;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
//--- DROPBITS(here.bits) ---//
oe>>>=me,de-=me,xe=0,ce=11+(127&oe),oe>>>=7,de-=7}if(o.have+ce>o.nlen+o.ndist){e.msg='invalid bit length repeat',o.mode=ee;break}for(;ce--;)o.lens[o.have++]=xe}}/* handle error breaks in while */if(o.mode===ee)break;/* check for end-of-block code (better have one) */if(0===o.lens[256]){e.msg='invalid code -- missing end-of-block',o.mode=ee;break}/* build code tables -- note: do not change the lenbits or distbits
	         values here (9 and 6) without reading the comments in inftrees.h
	         concerning the ENOUGH constants, which depend on those values */// state.lencode = state.next;
if(o.lenbits=9,ve={bits:o.lenbits},ke=f(g,o.lens,0,o.nlen,o.lencode,0,o.work,ve),o.lenbits=ve.bits,ke){e.msg='invalid literal/lengths set',o.mode=ee;break}// state.distcode = state.next;
if(o.distbits=6,o.distcode=o.distdyn,ve={bits:o.distbits},ke=f(_,o.lens,o.nlen,o.ndist,o.distcode,0,o.work,ve),o.distbits=ve.bits,ke){e.msg='invalid distances set',o.mode=ee;break}//Tracev((stderr, 'inflate:       codes ok\n'));
if(o.mode=Z,t===y)break inf_leave;/* falls through */case Z:o.mode=q;/* falls through */case q:if(6<=ie&&258<=se){e.next_out=ae,e.avail_out=se,e.next_in=re,e.avail_in=ie,o.hold=oe,o.bits=de,m(e,pe),ae=e.next_out,ne=e.output,se=e.avail_out,re=e.next_in,d=e.input,ie=e.avail_in,oe=o.hold,de=o.bits,o.mode===P&&(o.back=-1);break}for(o.back=0;;){if(a=o.lencode[oe&(1<<o.lenbits)-1],me=a>>>24,fe=255&a>>>16,ge=65535&a,me<=de)break;//--- PULLBYTE() ---//
if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}if(fe&&0==(240&fe)){for(_e=me,be=fe,ye=ge;;){if(a=o.lencode[ye+((oe&(1<<_e+be)-1)>>/*BITS(last.bits + last.op)*/_e)],me=a>>>24,fe=255&a>>>16,ge=65535&a,_e+me<=de)break;//--- PULLBYTE() ---//
if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//--- DROPBITS(last.bits) ---//
oe>>>=_e,de-=_e,o.back+=_e}//--- DROPBITS(here.bits) ---//
if(oe>>>=me,de-=me,o.back+=me,o.length=ge,0===fe){o.mode=K;break}if(32&fe){o.back=-1,o.mode=P;break}if(64&fe){e.msg='invalid literal/length code',o.mode=ee;break}o.extra=15&fe,o.mode=Y;/* falls through */case Y:if(o.extra){for(we=o.extra;de<we;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
o.length+=oe&(1<<o.extra)-1/*BITS(state.extra)*/,oe>>>=o.extra,de-=o.extra,o.back+=o.extra}//Tracevv((stderr, "inflate:         length %u\n", state.length));
o.was=o.length,o.mode=G;/* falls through */case G:for(;;){if(a=o.distcode[oe&(1<<o.distbits)-1],me=a>>>24,fe=255&a>>>16,ge=65535&a,me<=de)break;//--- PULLBYTE() ---//
if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}if(0==(240&fe)){for(_e=me,be=fe,ye=ge;;){if(a=o.distcode[ye+((oe&(1<<_e+be)-1)>>/*BITS(last.bits + last.op)*/_e)],me=a>>>24,fe=255&a>>>16,ge=65535&a,_e+me<=de)break;//--- PULLBYTE() ---//
if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//--- DROPBITS(last.bits) ---//
oe>>>=_e,de-=_e,o.back+=_e}//--- DROPBITS(here.bits) ---//
if(oe>>>=me,de-=me,o.back+=me,64&fe){e.msg='invalid distance code',o.mode=ee;break}o.offset=ge,o.extra=15&fe,o.mode=X;/* falls through */case X:if(o.extra){for(we=o.extra;de<we;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
o.offset+=oe&(1<<o.extra)-1/*BITS(state.extra)*/,oe>>>=o.extra,de-=o.extra,o.back+=o.extra}//#ifdef INFLATE_STRICT
if(o.offset>o.dmax){e.msg='invalid distance too far back',o.mode=ee;break}//#endif
//Tracevv((stderr, "inflate:         distance %u\n", state.offset));
o.mode=V;/* falls through */case V:if(0===se)break inf_leave;if(ce=pe-se,o.offset>ce){if(ce=o.offset-ce,ce>o.whave&&o.sane){e.msg='invalid distance too far back',o.mode=ee;break}// (!) This block is disabled in zlib defailts,
// don't enable it for binary compatibility
//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR
//          Trace((stderr, "inflate.c too far\n"));
//          copy -= state.whave;
//          if (copy > state.length) { copy = state.length; }
//          if (copy > left) { copy = left; }
//          left -= copy;
//          state.length -= copy;
//          do {
//            output[put++] = 0;
//          } while (--copy);
//          if (state.length === 0) { state.mode = LEN; }
//          break;
//#endif
ce>o.wnext?(ce-=o.wnext,ue=o.wsize-ce):ue=o.wnext-ce,ce>o.length&&(ce=o.length),he=o.window}else he=ne,ue=ae-o.offset,ce=o.length;ce>se&&(ce=se),se-=ce,o.length-=ce;do ne[ae++]=he[ue++];while(--ce);0===o.length&&(o.mode=q);break;case K:if(0===se)break inf_leave;ne[ae++]=o.length,se--,o.mode=q;break;case $:if(o.wrap){//=== NEEDBITS(32);
for(;32>de;){if(0===ie)break inf_leave;ie--,oe|=d[re++]<<de,de+=8}//===//
// NB: crc32 stored as signed 32-bit int, zswap32 returns signed too
if(pe-=se,e.total_out+=pe,o.total+=pe,pe&&(e.adler=o.check=/*UPDATE(state.check, put - _out, _out);*/o.flags?h(o.check,ne,pe,ae-pe):u(o.check,ne,pe,ae-pe)),pe=se,(o.flags?oe:r(oe))!==o.check){e.msg='incorrect data check',o.mode=ee;break}//=== INITBITS();
oe=0,de=0}o.mode=J;/* falls through */case J:if(o.wrap&&o.flags){//=== NEEDBITS(32);
for(;32>de;){if(0===ie)break inf_leave;ie--,oe+=d[re++]<<de,de+=8}//===//
if(oe!==(4294967295&o.total)){e.msg='incorrect length check',o.mode=ee;break}//=== INITBITS();
oe=0,de=0}o.mode=Q;/* falls through */case Q:ke=1;break inf_leave;case ee:ke=v;break inf_leave;case te:return w;case 32:/* falls through */default:return k;}// inf_leave <- here is real place for "goto inf_leave", emulated via "break inf_leave"
/*
	     Return from inflate(), updating the total counts and the check value.
	     If there was no progress during the inflate() call, return a buffer
	     error.  Call updatewindow() to create and/or update the window state.
	     Note: a memory error from inflate() is non-recoverable.
	   *///--- RESTORE() ---
//---
return(e.next_out=ae,e.avail_out=se,e.next_in=re,e.avail_in=ie,o.hold=oe,o.bits=de,(o.wsize||pe!==e.avail_out&&o.mode<ee&&(o.mode<$||t!==b))&&p(e,e.output,e.next_out,pe-e.avail_out))?(o.mode=te,w):(le-=e.avail_in,pe-=e.avail_out,e.total_in+=le,e.total_out+=pe,o.total+=pe,o.wrap&&pe&&(e.adler=o.check=/*UPDATE(state.check, strm.next_out - _out, _out);*/o.flags?h(o.check,ne,pe,e.next_out-pe):u(o.check,ne,pe,e.next_out-pe)),e.data_type=o.bits+(o.last?64:0)+(o.mode===P?128:0)+(o.mode===Z||o.mode===j?256:0),(0===le&&0===pe||t===b)&&ke===x&&(ke=-5),ke)},n.inflateEnd=function(e){if(!e||!e.state/*|| strm->zfree == (free_func)0*/)return k;var t=e.state;return t.window&&(t.window=null),e.state=null,x},n.inflateGetHeader=function(e,t){var n;/* check state *//* save header structure */return e&&e.state?(n=e.state,0==(2&n.wrap))?k:(n.head=t,t.done=!1,x):k},n.inflateSetDictionary=function(e,t){var n=t.length,r,a,i;/* check state *//* check for correct dictionary identifier */// Tracev((stderr, "inflate:   dictionary set\n"));
return e&&e.state/* == Z_NULL */?(r=e.state,0!==r.wrap&&r.mode!==B)?k:r.mode===B&&(a=1,a=u(a,t,n,0),a!==r.check)?v:(i=p(e,t,n,n),i)?(r.mode=te,w):(r.havedict=1,x):k;/* copy dictionary to window using updatewindow(), which will amend the
	   existing dictionary if appropriate */},n.inflateInfo='pako inflate (from Nodeca project)'},{"../utils/common":41,"./adler32":43,"./crc32":45,"./inffast":48,"./inftrees":50}],50:[function(e,t){// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.
var n=e('../utils/common'),r=15,a=852,i=592,s=0,o=1,d=2,l=[/* Length codes 257..285 base */3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,0,0],p=[/* Length codes 257..285 extra */16,16,16,16,16,16,16,16,17,17,17,17,18,18,18,18,19,19,19,19,20,20,20,20,21,21,21,21,16,72,78],c=[/* Distance codes 0..29 base */1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577,0,0],u=[/* Distance codes 0..29 extra */16,16,16,16,17,17,18,18,19,19,20,20,21,21,22,22,23,23,24,24,25,25,26,26,27,27,28,28,29,29,64,64];//var ENOUGH = (ENOUGH_LENS+ENOUGH_DISTS);
t.exports=function(e,t,h,m,f,g,_,b){var y=b.bits,x=0,k=0,v=0,w=0,N=0,C=0,E=0,S=0,I=0,A=0,T=null,O=0,z=new n.Buf16(r+1),D=new n.Buf16(r+1),R=null,B=0,P,L,F,j,U,M,W,H,Z;//here = opts.here; /* table entry for duplication */
/* a code's length in bits *//* index of code symbols *//* minimum and maximum code lengths *//* number of index bits for root table *//* number of index bits for current table *//* code bits to drop for sub-table *//* number of prefix codes available *//* code entries in table used *//* Huffman code *//* for incrementing code, index *//* index for replicating entries *//* low bits for current root entry *//* mask for low root bits *//* next available space in table *//* base value table to use *///  var shoextra;    /* extra bits table to use */
/* use base and extra for symbol > end *///[MAXBITS+1];    /* number of codes of each length */
//[MAXBITS+1];     /* offsets in table for each length */
/*
	   Process a set of code lengths to create a canonical Huffman code.  The
	   code lengths are lens[0..codes-1].  Each length corresponds to the
	   symbols 0..codes-1.  The Huffman code is generated by first sorting the
	   symbols by length from short to long, and retaining the symbol order
	   for codes with equal lengths.  Then the code starts with all zero bits
	   for the first code of the shortest length, and the codes are integer
	   increments for the same length, and zeros are appended as the length
	   increases.  For the deflate format, these bits are stored backwards
	   from their more natural integer increment ordering, and so when the
	   decoding tables are built in the large loop below, the integer codes
	   are incremented backwards.

	   This routine assumes, but does not check, that all of the entries in
	   lens[] are in the range 0..MAXBITS.  The caller must assure this.
	   1..MAXBITS is interpreted as that code length.  zero means that that
	   symbol does not occur in this code.

	   The codes are sorted by computing a count of codes for each length,
	   creating from that a table of starting indices for each length in the
	   sorted table, and then entering the symbols in order in the sorted
	   table.  The sorted table is work[], with that space being provided by
	   the caller.

	   The length counts are used for other purposes as well, i.e. finding
	   the minimum and maximum length codes, determining if there are any
	   codes at all, checking for a valid set of lengths, and looking ahead
	   at length counts to determine sub-table sizes when building the
	   decoding tables.
	   *//* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */for(x=0;x<=r;x++)z[x]=0;for(k=0;k<m;k++)z[t[h+k]]++;/* bound code lengths, force root to be within code lengths */for(N=y,w=r;1<=w&&0===z[w];w--);if(N>w&&(N=w),0==w)return f[g++]=20971520,f[g++]=20971520,b.bits=1,0;/* no symbols, but wait for decoding to report error */for(v=1;v<w&&0===z[v];v++);for(N<v&&(N=v),S=1,x=1;x<=r;x++)if(S<<=1,S-=z[x],0>S)return-1;/* over-subscribed */if(0<S&&(e===s||1!=w))return-1;/* incomplete set *//* generate offsets into symbol table for each length for sorting */for(D[1]=0,x=1;x<r;x++)D[x+1]=D[x]+z[x];/* sort symbols by length, by symbol order within each length */for(k=0;k<m;k++)0!==t[h+k]&&(_[D[t[h+k]]++]=k);/*
	   Create and fill in decoding tables.  In this loop, the table being
	   filled is at next and has curr index bits.  The code being used is huff
	   with length len.  That code is converted to an index by dropping drop
	   bits off of the bottom.  For codes where len is less than drop + curr,
	   those top drop + curr - len bits are incremented through all values to
	   fill the table with replicated entries.

	   root is the number of index bits for the root table.  When len exceeds
	   root, sub-tables are created pointed to by the root entry with an index
	   of the low root bits of huff.  This is saved in low to check for when a
	   new sub-table should be started.  drop is zero when the root table is
	   being filled, and drop is root when sub-tables are being filled.

	   When a new sub-table is needed, it is necessary to look ahead in the
	   code lengths to determine what size sub-table is needed.  The length
	   counts are used for this, and so count[] is decremented as codes are
	   entered in the tables.

	   used keeps track of how many table entries have been allocated from the
	   provided *table space.  It is checked for LENS and DIST tables against
	   the constants ENOUGH_LENS and ENOUGH_DISTS to guard against changes in
	   the initial root table size constants.  See the comments in inftrees.h
	   for more information.

	   sym increments through all symbols, and the loop terminates when
	   all codes of length max, i.e. all codes, have been processed.  This
	   routine permits incomplete codes, so another loop after this one fills
	   in the rest of the decoding tables with invalid code markers.
	   *//* set up for code type */// poor man optimization - use if-else instead of switch,
// to avoid deopts in old v8
/* mask for comparing low *//* check available table space */if(e===s?(T=R=_,M=19):e===o?(T=l,O-=257,R=p,B-=257,M=256):(T=c,R=u,M=-1),A=0,k=0,x=v,U=g,C=N,E=0,F=-1,I=1<<N,j=I-1,e===o&&I>a||e===d&&I>i)return 1;/* process all codes and make table entries */for(;;){W=x-E,_[k]<M?(H=0,Z=_[k]):_[k]>M?(H=R[B+_[k]],Z=T[O+_[k]]):(H=96,Z=0),P=1<<x-E,L=1<<C,v=L;/* save offset to next table */do L-=P,f[U+(A>>E)+L]=0|(W<<24|H<<16|Z);while(0!==L);/* backwards increment the len-bit code huff */for(P=1<<x-1;A&P;)P>>=1;if(0===P?A=0:(A&=P-1,A+=P),k++,0==--z[x]){if(x===w)break;x=t[h+_[k]]}/* create new sub-table if needed */if(x>N&&(A&j)!==F){for(0==E&&(E=N),U+=v,C=x-E,S=1<<C;C+E<w&&(S-=z[C+E],!(0>=S));)C++,S<<=1;/* check for enough space */if(I+=1<<C,e===o&&I>a||e===d&&I>i)return 1;/* point entry in root table to sub-table */F=A&j,f[F]=0|(N<<24|C<<16|U-g)}}/* fill in remaining table entry if code is incomplete (guaranteed to have
	   at most one remaining entry, since if the code is incomplete, the
	   maximum code length that was allowed to get this far is one bit) */return 0!=A&&(f[U+A]=0|(4194304|x-E<<24)),b.bits=N,0}},{"../utils/common":41}],51:[function(e,t){t.exports={2:'need dictionary',/* Z_NEED_DICT       2  */1:'stream end',/* Z_STREAM_END      1  */0:'',/* Z_OK              0  */"-1":'file error',/* Z_ERRNO         (-1) */"-2":'stream error',/* Z_STREAM_ERROR  (-2) */"-3":'data error',/* Z_DATA_ERROR    (-3) */"-4":'insufficient memory',/* Z_MEM_ERROR     (-4) */"-5":'buffer error',/* Z_BUF_ERROR     (-5) */"-6":'incompatible version'/* Z_VERSION_ERROR (-6) */}},{}],52:[function(e,t,n){/*============================================================================*/function r(e){for(var t=e.length;0<=--t;)e[t]=0}// From zutil.h
/* First normalized distance for each code (0 = distance of 1) */function a(e,t,n,r,a){this.static_tree=e,this.extra_bits=t,this.extra_base=n,this.elems=r,this.max_length=a,this.has_stree=e&&e.length}function i(e,t){this.dyn_tree=e,this.max_code=0,this.stat_desc=t}function o(e){return 256>e?Q[e]:Q[256+(e>>>7)]}/* ===========================================================================
	 * Output a short LSB first on the stream.
	 * IN assertion: there is enough room in pendingBuf.
	 */function d(e,t){e.pending_buf[e.pending++]=255&t,e.pending_buf[e.pending++]=255&t>>>8}/* ===========================================================================
	 * Send a value on a given number of bits.
	 * IN assertion: length <= 16 and value fits in length bits.
	 */function l(e,t,n){e.bi_valid>M-n?(e.bi_buf|=65535&t<<e.bi_valid,d(e,e.bi_buf),e.bi_buf=t>>M-e.bi_valid,e.bi_valid+=n-M):(e.bi_buf|=65535&t<<e.bi_valid,e.bi_valid+=n)}function p(e,t,n){l(e,n[2*t]/*.Code*/,n[2*t+1]/*.Len*/)}/* ===========================================================================
	 * Reverse the first len bits of a code, using straightforward code (a faster
	 * method would use a table)
	 * IN assertion: 1 <= len <= 15
	 */function s(e,t){var n=0;do n|=1&e,e>>>=1,n<<=1;while(0<--t);return n>>>1}/* ===========================================================================
	 * Flush the bit buffer, keeping at most 7 bits in it.
	 */function c(e){16===e.bi_valid?(d(e,e.bi_buf),e.bi_buf=0,e.bi_valid=0):8<=e.bi_valid&&(e.pending_buf[e.pending++]=255&e.bi_buf,e.bi_buf>>=8,e.bi_valid-=8)}/* ===========================================================================
	 * Compute the optimal bit lengths for a tree and update the total bit length
	 * for the current block.
	 * IN assertion: the fields freq and dad are set, heap[heap_max] and
	 *    above are the tree nodes sorted by increasing frequency.
	 * OUT assertions: the field len is set to the optimal bit length, the
	 *     array bl_count contains the frequencies for each bit length.
	 *     The length opt_len is updated; static_len is also updated if stree is
	 *     not null.
	 */function u(e,t)//    deflate_state *s;
//    tree_desc *desc;    /* the tree descriptor */
{var r=t.dyn_tree,a=t.max_code,i=t.stat_desc.static_tree,s=t.stat_desc.has_stree,o=t.stat_desc.extra_bits,d=t.stat_desc.extra_base,l=t.stat_desc.max_length,p=0,c,u,n,h,m,g;/* heap index *//* iterate over the tree elements *//* bit length *//* extra bits *//* frequency *//* number of elements with bit length too large */for(h=0;h<=U;h++)e.bl_count[h]=0;/* In a first pass, compute the optimal bit lengths (which may
	   * overflow in the case of the bit length tree).
	   *//* root of the heap */for(r[2*e.heap[e.heap_max]+1]/*.Len*/=0,c=e.heap_max+1;c<j;c++)/* We overwrite tree[n].Dad which is no longer needed */(u=e.heap[c],h=r[/*.Dad*/2*r[2*u+1]+1]/*.Len*/+1,h>l&&(h=l,p++),r[2*u+1]/*.Len*/=h,!(u>a))&&(e.bl_count[h]++,m=0,u>=d&&(m=o[u-d]),g=r[2*u]/*.Freq*/,e.opt_len+=g*(h+m),s&&(e.static_len+=g*(i[2*u+1]/*.Len*/+m)));/* not a leaf node */if(0!=p){// Trace((stderr,"\nbit length overflow\n"));
/* This happens for example on obj2 and pic of the Calgary corpus *//* Find the first bit length which could increase: */do{for(h=l-1;0===e.bl_count[h];)h--;e.bl_count[h]--,e.bl_count[h+1]+=2,e.bl_count[l]--,p-=2}while(0<p);/* Now recompute all bit lengths, scanning in increasing frequency.
	   * h is still equal to HEAP_SIZE. (It is simpler to reconstruct all
	   * lengths instead of fixing only the wrong ones. This idea is taken
	   * from 'ar' written by Haruhiko Okumura.)
	   */for(h=l;0!==h;h--)for(u=e.bl_count[h];0!==u;)(n=e.heap[--c],!(n>a))&&(r[2*n+1]/*.Len*/!==h&&(e.opt_len+=(h-r[2*n+1]/*.Len*/)*r[2*n]/*.Freq*/,r[2*n+1]/*.Len*/=h),u--)}}/* ===========================================================================
	 * Generate the codes for a given tree and bit counts (which need not be
	 * optimal).
	 * IN assertion: the array bl_count contains the bit length statistics for
	 * the given tree and the field len is set for all tree elements.
	 * OUT assertion: the field code is set for all tree elements of non
	 *     zero code length.
	 */function h(e,t,r)//    ct_data *tree;             /* the tree to decorate */
//    int max_code;              /* largest code with non zero frequency */
//    ushf *bl_count;            /* number of codes at each bit length */
{var a=Array(U+1),i=0,o,d;/* next code value for each bit length *//* running code value *//* bit index *//* code index *//* The distribution counts are first used to generate the code values
	   * without bit reversal.
	   */for(o=1;o<=U;o++)a[o]=i=i+r[o-1]<<1;/* Check that the bit counts in bl_count are consistent. The last code
	   * must be all ones.
	   *///Assert (code + bl_count[MAX_BITS]-1 == (1<<MAX_BITS)-1,
//        "inconsistent bit counts");
//Tracev((stderr,"\ngen_codes: max_code %d ", max_code));
for(d=0;d<=t;d++){var n=e[2*d+1]/*.Len*/;0!==n&&(e[2*d]/*.Code*/=s(a[n]++,n));/* Now reverse the bits */}}/* ===========================================================================
	 * Initialize the various 'constant' tables.
	 */function m(){var e=Array(U+1),t,n,r,i,o;/* iterates over tree elements *//* bit counter *//* length value *//* code value *//* distance index *//* number of codes at each bit length for an optimal tree */// do check in _tr_init()
//if (static_init_done) return;
/* For some embedded targets, global variables are not initialized: *//*#ifdef NO_INIT_GLOBAL_POINTERS
	  static_l_desc.static_tree = static_ltree;
	  static_l_desc.extra_bits = extra_lbits;
	  static_d_desc.static_tree = static_dtree;
	  static_d_desc.extra_bits = extra_dbits;
	  static_bl_desc.extra_bits = extra_blbits;
	#endif*//* Initialize the mapping length (0..255) -> length code (0..28) */for(r=0,i=0;i<R-1;i++)for(te[i]=r,t=0;t<1<<G[i];t++)ee[r++]=i;//Assert (length == 256, "tr_static_init: length != 256");
/* Note that the length 255 (match length 258) can be represented
	   * in two different ways: code 284 + 5 bits or code 285, so we
	   * overwrite length_code[255] to use the best encoding:
	   */for(ee[r-1]=i,o=0,i=0;16>i;i++)for(ne[i]=o,t=0;t<1<<X[i];t++)Q[o++]=i;//Assert (dist == 256, "tr_static_init: dist != 256");
/* from now on, all distances are divided by 128 */for(o>>=7;i<L;i++)for(ne[i]=o<<7,t=0;t<1<<X[i]-7;t++)Q[256+o++]=i;//Assert (dist == 256, "tr_static_init: 256+dist != 512");
/* Construct the codes of the static literal tree */for(n=0;n<=U;n++)e[n]=0;for(t=0;143>=t;)$[2*t+1]/*.Len*/=8,t++,e[8]++;for(;255>=t;)$[2*t+1]/*.Len*/=9,t++,e[9]++;for(;279>=t;)$[2*t+1]/*.Len*/=7,t++,e[7]++;for(;287>=t;)$[2*t+1]/*.Len*/=8,t++,e[8]++;/* Codes 286 and 287 do not exist, but we must include them in the
	   * tree construction to get a canonical Huffman tree (longest code
	   * all ones)
	   *//* The static distance tree is trivial: */for(h($,P+1,e),t=0;t<L;t++)J[2*t+1]/*.Len*/=5,J[2*t]/*.Code*/=s(t,5);// Now data ready and we can init static trees
ae=new a($,G,B+1,P,U),ie=new a(J,X,0,L,U),se=new a([],V,0,F,W)}/* ===========================================================================
	 * Initialize a new block.
	 */function f(e){var t;/* iterates over tree elements *//* Initialize the trees. */for(t=0;t<P;t++)e.dyn_ltree[2*t]/*.Freq*/=0;for(t=0;t<L;t++)e.dyn_dtree[2*t]/*.Freq*/=0;for(t=0;t<F;t++)e.bl_tree[2*t]/*.Freq*/=0;e.dyn_ltree[2*H]/*.Freq*/=1,e.opt_len=e.static_len=0,e.last_lit=e.matches=0}/* ===========================================================================
	 * Flush the bit buffer and align the output on a byte boundary
	 */function g(e){8<e.bi_valid?d(e,e.bi_buf):0<e.bi_valid&&(e.pending_buf[e.pending++]=e.bi_buf),e.bi_buf=0,e.bi_valid=0}/* ===========================================================================
	 * Copy a stored block, storing first the length and its
	 * one's complement if requested.
	 */function _(e,t,n,r)//DeflateState *s;
//charf    *buf;    /* the input data */
//unsigned len;     /* its length */
//int      header;  /* true if block header must be written */
{g(e),r&&(d(e,n),d(e,~n)),A.arraySet(e.pending_buf,e.window,t,n,e.pending),e.pending+=n}/* ===========================================================================
	 * Compares to subtrees, using the tree depth as tie breaker when
	 * the subtrees have equal frequency. This minimizes the worst case length.
	 */function b(e,t,n,r){var a=2*t,i=2*n;return e[a]/*.Freq*/<e[i]/*.Freq*/||e[a]/*.Freq*/===e[i]/*.Freq*/&&r[t]<=r[n]}/* ===========================================================================
	 * Restore the heap property by moving down the tree starting at node k,
	 * exchanging a node with the smallest of its two sons if necessary, stopping
	 * when the heap property is re-established (each father smaller than its
	 * two sons).
	 */function y(e,t,n)//    deflate_state *s;
//    ct_data *tree;  /* the tree to restore */
//    int k;               /* node to move down */
{/* left son of k */for(var r=e.heap[n],a=n<<1;a<=e.heap_len&&(a<e.heap_len&&b(t,e.heap[a+1],e.heap[a],e.depth)&&a++,!b(t,r,e.heap[a],e.depth));)e.heap[n]=e.heap[a],n=a,a<<=1;e.heap[n]=r}// inlined manually
// var SMALLEST = 1;
/* ===========================================================================
	 * Send the block data compressed using the given Huffman trees
	 */function x(e,t,n)//    deflate_state *s;
//    const ct_data *ltree; /* literal tree */
//    const ct_data *dtree; /* distance tree */
{var r=0,a,i,s,d;/* distance of matched string *//* match length or unmatched char (if dist == 0) *//* running index in l_buf *//* the code to send *//* number of extra bits to send */if(0!==e.last_lit)do a=e.pending_buf[e.d_buf+2*r]<<8|e.pending_buf[e.d_buf+2*r+1],i=e.pending_buf[e.l_buf+r],r++,0===a?p(e,i,t):(s=ee[i],p(e,s+B+1,t),d=G[s],0!==d&&(i-=te[s],l(e,i,d)),a--,s=o(a),p(e,s,n),d=X[s],0!==d&&(a-=ne[s],l(e,a,d)));while(r<e.last_lit);p(e,H,t)}/* ===========================================================================
	 * Construct one Huffman tree and assigns the code bit strings and lengths.
	 * Update the total bit length for the current block.
	 * IN assertion: the field freq is set for all tree elements.
	 * OUT assertions: the fields len and code are set to the optimal bit length
	 *     and corresponding code. The length opt_len is updated; static_len is
	 *     also updated if stree is not null. The field max_code is set.
	 */function k(e,t)//    deflate_state *s;
//    tree_desc *desc; /* the tree descriptor */
{var r=t.dyn_tree,a=t.stat_desc.static_tree,i=t.stat_desc.has_stree,s=t.stat_desc.elems,o=-1,d,n,l;/* iterate over heap elements *//* largest code with non zero frequency *//* new node being created *//* Construct the initial heap, with least frequent element in
	   * heap[SMALLEST]. The sons of heap[n] are heap[2*n] and heap[2*n+1].
	   * heap[0] is not used.
	   */for(e.heap_len=0,e.heap_max=j,d=0;d<s;d++)/*.Freq*/0===r[2*d]?r[2*d+1]/*.Len*/=0:(e.heap[++e.heap_len]=o=d,e.depth[d]=0);/* The pkzip format requires that at least one distance code exists,
	   * and that at least one bit should be sent even if there is only one
	   * possible code. So to avoid special checks later on we force at least
	   * two codes of non zero frequency.
	   */for(;2>e.heap_len;)l=e.heap[++e.heap_len]=2>o?++o:0,r[2*l]/*.Freq*/=1,e.depth[l]=0,e.opt_len--,i&&(e.static_len-=a[2*l+1]/*.Len*/);/* The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree,
	   * establish sub-heaps of increasing lengths:
	   */for(t.max_code=o,d=e.heap_len>>1/*int /2*/;1<=d;d--)y(e,r,d);/* Construct the Huffman tree by repeatedly combining the least two
	   * frequent nodes.
	   */l=s;/* next internal node of the tree */do d=e.heap[1/*SMALLEST*/],e.heap[1/*SMALLEST*/]=e.heap[e.heap_len--],y(e,r,1/*SMALLEST*/),n=e.heap[1/*SMALLEST*/],e.heap[--e.heap_max]=d,e.heap[--e.heap_max]=n,r[2*l]/*.Freq*/=r[2*d]/*.Freq*/+r[2*n]/*.Freq*/,e.depth[l]=(e.depth[d]>=e.depth[n]?e.depth[d]:e.depth[n])+1,r[2*d+1]/*.Dad*/=r[2*n+1]/*.Dad*/=l,e.heap[1/*SMALLEST*/]=l++,y(e,r,1/*SMALLEST*/);while(2<=e.heap_len);e.heap[--e.heap_max]=e.heap[1/*SMALLEST*/],u(e,t),h(r,o,e.bl_count)}/* ===========================================================================
	 * Scan a literal or distance tree to determine the frequencies of the codes
	 * in the bit length tree.
	 */function v(e,t,r)//    deflate_state *s;
//    ct_data *tree;   /* the tree to be scanned */
//    int max_code;    /* and its largest code of non zero frequency */
{var a=-1,i=t[1]/*.Len*/,s=0,o=7,d=4,l,n;/* iterates over all tree elements *//* last emitted length *//* length of current code *//* length of next code *//* repeat count of the current code *//* max repeat count *//* min repeat count *//* guard */for(0===i&&(o=138,d=3),t[2*(r+1)+1]/*.Len*/=65535,l=0;l<=r;l++){if(n=i,i=t[2*(l+1)+1]/*.Len*/,++s<o&&n===i)continue;else s<d?e.bl_tree[2*n]/*.Freq*/+=s:0===n?10>=s?e.bl_tree[2*q]/*.Freq*/++:e.bl_tree[2*Y]/*.Freq*/++:(n!==a&&e.bl_tree[2*n]/*.Freq*/++,e.bl_tree[2*Z]/*.Freq*/++);s=0,a=n,0===i?(o=138,d=3):n===i?(o=6,d=3):(o=7,d=4)}}/* ===========================================================================
	 * Send a literal or distance tree in compressed form, using the codes in
	 * bl_tree.
	 */function w(e,t,r)//    deflate_state *s;
//    ct_data *tree; /* the tree to be scanned */
//    int max_code;       /* and its largest code of non zero frequency */
{var a=-1,i=t[1]/*.Len*/,s=0,o=7,d=4,c,n;/* iterates over all tree elements *//* last emitted length *//* length of current code *//* length of next code *//* repeat count of the current code *//* max repeat count *//* min repeat count *//* tree[max_code+1].Len = -1; *//* guard already set */for(0===i&&(o=138,d=3),c=0;c<=r;c++){if(n=i,i=t[2*(c+1)+1]/*.Len*/,++s<o&&n===i)continue;else if(s<d)do p(e,n,e.bl_tree);while(0!=--s);else 0===n?10>=s?(p(e,q,e.bl_tree),l(e,s-3,3)):(p(e,Y,e.bl_tree),l(e,s-11,7)):(n!==a&&(p(e,n,e.bl_tree),s--),p(e,Z,e.bl_tree),l(e,s-3,2));s=0,a=n,0===i?(o=138,d=3):n===i?(o=6,d=3):(o=7,d=4)}}/* ===========================================================================
	 * Construct the Huffman tree for the bit lengths and return the index in
	 * bl_order of the last bit length code to send.
	 */function N(e){var t;/* index of last bit length code of non zero freq *//* Determine the bit length frequencies for literal and distance trees *//* opt_len now includes the length of the tree representations, except
	   * the lengths of the bit lengths codes and the 5+5+4 bits for the counts.
	   *//* Determine the number of bit length codes to send. The pkzip format
	   * requires that at least 4 bit length codes be sent. (appnote.txt says
	   * 3 but the actual value used is 4.)
	   */for(v(e,e.dyn_ltree,e.l_desc.max_code),v(e,e.dyn_dtree,e.d_desc.max_code),k(e,e.bl_desc),t=F-1;3<=t&&/*.Len*/0===e.bl_tree[2*K[t]+1];t--);/* Update opt_len to include the bit length tree and counts *///Tracev((stderr, "\ndyn trees: dyn %ld, stat %ld",
//        s->opt_len, s->static_len));
return e.opt_len+=3*(t+1)+5+5+4,t}/* ===========================================================================
	 * Send the header for a block using dynamic Huffman trees: the counts, the
	 * lengths of the bit length codes, the literal tree and the distance tree.
	 * IN assertion: lcodes >= 257, dcodes >= 1, blcodes >= 4.
	 */function C(e,t,n,r)//    deflate_state *s;
//    int lcodes, dcodes, blcodes; /* number of codes for each tree */
{var a;/* index in bl_order *///Assert (lcodes >= 257 && dcodes >= 1 && blcodes >= 4, "not enough codes");
//Assert (lcodes <= L_CODES && dcodes <= D_CODES && blcodes <= BL_CODES,
//        "too many codes");
//Tracev((stderr, "\nbl counts: "));
/* not -3 as stated in appnote.txt */for(l(e,t-257,5),l(e,n-1,5),l(e,r-4,4),a=0;a<r;a++)//Tracev((stderr, "\nbl code %2d ", bl_order[rank]));
l(e,e.bl_tree[2*K[a]+1]/*.Len*/,3);//Tracev((stderr, "\nbl tree: sent %ld", s->bits_sent));
w(e,e.dyn_ltree,t-1),w(e,e.dyn_dtree,n-1)}/* ===========================================================================
	 * Check if the data type is TEXT or BINARY, using the following algorithm:
	 * - TEXT if the two conditions below are satisfied:
	 *    a) There are no non-portable control characters belonging to the
	 *       "black list" (0..6, 14..25, 28..31).
	 *    b) There is at least one printable character belonging to the
	 *       "white list" (9 {TAB}, 10 {LF}, 13 {CR}, 32..255).
	 * - BINARY otherwise.
	 * - The following partially-portable control characters form a
	 *   "gray list" that is ignored in this detection algorithm:
	 *   (7 {BEL}, 8 {BS}, 11 {VT}, 12 {FF}, 26 {SUB}, 27 {ESC}).
	 * IN assertion: the fields Freq of dyn_ltree are set.
	 */function E(e){/* black_mask is the bit mask of black-listed bytes
	   * set bits 0..6, 14..25, and 28..31
	   * 0xf3ffc07f = binary 11110011111111111100000001111111
	   */var t=4093624447,r;/* Check for non-textual ("black-listed") bytes. */for(r=0;31>=r;r++,t>>>=1)if(1&t&&/*.Freq*/0!==e.dyn_ltree[2*r])return T;/* Check for textual ("white-listed") bytes. */if(/*.Freq*/0!==e.dyn_ltree[18]||/*.Freq*/0!==e.dyn_ltree[20]||/*.Freq*/0!==e.dyn_ltree[26])return O;for(r=32;r<B;r++)if(/*.Freq*/0!==e.dyn_ltree[2*r])return O;/* There are no "black-listed" or "white-listed" bytes:
	   * this stream either is empty or has tolerated ("gray-listed") bytes only.
	   */return T}/* ===========================================================================
	 * Initialize the tree data structures for a new zlib stream.
	 */function S(e){re||(m(),re=!0),e.l_desc=new i(e.dyn_ltree,ae),e.d_desc=new i(e.dyn_dtree,ie),e.bl_desc=new i(e.bl_tree,se),e.bi_buf=0,e.bi_valid=0,f(e)}/* ===========================================================================
	 * Send a stored block
	 */function I(e,t,n,r)//DeflateState *s;
//charf *buf;       /* input block */
//ulg stored_len;   /* length of input block */
//int last;         /* one if this is the last block for a file */
{l(e,(z<<1)+(r?1:0),3),_(e,t,n,!0)}/* ===========================================================================
	 * Send one empty static block to give enough lookahead for inflate.
	 * This takes 10 bits, of which 7 may remain in the bit buffer.
	 *//* ===========================================================================
	 * Determine the best encoding for the current block: dynamic trees, static
	 * trees or store, and output the encoded block to the zip file.
	 *//* ===========================================================================
	 * Save the match info and tally the frequency counts. Return true if
	 * the current block must be flushed.
	 */// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.
var A=e('../utils/common'),T=0,O=1,z=0,D=1,R=29,B=256,P=B+1+R,L=30,F=19,j=2*P+1,U=15,M=16,W=7,H=256,Z=16,q=17,Y=18,G=/* extra bits for each length code */[0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0],X=/* extra bits for each distance code */[0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13],V=/* extra bits for each bit length code */[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,7],K=[16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15],$=Array(2*(P+2));/* Public constants ==========================================================*//* ===========================================================================*///var Z_FILTERED          = 1;
//var Z_HUFFMAN_ONLY      = 2;
//var Z_RLE               = 3;
//var Z_DEFAULT_STRATEGY  = 0;
/* Possible values of the data_type field (though see inflate()) *///var Z_ASCII             = 1; // = Z_TEXT
/* The three kinds of block type *//* The minimum and maximum match lengths */// From deflate.h
/* ===========================================================================
	 * Internal compression state.
	 *//* number of length codes, not counting the special END_BLOCK code *//* number of literal bytes 0..255 *//* number of Literal or Length codes, including the END_BLOCK code *//* number of distance codes *//* number of codes used to transfer the bit lengths *//* maximum heap size *//* All codes must not exceed MAX_BITS bits *//* size of bit buffer in bi_buf *//* ===========================================================================
	 * Constants
	 *//* Bit length codes must not exceed MAX_BL_BITS bits *//* end of block literal code *//* repeat previous bit length 3-6 times (2 bits of repeat count) *//* repeat a zero length 3-10 times  (3 bits of repeat count) *//* repeat a zero length 11-138 times  (7 bits of repeat count) *//* eslint-disable comma-spacing,array-bracket-spacing *//* eslint-enable comma-spacing,array-bracket-spacing *//* The lengths of the bit length codes are sent in order of decreasing
	 * probability, to avoid transmitting the lengths for unused bit length codes.
	 *//* ===========================================================================
	 * Local data. These are initialized only once.
	 */// We pre-fill arrays with 0 to avoid uninitialized gaps
/* see definition of array dist_code below */// !!!! Use flat array insdead of structure, Freq = i*2, Len = i*2+1
r($);/* The static literal tree. Since the bit lengths are imposed, there is no
	 * need for the L_CODES extra codes used during heap construction. However
	 * The codes 286 and 287 are needed to build a canonical tree (see _tr_init
	 * below).
	 */var J=Array(2*L);r(J);/* The static distance tree. (Actually a trivial tree since all codes use
	 * 5 bits.)
	 */var Q=Array(512);r(Q);/* Distance codes. The first 256 values correspond to the distances
	 * 3 .. 258, the last 256 values correspond to the top 8 bits of
	 * the 15 bit distances.
	 */var ee=Array(258-3+1);r(ee);/* length code for each normalized match length (0 == MIN_MATCH) */var te=Array(R);r(te);/* First normalized length for each code (0 = MIN_MATCH) */var ne=Array(L);r(ne);var re=!1,ae,ie,se;n._tr_init=S,n._tr_stored_block=I,n._tr_flush_block=function(e,t,n,r)//DeflateState *s;
//charf *buf;       /* input block, or NULL if too old */
//ulg stored_len;   /* length of input block */
//int last;         /* one if this is the last block for a file */
{var a=0,i,s;/* opt_len and static_len in bytes *//* index of last bit length code of non zero freq *//* Build the Huffman trees unless a stored block is forced */0<e.level?(e.strm.data_type===2&&(e.strm.data_type=E(e)),k(e,e.l_desc),k(e,e.d_desc),a=N(e),i=e.opt_len+3+7>>>3,s=e.static_len+3+7>>>3,s<=i&&(i=s)):i=s=n+5,n+4<=i&&-1!==t?I(e,t,n,r):e.strategy===4||s===i?(l(e,(D<<1)+(r?1:0),3),x(e,$,J)):(l(e,(2<<1)+(r?1:0),3),C(e,e.l_desc.max_code+1,e.d_desc.max_code+1,a+1),x(e,e.dyn_ltree,e.dyn_dtree)),f(e),r&&g(e)},n._tr_tally=function(e,t,n)//    deflate_state *s;
//    unsigned dist;  /* distance of matched string */
//    unsigned lc;    /* match length-MIN_MATCH or unmatched char (if dist==0) */
{// (!) This block is disabled in zlib defailts,
// don't enable it for binary compatibility
//#ifdef TRUNCATE_BLOCK
//  /* Try to guess if it is profitable to stop the current block here */
//  if ((s.last_lit & 0x1fff) === 0 && s.level > 2) {
//    /* Compute an upper bound for the compressed length */
//    out_length = s.last_lit*8;
//    in_length = s.strstart - s.block_start;
//
//    for (dcode = 0; dcode < D_CODES; dcode++) {
//      out_length += s.dyn_dtree[dcode*2]/*.Freq*/ * (5 + extra_dbits[dcode]);
//    }
//    out_length >>>= 3;
//    //Tracev((stderr,"\nlast_lit %u, in %ld, out ~%ld(%ld%%) ",
//    //       s->last_lit, in_length, out_length,
//    //       100L - out_length*100L/in_length));
//    if (s.matches < (s.last_lit>>1)/*int /2*/ && out_length < (in_length>>1)/*int /2*/) {
//      return true;
//    }
//  }
//#endif
return e.pending_buf[e.d_buf+2*e.last_lit]=255&t>>>8,e.pending_buf[e.d_buf+2*e.last_lit+1]=255&t,e.pending_buf[e.l_buf+e.last_lit]=255&n,e.last_lit++,0===t?e.dyn_ltree[2*n]/*.Freq*/++:(e.matches++,t--,e.dyn_ltree[2*(ee[n]+B+1)]/*.Freq*/++,e.dyn_dtree[2*o(t)]/*.Freq*/++),e.last_lit===e.lit_bufsize-1;/* We avoid equality with lit_bufsize because of wraparound at 64K
	   * on 16 bit machines and because stored blocks are restricted to
	   * 64K-1 bytes.
	   */},n._tr_align=function(e){l(e,D<<1,3),p(e,H,$),c(e)}},{"../utils/common":41}],53:[function(e,t){t.exports=// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.
function(){this.input=null,this.next_in=0,this.avail_in=0,this.total_in=0,this.output=null,this.next_out=0,this.avail_out=0,this.total_out=0,this.msg=''/*Z_NULL*/,this.state=null,this.data_type=2/*Z_UNKNOWN*/,this.adler=0}},{}],54:[function(e,t){t.exports='function'==typeof setImmediate?setImmediate:function(){var e=[].slice.apply(arguments);e.splice(1,0,0),setTimeout.apply(null,e)}},{}]},{},[10])(10)})});/**
	 * Handles Unzipping a requesting files from an Epub Archive
	 * @class
	 */class jn{constructor(){this.zip=void 0,this.urlCache={},this.checkRequirements()}/**
	  * Checks to see if JSZip exists in global namspace,
	  * Requires JSZip if it isn't there
	  * @private
	  */checkRequirements(){try{this.zip=new Fn}catch(t){throw new Error('JSZip lib not loaded')}}/**
	  * Open an archive
	  * @param  {binary} input
	  * @param  {boolean} isBase64 tells JSZip if the input data is base64 encoded
	  * @return {Promise} zipfile
	  */open(e,t){return this.zip.loadAsync(e,{base64:t})}/**
	  * Load and Open an archive
	  * @param  {string} zipUrl
	  * @param  {boolean} isBase64 tells JSZip if the input data is base64 encoded
	  * @return {Promise} zipfile
	  */openUrl(e,t){return Re(e,'binary').then(function(e){return this.zip.loadAsync(e,{base64:t})}.bind(this))}/**
	  * Request a url from the archive
	  * @param  {string} url  a url to request from the archive
	  * @param  {string} [type] specify the type of the returned result
	  * @return {Promise}
	  */request(e,t){var n=new ve,r=new fn(e),a;// If type isn't set, determine it from the file extension
return t||(t=r.extension),a='blob'==t?this.getBlob(e):this.getText(e),a?a.then(function(e){let r=this.handleResponse(e,t);n.resolve(r)}.bind(this)):n.reject({message:'File not found in the epub: '+e,stack:new Error().stack}),n.promise}/**
	  * Handle the response from request
	  * @private
	  * @param  {any} response
	  * @param  {string} [type]
	  * @return {any} the parsed result
	  */handleResponse(e,t){var n;return n='json'==t?JSON.parse(e):de(t)?me(e,'text/xml'):'xhtml'==t?me(e,'application/xhtml+xml'):'html'==t||'htm'==t?me(e,'text/html'):e,n}/**
	  * Get a Blob from Archive by Url
	  * @param  {string} url
	  * @param  {string} [mimeType]
	  * @return {Blob}
	  */getBlob(e,t){var n=decodeURIComponent(e.substr(1)),r=this.zip.file(n);// Remove first slash
if(r)return t=t||Bn.lookup(r.name),r.async('uint8array').then(function(e){return new Blob([e],{type:t})})}/**
	  * Get Text from Archive by Url
	  * @param  {string} url
	  * @param  {string} [encoding]
	  * @return {string}
	  */getText(e){var t=decodeURIComponent(e.substr(1)),n=this.zip.file(t);// Remove first slash
if(n)return n.async('string').then(function(e){return e})}/**
	  * Get a base64 encoded result from Archive by Url
	  * @param  {string} url
	  * @param  {string} [mimeType]
	  * @return {string} base64 encoded
	  */getBase64(e,t){var n=decodeURIComponent(e.substr(1)),r=this.zip.file(n);// Remove first slash
if(r)return t=t||Bn.lookup(r.name),r.async('base64').then(function(e){return'data:'+t+';base64,'+e})}/**
	  * Create a Url from an unarchived item
	  * @param  {string} url
	  * @param  {object} [options.base64] use base64 encoding or blob url
	  * @return {Promise} url promise with Url string
	  */createUrl(e,t){var n=new ve,r=t&&t.base64,a,i;//var _URL = window.URL || window.webkitURL || window.mozURL;
return e in this.urlCache?(n.resolve(this.urlCache[e]),n.promise):(r?(i=this.getBase64(e),i&&i.then(function(t){this.urlCache[e]=t,n.resolve(t)}.bind(this))):(i=this.getBlob(e),i&&i.then(function(t){a=URL.createObjectURL(t),this.urlCache[e]=a,n.resolve(a)}.bind(this))),i||n.reject({message:'File not found in the epub: '+e,stack:new Error().stack}),n.promise)}/**
	  * Revoke Temp Url for a achive item
	  * @param  {string} url url of the item in the archive
	  */revokeUrl(e){//var _URL = _URL || window.webkitURL || window.mozURL;
var t=this.urlCache[e];t&&URL.revokeObjectURL(t)}destroy(){// var _URL = window.URL || window.webkitURL || window.mozURL;
for(let e in this.urlCache)URL.revokeObjectURL(e);this.zip=void 0,this.urlCache={}}}const Un='META-INF/container.xml',Mn={BINARY:'binary',BASE64:'base64',EPUB:'epub',OPF:'opf',MANIFEST:'json',DIRECTORY:'directory'};/**
	 * An Epub representation with methods for the parsing of its contents.
	 * @class
	 * @param {string} [url]
	 * @param {object} [options]
	 * @param {method} [options.requestMethod] a request function to use instead of the default
	 * @param {boolean} [options.requestCredentials=undefined] send the xhr request withCredentials
	 * @param {object} [options.requestHeaders=undefined] send the xhr request headers
	 * @param {string} [options.encoding=binary] optional to pass 'binary' or base64' for archived Epubs
	 * @param {string} [options.replacements] use base64, blobUrl, or none for replacing assets in archived Epubs
	 * @param {method} [options.cache] use cache to save book contents for a service workers
	 * @returns {Epub}
	 * @example new Epub("/path/to/book.epub", {})
	 * @example new Epub({ replacements: "blobUrl" })
	 */class Wn{constructor(e,t){'undefined'==typeof t&&'object'==typeof e&&(t=e,e=void 0),this.settings=re(this.settings||{},{requestMethod:void 0,requestCredentials:void 0,requestHeaders:void 0,encoding:void 0,replacements:void 0,cache:void 0,stylesheet:null,script:null}),re(this.settings,t),this.opening=new ve,this.opened=this.opening.promise,this.isOpen=!1,this.book=void 0,this.ready=this.opened.then(()=>(this.manifest=this.book.toJSON(),this.emit(Cn.BOOK.READY,this.manifest),this.book)),this.request=this.settings.requestMethod||Re,this.archived=!1,this.container=void 0,this.packaging=void 0,this.locations=void 0,this.pageList=void 0,e&&this.open(e).catch((t)=>{var n=new Error('Cannot load book at '+e);this.emit(Cn.BOOK.OPEN_FAILED,n),console.error(t)})}/**
	  * Open a epub or url
	  * @param {string | ArrayBuffer} input Url, Path or ArrayBuffer
	  * @param {string} [what="binary", "base64", "epub", "opf", "json", "directory"] force opening as a certain type
	  * @returns {Promise} of when the book has been loaded
	  * @example book.open("/path/to/book.epub")
	  */open(e,t){let n=t||this.determineType(e),r,a;// For browsers
return'undefined'!=typeof window&&(a=window.location.href),'undefined'!=typeof self&&(a=self.location.href),n===Mn.BINARY?(this.archived=!0,this.url=new gn('/',''),this.locationUrl=new gn(a),r=this.openEpub(e)):n===Mn.BASE64?(this.archived=!0,this.url=new gn('/',''),this.locationUrl=new gn(a),r=this.openEpub(e,n)):n===Mn.EPUB?(this.archived=!0,this.url=new gn('/',''),this.locationUrl=new gn(e,a),r=this.request(e,'binary').then(this.openEpub.bind(this))):n==Mn.OPF?(this.url=new gn(e),this.locationUrl=new gn(e),r=this.openPackaging(this.url.Path.toString())):n==Mn.MANIFEST?(this.url=new gn(e),this.locationUrl=new gn(e),r=this.openManifest(this.url.Path.toString())):(this.url=new gn(e),this.locationUrl=new gn(e),r=this.openContainer(Un).then(this.openPackaging.bind(this))),r.then((e)=>this.unpack(e))}/**
	  * Open an archived epub
	  * @private
	  * @param  {binary} data
	  * @param  {string} [encoding]
	  * @return {Promise}
	  */openEpub(e,t){return this.unarchive(e,t||this.settings.encoding).then(()=>this.openContainer(Un)).then((e)=>this.openPackaging(e))}/**
	  * Open the epub container
	  * @private
	  * @param  {string} url
	  * @return {string} packagePath
	  */openContainer(e){return this.load(e).then((e)=>(this.container=new Tn(e),this.resolve(this.container.packagePath)))}/**
	  * Open the Open Packaging Format Xml
	  * @private
	  * @param  {string} url
	  * @return {Promise}
	  */openPackaging(e){return this.path=new fn(e),this.load(e).then((e)=>(this.packaging=new On(e),this.packaging))}/**
	  * Open the manifest JSON
	  * @private
	  * @param  {string} url
	  * @return {Promise}
	  */openManifest(e){return this.path=new fn(e),this.load(e).then((e)=>(this.packaging=new On,this.packaging.load(e),this.packaging))}/**
	  * Load a resource from the Book
	  * @private
	  * @param  {string} path path to the resource to load
	  * @return {Promise}     returns a promise with the requested resource
	  */load(e,t){var n;return this.archived?(n=this.resolve(e),this.archive.request(n,t)):(n=this.resolve(e),this.request(n,t,this.settings.requestCredentials,this.settings.requestHeaders))}/**
	  * Resolve a path to it's absolute position in the Book
	  * @private
	  * @param  {string} path
	  * @param  {boolean} [absolute] force resolving the full URL
	  * @return {string}          the resolved path string
	  */resolve(e,t){if(!e)return;let n=e,r=-1<e.indexOf('://');return r?e:(this.path&&(n=this.path.resolve(e)),!1!=t&&this.url&&(n=this.url.resolve(n)),n)}/**
	  * Determine the type of they input passed to open
	  * @private
	  * @param  {string} input
	  * @return {string}  binary | directory | epub | opf
	  */determineType(e){var t,n,r;return'base64'===this.settings.encoding?Mn.BASE64:'string'==typeof e?(t=new gn(e),n=t.path(),r=n.extension,r?'epub'===r?Mn.EPUB:'opf'===r?Mn.OPF:'json'===r?Mn.MANIFEST:void 0:Mn.DIRECTORY):Mn.BINARY}/**
	  * unpack the contents of the Packaging
	  * @private
	  * @param {document} packageXml XML Document
	  */unpack(e){this.package=e;let t=this.path.toString(),n;n=this.archived?new gn(t,''):this.url?this.url.resolve(t):new gn(t),this.resources=new Pn(this.package.manifest,{archive:this.archive,url:n,load:this.load.bind(this),replacements:this.settings.replacements,inject:{script:this.settings.script,stylesheet:this.settings.stylesheet,identifer:this.package.metadata.identifier}});let r=[],a=n.origin!==location.origin;// If caches doesn't exist, use replacements instead
if('undefined'==typeof caches&&(this.settings.replacements=!0,this.settings.cache=!1),'undefined'==typeof this.settings.cache&&this.settings.worker&&(this.settings.cache=!0),(a||this.archived)&&!this.settings.worker&&!this.settings.cache&&'undefined'==typeof this.settings.replacements&&(this.settings.replacements=!0),this.settings.cache&&'undefined'!=typeof caches){let e,i,s;this.archived?(e=encodeURIComponent(this.locationUrl.toString()),s='epubjs-zip/',n=new gn(s+e+t,location.href),i=this.resources.cache(s,n.toString()),this.cacheUrl=n):a&&(e=encodeURIComponent(this.locationUrl.origin),s='epubjs-proxy/',n=new gn(s+e+t,location.href),i=this.resources.cache(s,n.toString()),this.cacheUrl=n),(this.settings.script||this.settings.stylesheet)&&r.push(i)}if(this.settings.replacements){let e=this.resources.replacements();r.push(e)}return Promise.all(r).then(()=>this.loadNavigation(this.package).then(()=>this.navigation)).then(()=>(this.isOpen=!0,this.book=this.toBook(),this.opening.resolve(this),this.book)).catch((e)=>{console.error(e)})}cache(e,t,n){return e||(e=this.key()),this.resources.cache(e,t,n).then(()=>(this.book=this.toBook(),this.book)).catch((e)=>{console.error(e)})}replacements(){return this.resources.replacements().then(()=>(this.book=this.toBook(),this.book)).catch((e)=>{console.error(e)})}/**
	  * Load Navigation and PageList from package
	  * @private
	  * @param {document} opf XML Document
	  */loadNavigation(e){let t=e.navPath||e.ncxPath,n=e.toc;return t?this.load(t,'xml').then((e)=>(this.navigation=new zn(e,this.resolve(t)),this.pageList=new Ln(e),this.navigation)):new Promise((e)=>{this.navigation=new zn(null),this.pageList=new Ln,e(this.navigation)})}/**
	  * Set if request should use withCredentials
	  * @param {boolean} credentials
	  */setRequestCredentials(e){this.settings.requestCredentials=e}/**
	  * Set headers request should use
	  * @param {object} headers
	  */setRequestHeaders(e){this.settings.requestHeaders=e}/**
	  * Unarchive a zipped epub
	  * @private
	  * @param  {binary} input epub data
	  * @param  {string} [encoding]
	  * @return {Archive}
	  */unarchive(e,t){return this.archive=new jn,this.archive.open(e,t)}generateLocations(e){if(this.book)return this.locations||(this.locations=new An),this.locations.generate(this.book.sections,e).then((e)=>(book.locations=e,e))}loadLocations(e){let t;if(this.book)return this.locations||(this.locations=new An),t='string'==typeof t?JSON.parse(e):e,this.book.locations=t,t}/**
	  * Generates the Book Key using the identifer in the manifest or other string provided
	  * @param  {string} [identifier] to use instead of metadata identifier
	  * @return {string} key
	  */key(e){var t=e||this.package.metadata.identifier||this.url.filename;return`epubjs-${Nn}-${t}`}toBook(){let e=this.resources.resolve.bind(this.resources),t=new In;return t.url='',t.url=this.cacheUrl?this.cacheUrl.resolve('manifest.json'):this.locationUrl.resolve('manifest.json'),this.archived&&(t.source=this.locationUrl.toString()),t.resources=this.resources.toArray(),t.spine=this.package.spine.map((e,n)=>{let a=this.resources.get(e.idref)||e,r=this.resources.resolve(a.href),s=t.resources.findIndex((e)=>e.id===a.id);// Remove from resources array
return-1<s&&t.resources.splice(s,1),e.index=n,e.cfiBase=new yn().generateChapterComponent(this.package.spineNodeIndex,e.index,e.idref),a&&(e.source=a.href,e.href=r,e.type=a.type,a.properties&&a.properties.length&&e.properties.push.apply(e.properties,a.properties)),e}),t.metadata=this.package.metadata,this.navigation&&(t.toc=this.navigation.getTocArray(e),t.landmarks=this.navigation.getLandmarksArray(e)),this.pageList&&(t.pages=this.pageList.toArray()),this.locations&&(t.locations=this.locations.toArray()),t}/**
	  * Destroy the Book and all associated objects
	  */destroy(){this.opened=void 0,this.loading=void 0,this.loaded=void 0,this.ready=void 0,this.isOpen=!1,this.isRendered=!1,this.book&&this.book.destroy(),this.locations&&this.locations.destroy(),this.pageList&&this.pageList.destroy(),this.archive&&this.archive.destroy(),this.resources&&this.resources.destroy(),this.container&&this.container.destroy(),this.packaging&&this.packaging.destroy(),this.spine=void 0,this.locations=void 0,this.pageList=void 0,this.archive=void 0,this.resources=void 0,this.container=void 0,this.packaging=void 0,this.navigation=void 0,this.url=void 0,this.path=void 0,this.archived=!1}}ct(Wn.prototype);const Hn=!1;let Zn={resources:'epubjs-resources'};new class{constructor(){self.addEventListener('message',this.onMessage.bind(this)),self.addEventListener('install',this.onInstall.bind(this)),self.addEventListener('fetch',this.onFetch.bind(this)),self.addEventListener('activate',this.onActivate.bind(this)),this.epub=void 0}onInstall(e){Hn,e.waitUntil(self.skipWaiting())}onActivate(e){Hn,e.waitUntil(clients.claim().then(function(){// After the activation and claiming is complete, send a message to each of the controlled
// pages letting it know that it's active.
// This will trigger navigator.serviceWorker.onmessage in each client.
return self.clients.matchAll().then(function(e){return Promise.all(e.map(function(e){return e.postMessage({msg:'active'})}))})}))}onFetch(e){e.respondWith(caches.match(e.request).then((t)=>{// Cache hit - return the response from the cached version
if(t)return Hn,t;let n=e.request.url.indexOf('epubjs-zip/');if(-1<n)return this.loadFromZip(e.request);let r=e.request.url.indexOf('epubjs-proxy/');return-1<r?this.loadFromProxy(e.request):(Hn,fetch(e.request));// Not in cache - return the result from the live server
}))}onMessage(e){let{data:t}=e;switch('string'==typeof t&&(t=JSON.parse(t)),Hn,t.method){case'init':this.init(t);break;case'destroy':this.epub&&this.epub.destroy(),self.close();break;case'add':this.add(e);break;case'open':this.epub&&this.epub.open.apply(this.epub,t.args).then((e)=>{let n=e.toJSON();this.respond(t.method,n,t.promise)});break;default:if(this.epub){let e=this.epub[t.method].apply(this.epub,t.args);Promise.resolve(e).then((e)=>{'function'==typeof e.toJSON&&(e=e.toJSON()),this.respond(t.method,e,t.promise)})}}}respond(e,t,n,r){let a={method:e,promise:n,value:t};r&&(a=JSON.stringify(a)),self.postMessage(a)}init(e){let t,n;1<e.args.length?(n=e.args[0],t=e.args[1]):t=e.args[0],'undefined'==typeof t.cache&&(t.cache=!0),this.epub=n?new Wn(n,t):new Wn(t),this.epub.on(Cn.BOOK.READY,(e)=>{self.postMessage({eventName:'ready',value:e})}),this.epub.on(Cn.BOOK.OPEN_FAILED,(e)=>{self.postMessage({eventName:'failed',error:e.message})})}add(e){let t=e.data.resources,n=e.data.key||Zn.resources;!n in Zn&&(Zn[n]=n);// Open the given cache with the keys
let r=caches.open(Zn[n]).then((e)=>{// Process each item in the resources
let n=t.map((t)=>{let n=t.href;// Check if the href is already cached
return e.match(n).then((t)=>{if(!t){// If not found, fetch the resource and store it
let t=new Request(n,{mode:'no-cors'});return fetch(t).then(function(t){if(t.ok)return e.put(n,t)})}})});return Promise.all(n)});e.waitUntil(r)}loadFromZip(e){let t='epubjs-zip/',n=e.url.indexOf(t)+t.length,r=e.url.substring(n).split('/'),a=r.shift(),i=decodeURIComponent(a),s=decodeURIComponent(r.join('/')),o='text/plain',d;return this.zip?(d=this.zip.file(s),o=Bn.lookup(d.name),d.async('arraybuffer').then((t)=>{let n=new Response(t,{status:200,headers:{"Content-Type":o}}),r=n.clone();return caches.open(a).then((t)=>t.put(e.url,r)).then(()=>{console.log('from cached zip')}),n})):(this.zip=new Fn,fetch(i).then((e)=>e.arrayBuffer()).then((e)=>this.zip.loadAsync(e)).then(()=>(d=this.zip.file(s),o=Bn.lookup(d.name),d.async('arraybuffer'))).then((t)=>{let n=new Response(t,{status:200,headers:{"Content-Type":o}}),r=n.clone();return caches.open(a).then((t)=>t.put(e.url,r)).then(()=>{console.log('loaded from zip & cached')}),n}))}loadFromProxy(e){let t='epubjs-proxy/',n=e.url.indexOf(t)+t.length,r=e.url.substring(n).split('/'),a=r.shift(),i=decodeURIComponent(a),s=decodeURIComponent(r.join('/')),o=Bn.lookup(r[r.length-1]);return fetch(i+'/'+s).then((e)=>e.arrayBuffer()).then((t)=>{let n=new Response(t,{status:200,headers:{"Content-Type":o}}),r=n.clone();return caches.open(a).then((t)=>t.put(e.url,r)),n})}}});
//# sourceMappingURL=epub.worker.min.js.map
